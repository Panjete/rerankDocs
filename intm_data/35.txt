severe acute respiratory syndrome or sars emerged as a life-threatening viral disease of unknown origin in late 2002 in the guangdong province of southern china caused by the sars-cov-1 virus 1 the severe acute respiratory syndrome coronavirus 2 sars-cov-2 is a related virus responsible for the current outbreak of coronavirus disease 2019 covid-19 2 as of june 2020 over 76 million people globally have been shown to be infected with the virus with more than 426000 deaths directly attributed to its effects john hopkins university httpscoronavirusjhuedumaphtmlthe covid-19 pandemic has resulted in massive scientific efforts attempting to fight the disease and understand the biology of the virus this has derived in enormous challenges for the research scientist when attempting to find and select information relevant to specific areas of viral biology and pathology in order to aid the scientific community and expedite drug and vaccine development multiple data curation efforts have been undertaken to perform a critical assessment of the literature and represent different aspects of the virus and the disease in a structured and computationally accessible manner one recent example of such efforts is the covid-19 disease map 3 a community effort to capture the intricate aspects of sars-cov-2 biology as reusable and interoperable pathway maps so they can be used in systems biology and modelling pipelinesidentification of virus-host interactions and the analysis of the topological structure of a relevant molecular interaction network is a necessary step in enabling an understanding of the cellular mechanisms involved in a biological process such as viral infection of a cell a detailed map of the interactions between human and pathogen proteins will aid a more complete awareness of the mechanisms of infection and subsequent viral replication assembly and release and may help to identify novel drug targets or assist in rapid and more accurate repurposing of existing drugs for treating or preventing infection further to this such networks can be used to study data such as changes in the transcriptome or proteome of a virally infected cell when compared to normal co-regulated genes or proteins which also co-cluster in this network may indicate that these entities are involved in the same biological process or are members of the same functional complexfor such a network to be of value to the researcher a certain amount of meta-data needs to be provided which enables the assessment of network quality and data types these data need to be supplied in a standardized and computer-accessible format which allows for scoring filtering and selection the imex consortium 4 has been providing such data for over 15 years supplying experimental details using controlled vocabulary terms captured using a detailed curation model all aspects of an interaction experiment are described including host organism interaction detection and participant identification methodologies and full details of the constructs such as binding domains and the effects of site-directed mutations current membership of the imex consortium includes the intact 5 mint 6 dip 7 uniprot 8 matrixdb 9 and iid 10 data resources who collaborate to provide the users with a single consistent viral-host dataset to work with when a novel virus emerges as was the case with sars-cov-2 in 2019 the study of closely related species such as sars-cov-1 and other coronaviruses may help with this process giving the scientific community time to produce species-relevant data for this reason the network includes data on all coronaviruses available in the scientific literature whilst primarily consisting of protein-protein interaction data the network also contains interactions with lipids glycosaminoglycans and rnas again curated to imex standards the data is fully open under a cc-by 40 license and downloadable from the intact website and ftp in psi-mi standard tab-delimited and xml-based formats a brief description can be found under wwwebiacukintactresourcesdatasets and a collection of interactive network representations of the dataset at the time of writing is available at httpwwwndexbioorgnetworkset4c2268a1-a0f0-11ea-aaef-0ac135e8bacf the dataset will be expanded and updated with every intact releaseas of june 2020 the dataset contains 1778 unique interacting molecule pairs represented in 2212 binarized interactions extracted from 86 publications 5 of which are pre-prints from biorxiv the dataset can be downloaded from the intact ftp site in psi-mi standard xml-based formats psi-mi xml 25 ftpftpebiacukpubdatabasesintactcurrentpsi25datasetscoronaviruszip and 30 ftpftpebiacukpubdatabasesintactcurrentpsi30datasetscoronaviruszip it can also be browsed on the intact webpage wwwebiacukintactqueryannotdatasetcoronavirus where it is available for download in additional formats such as the tab-delimited psi-mi-tab 27 a brief dataset description can be found under wwwebiacukintactresourcesdatasetscoronavirus the data can be searched in the imex psicquic 11 service and on both the imex consortium webpages wwwimexconsortiumorg and via the virusmentha 12 browser at httpsvirusmenthauniroma2it interactive network representations for unique molecule pairs and full evidence details can be found in httpsdoiorg1018119n9mp4s and in httpsdoiorg1018119n9rc8f as with all data hosted in intact the dataset is freely available under a cc by 40 licensethe data refers mostly to ppis 1674 interactions plus some interactions involving different rnas 67 interactions or small molecules 37 interactions while data on 70 organisms are included suppl table 1a most interactions refer to sars-cov-2 and sars-cov-1 -human interactions 992 and 351 unique interactions respectivelyimex consortium curators have collated interaction evidence from scientific articles and pre-prints using the following selection criteria
the publication contains interactions involving proteins from any virus member of the coronaviridae family ncbi taxon id 11118 this includes not only sars-cov-1 and sars-cov-2 but also mers-cov and members of the family that infect other mammalsthe publication contains interactions of human proteins with established relevance for sars-cov-2 life cycle eg ace2 interactions have been included in the datasetevery interaction described in these publications is curated and included in the dataset even if their relevance to covid-19 might seem limited this results in the inclusion of data from apparently irrelevant species eg yeast that is of interest from the phylogenetic and evolutionary point of viewpre-prints are considered and if deemed appropriate curated when containing sars-cov-2 data an exception to imex practice of representing only peer-reviewed research this reflects the interest these data have engendered during the pandemic these datasets are clearly marked as pre-publication and will be re-curated if necessary when publishedthe imex curation model captures the details of specific constructs used for the detection of interactions this allows for the representation of different construct-associated features such as specific mutations affecting interaction outcome 13 or sequence regions that are associated with binding most of these in-depth studies are centered around the spike-ace2 interaction for sars-cov-2 and sars-cov-1 the only other sars-cov-2 mutation reported so far is nsp5  3c-like proteinase pcys145ala catalytically inactive mutant which exhibits an interaction profile different from the canonical form in an ap-ms study 14 there are a few other mutations reported for sars-cov-1 and in other members of the coronaviridae family but it is clear that specific variation effects on coronavirus-related interactions is an area requiring extensive exploration as shown in figures 1b and 1c fragment constructs have been used in more studies than mutations although some of these might have been designed for convenience reasons eg constructs that are easier to express in heterologous systems interactive network representations highlighting mutations and binding regions can be found in httpsdoiorg1018119n9w590 and in httpsdoiorg1018119n90w3wregarding interaction data generation approaches the experimental setup used to detect an interaction is summarized by three key fields in the imex curation model the method used to determine that an interaction is happening interaction detection method the method used to determine which molecules are involved participant detection method and the biological environment in which the interaction occurs host organism each of these is described by an appropriate controlled vocabulary term making the data readily searchable in the coronavirus dataset the overwhelming majority of data were generated by affinity-purification combined with mass-spectrometry approaches performed in hek293t or hela cells suppl table 1b this type of data produces sets of potential interacting partners preys associated with a bait of interest but does not directly identify binary interacting partners also the data needs to be automatically expanded into binaries for its representation in tabular or network graph form this accounts for a large proportion of spoke-expanded binary relationships found in the dataset 1310 out of 2212 interactions 59 are expanded binaries while only 43 of the binary interactions found in the full intact database are expanded binariesmost content has been curated after declaration of the covid-19 pandemic on 11032020 figure 1 the data growth timeline shows three jumps in interaction numbers two for sars-cov-2 and one for sars-cov-1 due to curation of high-throughput ht studies not available for other coronaviridae figure 1a this is also reflected in the pattern of data growth regarding detailed information about mutations and binding regions figure 1a the plots also illustrate that at this point there are more studies dealing with detailed interaction data for sars-cov-1 a situation that will likely change as more sars-cov-2 studies are performedinteraction data is derived from both small-scale studies focused on one or just a few interactions low-throughput lt and large-scale screenings able to detect hundreds or thousands of interactions in a single experiment ht the extreme urgency in the study of sars-cov-2 has resulted in a strong dominance of high-throughput data for this species in comparison with the other members of coronaviridae reported in the dataset figure 2a additionally sars-cov-2 small-scale studies are mainly focused around the ace2-spike interaction due to its relevance for virion recognition and infection for the remaining interactions most sars-cov-2 data comes from two studies gordon et al 14 and li et al 15 both focused on affinity purification techniques combined with mass-spectrometry detection of interacting candidates ap-ms in hek293t cells transfected with sars-cov-2 proteins the studies are distinct showing virtually no overlap figures 2bd and different degree distribution patterns figure 2e gordon et al shows an unexpected pattern of fully isolated components likely due to stringent target selectionlack of overlap between different high-throughput interaction datasets is a long-recognized phenomenon since different experimental approaches are better suited to detect interactions featuring specific physico-chemical characteristics and protein abundances among other parameters 1618 even in this case where the approach used is broadly similar they likely reflect methodological differences ap-ms datasets are very sensitive to protein abundances and affinities as well as to the selection and orientation of tags and expression systems additionally strong differences can arise during the selection of bona fide interactors where multiple strategies can be used in order to clean up spurious detections the lack of common interactions between the different studies focused on sars-cov-2 suggest that more of these systematic experiments are needed to increase reliability of biological conclusions extracted from this type of dataexploring the biological context of sars-cov-2 interactors suggests that the two ht studies are complementary pathway enrichment figure 3 and supplementary table 2 finds commonalities on expected pathways related with cell cycle response to stress and infectious disease and dna and rna synthesis and processing key pathways such as innate immune response or cytokine signaling are only found in one ht study along with several intracellular signaling and metabolic routes only sars-cov-1 shows appreciable enrichment in lung tissue while none of the sars-cov-2 sets reach the 5x enrichment threshold suggested by jain  tuteja 19 supplementary figure 1 supplementary table 3 finally sars-cov-2 interactors from both studies are found as components of histone deacetylase exosome and atp-ase transmembrane complexes supplementary table 4 including those represented in only one of the studies we see an abundance of complexes involved in endosome and exosome generation mitochondrial metabolism protein production ca2-dependent cell signaling and cell cycle controldevelopment of the imex coronavirus dataset complements other curation efforts that have been initiated in the light of the pandemic the dataset has been used by the disgenet database 20 for contextual annotation with related diseases httpswwwdisgenetorgdownloadssection9 also members of the imex consortium are involved in the covid-19 disease map initiative httpscovidpagesunilu where interaction information from the dataset is guiding covid-19-related pathway curation as an example the list of pmids from imex coronavirus dataset has been used to screen papers containing causal interactions to build covid-19 causal network perturbed during sars-cov2 infection by the signor 20 resource 21 httpssignoruniroma2itcovid and to select the gordon et al human interactors to integrate in the signor 20 networkwe are also involved in a parallel effort curating sars-cov-1 and sars-cov-2 related protein complexes in the complex portal wwwebiacukcomplexportal linking available experimental interaction evidence when possible this initiative is especially relevant because as previously stated coronaviruses increase the number of functional proteins produced by the viral genome by post-translational cleavage of long polypeptide transcripts the functionality andor stability of these proteins is further increased through the formation of protein complexes all of which have been catalogued into the complex portal to date 12 complexes have been identified in each strain formed by viral-viral protein interactions including homomeric assemblies such as the dimeric sars-cov-2 main protease complex cpx-5685 other reference entities such as the sars-cov-2 spike - human ace2 receptor complex cpx-5683 have also been created to enable their identification in large -omics datasets all complexes have been annotated with gene ontology terms describing their role in the virus lifecycle which again will assist in the analysis of large omics-derived datasets ongoing work includes the addition of the mers virus complexosome to the available dataaccurate and detailed representation of biological insight into public databases is a fundamental source of data for scientific discovery even more so in a situation of accelerated research work such as the current pandemic our curation of molecular interactions related to coronaviridae enables a systematic perspective of this data and greatly increases its interoperability from our overview analysis of the data available so far we can highlight how the sars-cov-2 data seems to be both biologically relevant and thus informative for research on the disease and strongly preliminary so full consideration for its inherent incompleteness should be given when using it the imex consortium is expanding the resource as new data becomes available striving to provide the most accurate possible picture of the coronaviridae interactomeall stats and details shown on this manuscript are derived from the intact database release of 2020-04-30 complex portal data used for human complexes overlap checks was also obtained from the same data releasespecific analyses include the following datasets sars-cov-2 - all human targets of sarscov-2 viral proteins sars-cov-1 - all human targets of sars-cov-1 viral proteins gordonlt - all human targets of sars-cov-2 viral proteins derived by gordon et al plus selected sars-cov-2 low throughput studies lilt - all human targets of sars-cov-2 viral proteins derived by li et al plus selected sars-cov-2 low throughput studies the selected low-throughput studies added to gordon and li studies represent just two representative interactions that were not detected in either study ace2-spike and bsg-spike so they were not analysed separately formatted subsets are available in supplementary table 5analyses were done using r 400 22 and the r datatable package 23 venn diagrams were created using ggvenndiagram 03 24 all other plots were created using ggplot2 330 24 and wesanderson 25 packagesanalysis was performed using tissueenrich 19 180 r package on human protein targets using protein atlas 26 expression data background was the entire proteome as listed in the human protein atlas website wwwproteinatlasorg only hits with a fold change above zero are shown log10 p-value was zero for all tissues full data is available in supplementary table 3pathway enrichment analysis was performed using pathdip 4 27 api in r with literature curated set only pathways with false discovery rate 001 bh-method were considered as the majority of enriched pathways 75 for sars-cov-1 80 for sars-cov-2 72 for gordonlt and 76 for lilt were from reactome database 28 we further organized them using level one reactome ontology to create the figure all enriched pathways are listed in the supplementary table 2 and pathways present in multiple sets are highlighted in the overlap tabcoronavirus outbreak continues to surprise the world to date over one million people across the two hundred countries have been infected according to the last updates of the world health organization who approximately sixty thousand confirmed deaths among the cases are reported 1 humanity had not faced a pandemic through the history that spreads rapidly all over the earth if a defined brand new virus is able to spread from person to person while infecting the contacts easily with a sustained and efficient way then it is called a pandemic the novel coronavirus 2019-ncov fulfills all those definitions strongly at the end of the year 2019 wuhan city of china cradled the first case of the novel coronavirus now from europe to america its deadly effects threaten the whole world the who named the 2019-ncov epidemic disease on february 11 2020 as coronavirus disease covid-19 2019-ncov is a new member of the severe acute respiratory syndrome coronavirus family sars-cov and labeled as sars-cov-2 2with its spike surface for binding to receptors see figure 1
 sars-cov-2 presents the covid-19 with the symptoms of fever sore throat and following pneumonia with severe acute respiratory distress 3 for all that the respiratory symptoms are not in a specific form there are so many isolated cases ie the existence of the covid-19 may not appear at the first clinical symptoms 4 the rapid spreading nature of the coronavirus and the serious respiratory effects to humans make the diagnosis of the covid-19 an urgent situation 5 today health specialists use the reverse transcription polymerase chain reaction rt-pcr test for the detection of the nucleic acid forms stem from the sars-cov-2 in the process the respiratory specimens such as oropharyngeal swabs or nasopharyngeal sampling are collected and the very important issue when doing this is the receipt place of the specimens the operation is categorically open to malfunctions by the expert mistakes 6 besides the operation procedure the pcr test is a time-consuming process because a patient has to be isolated in non-suitable circumstances for hours until getting the test results in addition these types of tests have a low detection rate of between 30  50 hence most of the times they need to be repeated to make a confirmation 7to be able to procure an atmosphere where the patients could get quick treatment and care is a crucial task in the fight of the covid-19 because of the fast-spreading essence of the pandemic patients apply to the health center in batches at this point the need for rapid diagnosis methods is a very important issue for monitoring the sars-cov-2 infections to diagnose there is another option of visualization using the radiological images for instance chest x-rays or computed tomography ct former studies prove that covid-19 causes abnormalities that are visible in the chest x-rays and ct images in the form of ground-glass opacities with a strong suggestion a diagnostic with radiological images could be a first step in monitoring the covid-19 9 although the radiological images based diagnostic is a faster way and also it has some advances over the pcr testing in terms of the detection rate in earlier stages of the covid-19 the backbone of the system is the need of experts in comprehending the images intrinsically artificial intelligence ai based diagnostic options can encourage the experts to gain a rapid and accurate explication over the x-ray images on the way of the detection of the covid-19 10for this motivation there are several studies in the literature including the analysis conducted on ai-based diagnostic of the covid-19 with the help of the radiological images 11 12 13 14 15 in 15 the authors propose a transfer learning model that processes a dataset including the ct images of the covid-19 infected patients they obtain a test accuracy of 793 the study 14 indicates a three-class model that can distinguish the covid-19 influenza-a viral-based pneumonia and healthy cases the segmentation-based study reaches the 867 accuracy value with the ct images dataset in 13 the authors propose a rapid ai development cycle using a deep learning-based ct image analysis heretofore the mentioned studies in the literature use non-public datasets through developing a deep learning-based diagnostic of the covid-19 the studies 11 12 provides public datasets including the covid-19 x-ray images of infected patients in 11 the authors propose a combined public dataset besides a deep learning model called covid-net for the detection of covid-19 covid-net architecture relies on a tailored convolutional neural network cnn model which uses the chest x-rays as inputs the authors reach a test accuracy of 924 with restricted covid-19 class images in our study we use the same dataset of the 11 to be able to outperform the existing covid-net accuracy in detecting the covid-19 in addition there are several more studies that we can consider in covid-19 detection using chest x-rays 16 17 18 19 with a detailed pre-processed dataset our study captures the flag with a specially designed deep learning modelthe usage of deep learning models in medical image processing and analysis is a challenging topic in the ai field 10 20 in 21 the authors propose a cnn model for pneumonia detection the authors of the study 22 propose a vessel extraction from the fundus images in 23 an expert system is proposed for brain tumor detection in high-resolution brain magnetic resonance images to this end in our study we use a specially designed deep learning model called squeezenet first proposed in 24 the proposed deep learning model for the diagnostic of the covid-19 is based on squeezenet architecture as because it has a smaller structure compared to the well-known pre-trained network designs 25 26in this study we introduce a covid-19 detection ai model covidiagnosis-net based on deep squeezenet with bayes optimization with a view to obtain a higher accuracy rate the hyper-parameter optimization of the deep learning models is a crucial task 27 the backbone of the proposed model ie the dataset is a public dataset that is detailed in 11 differently from the study 11 we perform a multi-scale augmentation process to overcome the imbalance problem of the proposed public dataset since the focus is on covid-19 diagnosis we perform a detailed offline augmentation process for the limited number of covid-19 infected chest x-rays of the patients with the help of the offline well-defined augmentation process and bayes-squeezenet our proposed diagnostic model for covid-19 outperforms the covid-net 11 while reaching a test accuracy of 0983 in building our model we first perform a detailed augmentation after obtaining the augmented dataset the data split is generated on the shuffled database to form the train validation and test datasets we manage the training process of the deep squeezenet while performing a bayes optimization with the validation phase at the same time through the training the best model is determined and the final network design is tested with the separate test dataset package on through those developments the proposed deep bayes  squeezenet obtains a higher detection rate in the diagnosis of the covid-19 using the chest x-ray imagesherein we can describe the contributions of our proposed model as listed below1presents a novel model for the rapid diagnostic of the covid-19 based on deep bayes-squeezenet called covidiagnosis-net2overcomes the imbalance problem of the public dataset a multi-scale offline augmentation is performed3proposes an easy to implement deep learning network for embedded and mobile systems that could aid the health experts for a stable diagnosis of the covid-19 in the control of the current epidemic
the composition of the rest of the article is as follows section 2 describes the materials and methods with details of the proposed deep bayes-squeezenet along with the model components ie squeezenet architecture bayesian optimization and dataset description section 3 presents the explanation of what we design in experiments with evaluation criteria findings and a comparison sub-section to draw the big picture of where our study stands among the other state-of-the-art methods finally section 4 briefs a conclusion of the studythe overall architecture of the deep bayes-squeezenet based rapid diagnostic system is presented in figure 1 the proposed system is composed of three main stages as offline augmentation of the raw dataset training of the bayesian optimization-based squeezenet model and decision-making of the network with the testing phase the proposed method classifies the three-class x-ray images labeled as normal no infection pneumonia bacterial or none-covid viral infection and covid covid-19 viral infectionin the first stage the offline augmentation method is utilized to the raw input x-ray images due to their uneven sample distributions this method is preferred for smaller classes with fewer sample numbers in order to increase the size of the classes by a transformation factor after the augmentation the augmented dataset is divided into three subsets as train validation and test sets train and validation sets are set as the input of the training and optimization stage the test set is used for the testing input in the training and optimization stage the squeezenet convolution network is utilized and it uses the squeeze and expands layers of the fire modules to construct a smaller and more effective cnn architecture squeezenet is a pre-trained cnn model and it is pre-trained on the ilsvrc-12 challenge imagenet dataset 30 31 this supporting dataset is completely different from x-ray images and the squeezenet model needs to be fine-tuned to classify the covidx classes in order to obtain the best decision-making model the cnn network is optimized with the bayesian-based method which is a sequential design strategy during training a validation error is used to update the optimization process finally the best squeezenet model is obtained and used for the decision-making process with the test set the obtained best network model classifies the infection classes and classification performances are determinedsqueezenet is a convolution network that executes better performance than alexnet with 50x fewer parameters 23 24 30 squeezenet consists of fifteen layers with five different layers as two convolution layers three max pooling layers eight fire layers one global average pooling layer and one output layer softmax the architecture of the network is given in figure 2
as shown in figure 2 kk notation represents the receptive field size of the filters s denotes the stride size and l is the feature map length respectively the input of the network has 227227 dimensions with rgb channels the input images are generalized by convolution and max pooling is applied convolution layer convolutes between the weights and small regions in the input volumes with 33 kernels each convolution layer performs an element-wise activation function as the positive part of its argument squeezenet utilizes from the fire layers which constructed of squeeze and expansion phases between the convolution layers the output tensor scale and input of the fire are consistent the squeeze phase uses the filter of size 11 whereas expansion uses the filters of size 11 and 33 firstly the input tensor hwc passes through the squeeze and the number of convolution is equal to c4 of the number of input tensor channels after the first phase the data passes through the expansions and depth of the data is expanded to c2 of the output tensor depth both squeeze and expansion phases are connected to the relu units the squeeze operation compresses the depth and expansion increases the depth by keeping the same feature size finally expansion outputs are stacked in the depth dimension of input tensor with concatenate operation figure 3
summarizes the fire layer and sub-operations assuming fm and c define the feature maps and channels the output layer fy of the squeeze operation with the kernel w can be expressed as 321fyfm11fmc1cwcfxcfm1
here fyrn and wrc1fm2 the squeeze outputs can be defined as a weighted combination of the feature maps of the different tensors in the network max pool layers execute a down-sampling operation along the spatial dimensions and global average pool convert the feature maps of the classes into one value at the end of the network softmax activation function gives the multiclass probability distributions
table 1
presents the detailed layer configuration of the squeezenet architecture the motivation for designing the squeezenet architecture in covid-19 diagnosis is that the network provides three main advantages 23 24 1 the network is more efficient because it has fewer parameters 2 applications developed for this network are easy to move and require less communication 3 it has a model size of less than 5 mb and it is easy to implement to embedded systemshyperparameters have a key role in both machine learning and deep learning algorithms inasmuch as those parameters are tightly managing the acts of the training algorithms and they affect the performance of the models significantly therefore the optimization of hyperparameters is a crucial task especially when it comes to deep learning in medical image processing in general there exist two ways of hyperparameters optimization called manual and automatic searching the manual searching as the name suggests looks for the hyperparameters by hand hence manual searching requires expertise unfortunately when dealing with big data and so many model parameters for tuning even expertise may be insufficient 27 33 to handle the difficulties of manually searching automatic searching alternatives take place in the literature grid search and random search algorithms can be considered in this topic nevertheless there are still problems remaining in both methods such as the curse of dimensionality and unavailability of the highly efficient performance with the time-consuming operations 27 34tuning of hyperparameters is such an optimization problem that the objective function of it is latent and unknown in other words it is a black-box function as its name suggests stemming from the bayesian theorem the bayesian optimization is an efficient algorithm dealing with such kind of optimization problem 27 35 bayesian optimization relies on a typical kind of approximation dealing with an unknown function requires an approximation with the help of some known samples ie prior knowledge it is like the concept of the posteriori probability here the food of the algorithm is observations generated by the model evaluations in which the outputs of the online learning this means that in bayesian optimization we need a training process during the training the model will trace a function that we only have its knowledge from the learned data in the center of the bayesian optimization algorithm the main purpose is to obtain the related hyperparameters that make learning outline maximum 36 in mathematical expression we can consider a global maximization or minimization problem of the black box unknown functionf2xargmaxxxfx
here x stands for a searching space ofx caused by the nature of the bayes theorem 35 bayesian optimization calculates the posteriori probability pdl of a model d with the aid of the learned data l posteriori probability is proportional to the likelihood pld of observations l and the multiplication of the prior probabilitypd3pdlpldpd
equation 3 reflects the main behavior of the bayesian optimization 27 in brief bayesian optimization searches for the best model amid many of them at this point one can recall the cross  validation method however it is very hard to find the best model in many samples of pre-listed hundreds of alternatives thus bayesian optimization accelerates the operation by reducing the computational cost and we do not need expertise to guess the outputs though 37 the algorithm combines the prior distribution of thefxfunction with the samples of the prior knowledge to obtain the posteriors those posteriors calculate the value which describes the maximization point of thefx herein the criterion of the maximization process is the expression called acquisition function we introduce a pseudo-code format of bayesian optimization via algorithm 1 table in the algorithm n1i-1xnynn1i-1 reflects the training dataset which includes i-1 observations of the ffunctionin the flow we can clarify the two basic parts of the algorithm 1 it updates the posterior distribution and 2 it maximizes the acquisition function bayesian optimization process continues repeatedly until the defined maximum iteration value is reached alternatively it can also be quitted when it catches a threshold value which is the difference between the actual value and the obtained optimal value 27 36in the proposed deep bayes-squeezenet model the most important hyperparameter of the deep network design called initial learning rate is optimized beside the l2-regularization and the momentum values we also provide a validation dataset to be able to track the validation error object function in the online training please find the experiment details of the bayesian optimization in section 3as declared before the general detection method for covid-19 disease is the rt-pcr testing that identifies sars-cov-2 rna from sputum or nasopharyngeal swab however rt-pcr testing has a long time complex process and it is very troublesome 6 another detection method is chest radiography imaging due to the abnormalities in chest x-ray images of patients infected with covid-19 2 11 therefore we have selected a distinctive and public dataset including chest x-ray images to respond to the need for a rapid disease diagnosis system 11 in order to compose a special covid-19 dataset two different publicly available datasets were combined as covid chest x-ray dataset 12 and kaggle chest x-ray pneumonia dataset 38 the obtained covidx dataset 11 consists of a total of 5949 posteroanterior chest radiography images for 2839 patient cases the dataset includes 1583 normal 4290 pneumonia and 76 covid-19 infection cases in the pneumonia samples diseases were caused by none-covid-19 viral and bacterial effects considering the number of cases there are a total of 1203 uninfected normal patients 1591 pneumonia cases with none-covid-19 and 45 covid-19 patient cases the dataset includes three classes and figure 4
shows a batch of images that are randomly selected from class samples the images are transformed to rgb with 8-bit depth and have variable pixel-based resolution valuesthe main purpose of the selection of covidx dataset is that it is public available so it is accessible for researchers and to be extensible therefore further studies based on this database may be more helpful in the diagnosis and treatment of covid-19 casesin the classification process of both classical machine learning and deep learning algorithms the imbalance ratio of the class distribution of the dataset has a huge impact on the performances of the models in the study 39 the authors conduct systematic research on how imbalance data affects the classification performance of cnn the findings of the study point out a detrimental effect of the imbalanced class distribution on classification performance in our dataset there are very few covid-19 class images compared to the other classes to overcome this unfavorable situation we perform a detailed offline augmentation over the covid-19 class images in our dataset firstly we obtain the mirrored version of the original images by flipping each image then the listed augmentation technics are applied to both original and flipped images1
noise adding gaussian noise to images2
shear shearing the images in affine form3
brightness decrease decreasing the brightness of the images by subtracting 30 from every pixel4
brightness increase increasing the brightness of the images by adding 30 to every pixel
as figure 5
describes we obtain twelve different images from a single image with the aid of the augmentation techniques and their combinations the same operations depicted in figure 5 are also implemented to the flipped images which are the mirrored versions of the original images at the end of the day we gain twenty-four different images for a single image thus the number of images in the covid-19 class is augmented offline in the pre-processing of the dataset resulting in an acceptable amount figure 6
shows a sample image both in original and flipped mirrored versionin order to evaluate the quantitative performance of the proposed method such evaluation metrics accuracy acc correctness cor completeness com specificity spe f1 score and matthew correlation coefficient mcc are statistically computed from the confusion matrix acc measures the classification performance cor gives the rate of the truly classified x-ray images among the classes while com defines the truly detected negative images spe represents the correctly classified the rate of opposite disease classes f1 is a harmonic average and gives the combination of cor and com mcc measures the quality of the classification performance according to the confusion matrix the selected evaluation metrics are defined as4accntpntnntpnfpntnnfn
5corntpntpnfp
6comntpntpnfn
7spentnntnnfp
8f12corcomcomcor
9mccntpntn-nfpnfnntpnfpntpnfnntnnfpntnnfn
here ntpntnnfpnfn define the number of correctly classified diseases number of correctly classified opposite classes number of incorrectly classified diseases and number of the misclassified diseases respectively the classification procedure proves and determines the robustness effectiveness and generalization ability of the proposed method using the aforementioned evaluation metricsin the experimental setup firstly we perform an offline augmentation to the raw covidx dataset after the pre-processing the augmented dataset is divided into three packages as training validation and testing sets the triple split of the dataset packages is formed as 80 for training 10 for validation and 10 for testing training and validation datasets are designed for the bayesian optimization-based online learning structure as because of the bayesian contribution of our model it needs a validation result to minimize the objective function error after the bayesian optimization-based online training process we reach the best network model to implement the testing phase with a separate test dataset the obtained best model is evaluated all the input images are resized to 227227 pixel size and transformed to rgb with 8-bit depth in the meantime all the dataset packages are shuffled to overcome the negative effect of the overfitting thus we reach a robust decision-making performance for the classification of the infected patient cases in the training process mini-batch size is given as 32 and all images are normalized with the mean subtracting operation
table 2
shows the class distribution of the raw and augmented dataset in the pre-processing we achieve 1536 images after the augmentation of covid-19 class since other classes have sufficient images each we perform the augmentation to just covid class we also provide a balanced dataset fixing the all class image numbers to 1536 samples to gain a robust training performance of the model briefly our offline augmentation model enhances the covid class approximately 20 times in our proposed model we improve the existing dataset by increasing the covid class imagesproposed deep bayes-squeezenet includes the bayesian optimization in the training stage with validation process the objective function of the optimization process is given in figure 7
 it can be seen that function evaluation ends with 35 iterations because of the model saturation at the end of the 10th iteration the minimum observed objective is achieved to construct the best modelthe optimized parameters ie initial learning rate initiallearnrate momentum and l2 regularization are listed in table 3
along with iterations model result run time and observed - estimation values of the objective function during the optimization process it is clearly seen that after catching five different best models bayesian optimization points out the model of the 10th iteration as selected best model after the training process the obtained best model parameters are used in the proposed deep bayes-squeezenet network and highlighted in table 3in order to evaluate the effectiveness of our augmentation improvement we first present the raw dataset results here our aim is to prove the negative effect of the imbalance distributions in the raw dataset over the performance it should be noted that we tune the squeezenet with the best model parameters for a regular training process the re-training and testing processes are performed with the train and test packages of the related dataset please see table 2 figure 8
demonstrates the confusion matrix of the test process of the re-trained squeezenet in the confusion matrix presentation accuracies and errors of each row and columns are given as the percentage value in the lower and right cells respectively the accuracy rates of each column show us the correctness value of each class and the accuracy values for each row state the single accuracy values of the classesas shown in figure 8 the false classification rate appears majorly within normal and pneumonia pneumonia class achieves nearly the perfect classification whereas covid class has 70 accuracy within 10 test samples in the normal class distribution 141 samples are misclassified as pneumonia this situation shows the negative effect of the imbalanced distribution of the dominant pneumonia classin table 4
 we can see the detailed classification results of the squeezenet for the raw dataset the obtained results show that normal class has the lower values of acc com and f1 as 3889 3889 and 5583 respectively the model with the raw dataset just reaches the 7637 overall accuracy and 7000 single accuracy value of the covid class while the highest accuracy is presented by pneumonia class the lower values of mcc and spe in pneumonia point out poor classification performancethe second phase of our experiments is performing the augmented dataset testing process in this phase the proposed deep bayes-squeezenet model which is obtained by the bayesian optimization approach is validated with the separate test dataset it should be noted that the obtained best model is trained with the augmented dataset to overcome the above-mentioned imbalance effects as well as achieving a rapid system for covid-19 diagnosis with a robust and sustainable structure figure 9
presents the confusion matrix of the test phase here we can see a tremendous performance boosting on all classes and overall accuracy the deep bayes-squeezenet model catches all the covid samples in the x-rays perfectly there are just eight misclassified samples among 459 test samples the error rate of the normal class is 2 while it is 33 in pneumonia in addition the most misclassification rate is presented by pneumoniawe can interpret the detailed test results from table 5
 in the decision-making system covid class reaches the perfect classification rate as showing the 100 test accuracy and completeness values f1 and mcc values also prove that it is obtained a stable classification the overall accuracy is 9826 with a com of 9826 it draws a picture that our model is well-trained and robust although pneumonia accuracy decreases to 9673 compared to former experiments all other performance criteria of the related class are boosted and exhibit an effective prediction the classification performance of the normal class is visibly enhanced and it reaches to 9804 acc valuein order to analyze the performance comparison between the experiments of the raw dataset and the augmented one we report the increase rates of the performance values as in figure 10
 the sharp bounce is experienced in the normal class by a boosting of 25 times as it is the focus of our model when we concentrate on the performance of the covid then we detect 25 times boosting in pneumonia class there is a decreasing percentage of 206 considering just the accuracy value the overall accuracy rate has also a performance increasing at the rate of 2866 the overall accuracy rate has also a performance increase at a rate of 2866for a detailed visual analysis we provide a class activation mapping images as shown in figure 11
 class activation mapping is a way of generating visual explanations of the predictions of deep learning models misclassified or unreasonable predictions sometimes can rely on reasonable explanations by the aid of the class activation mapping we can investigate useful knowledge of the prediction regions activation mapping also defines the bias regions in the training images the first column of figure 11 defines the original input images while the second column includes the heat map images of the predicted samples when all the class activation mappings are examined in figure 11 a  c the probability values of the predictions are nearly 100 according to the heat maps of the images the trained network distinguishes the classes with an acceptable feature mapping to form an outlier example figure 11 d presents a misclassified class sample ie normal class is confused with pneumonia the probability values are 025 and 074 for normal and pneumonia respectivelyfig 12
the proposed deep bayes-squeezenet with its low model size is easy to implement in hardware deployments as shown in table 6
 the model size of the proposed network is less than 7731 times lower compared to the alexnet which is the inspiration of the squeezenet architecturethe overall experimental results show that proposed model has a significant and robust performance value over the covid-19 patient cases this study proposes a complete and compact solution using the chest x-ray images for rapid diagnosisthe coronavirus disease 2019 was announced as an outbreak by who on february 11 2020 1 due to the covid-19 outbreak the early diagnosis of this disease has become a key topic for clinicians and radiologists in the world the ai techniques regarding the image classification approaches can help in early diagnose of the disease considering ai cnn methods achieve better and faster results compared to the traditional diagnosis methods in this paper a rapid robust and efficient covid-19 diagnosis method which is namely deep bayes-squeezenet is proposed the proposed method performs the x-ray images into multiclass as normal pneumonia and covid in order to evaluate the proposed cnn model the general performance comparison of our study with the state-of-art methods is given in this section in the model evaluations the related studies depend on the multiclass classification of the chest x-ray images with various ai techniques table 7
shows the comparison results with the related studies uses the same or similar datasetsli and zhu 16 propose a densenet based covid-xpert architecture classifying the three-class chest x-ray images they use transfer learning and obtain an overall accuracy of 0889 wang and wong 11 present covid-net design to the diagnosis of the covid-19 and in their study the main model is based on the tailored cnn machine-driven design is used to improve the model architecture the overall accuracy com and cor metrics of 11 can be listed as 0923 0887 and 0913 respectively the authors also share and collect the covidx dataset used in our study afshar et al 17 introduce a deep learning model based on a capsule network using a four-class dataset their model produces a 0957 overall accuracy farooq and hafeez 18 present a resnet based framework in a four-class dataset with augmentation the model accuracy has remained as 0962 chowdhury et al 19 explain a bundle structure that includes various deep learning models using four different chest x-ray datasets amid the performance metrics that table 8
gives our model outperforms similar studies that use chest x-rays in the diagnosis of the covid-19 although it seems that some of the performance values have been achieved the same with the study 19 the whole performance of the proposed method in our study is better than itin table 8 the performance values of the listed studies are given in terms of covid-19 class accuracy while chowdhury et al 19 have the same overall accuracy with our study the covid-19 class accuracy stays behind the proposed method farooq and hafeez 18 obtain the same accuracy of covid-19 class but our study outperforms it in the overall accuracy in addition the test dataset of the study includes just eight samples of covid-19to the best of our knowledge the proposed model reveals the excellent classification performance for the covid-19 diagnosis with chest x-rays the proposed model has a great advantage of owning a practical network architecture with a robust and stable operation with its nature of including fewer parameters our network is more favorable for embedded systems among existing deep learning modelsa rapid diagnosis method has a key role in the control of infectious diseases and pandemic situations like the up to date covid-19 some limitations of the rt-pcr nucleic acid-based test modules reveal a need for fast alternative methods to be able to serve the front-line experts to make them reach a quick and accurate diagnosis in this study we propose an ai-based decision-making system including the recognition of input x-ray images under the roof of a very practical deep learning model this study is an important attempt including an easy to implement deep learning model which has an accuracy performance of 983 among normal pneumonia and covid cases and 100 for the single recognition of covid-19 among other classes in these difficult days of the global covid-19 pandemic our model has a strong potential to build a tool design for covid-19 monitoring we would like to note that that the rt-pcr test method to detect the sars-cov-2 is still important however it is proved that there are also undeniable shortcomings along with the rt-pcr test method which can be listed as follows 1 its possible methodology lacks 2 strict dependence on the level of the disease timing 3 the possibility for collecting the specimens in mistaken localizations and 4 its response time delay 6 7 in our model working with a deep learning-based practical structure the early stage detections of the covid-19 cases could be done to manage and control the pandemic disease in medical image processing while deep learning methods are preferred in many areas it is becoming more and more important especially in the interpretation of radiological images as such our model which is extremely satisfactory even with its initial results opens the door for the implementation of a comprehensive product that can work mobile and appeal to the end-userbackbone of our model is the deep bayes-squeezenet decision-making system for the covid-19 diagnosis from x-ray images squeezenet with much less model size is a state-of-the-art deep learning model which is inspired by the well-known alexnet with its practical structure and generalization performance the squeezenet is preferable in the embedded applications we improve the squeezenet structure with bayes optimization algorithm to build a robust and sustainable learning model bayesian optimization helps us to build a best-performed model with a validation dataset the diagnosis system is trained using the public dataset proposed in 11 with its augmented form a separate test which is independent of train and validation sets performs the experiments our experimental results also present the performance boosting of the augmentation contribution to the dataset pre-processing thus model training can be performed with a rich image set of x-rays of covid-19 after comprehensive literature research the up to date studies which use the same or similar public datasets are detected and we evaluate our model with those the proposed diagnosis model for covid-19 using the x-ray images the deep bayes-squeezenet outperforms its competitors we believe that with increased training dataset it is expected to get higher resultsin further works we aim to plan our model to be able to work mobile appealing to the health care experts for diagnosis of the covid-19 in addition the possibility of presenting this diagnostic system as a solution for other medical image processing cases will also be exploredthe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paperthe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paperviruses are a submicroscopic agent which are made up of genetic substances inside of a protein coating and it can be found anywhere such as air water and soil a virus can cause different infectious types of diseases such as common flu cold and warts they also cause severe illnesses such as acquired immunodeficiency syndrome aids ebola smallpox 1 etc viruses are akin to hijackers they enter normal cells and from those cells to replicate themselves this process destroys or damages the cells and makes us sick and this kind of virus is called pandemic virus various viruses attack and harm certain cells of the human body such as our respiratory system liver or blood when we get a virus it will not always affect us to get ill from the virus the immune system of us may be capable to fight with it for most epidemiologic infections the only method to help is the treatment of symptoms as you should wait for the immune system to confront against or fight off the virus for viral infections the antibiotics cannot work there are antiviral drugs and medicines to cure or heal some of the viral infections the vaccines help to prevent us from getting various viral diseasesa pandemic is an occurrence of a disease or wide-scale outbreak of any infectious disease which can rapidly increase mortality and morbidity rate on a large-scale over a large area even crossing the international boundaries which can disturb a large population of the world and that can cause a significant social economic and political disturbance previous studies indicate that the chances of pandemics have risen in the past centuries 2 this pandemic outbreak can happen when a novel virus turns out to be capable of circulating or spreading rapidly globally wherein an epidemic can be in a specific region or city in one and other cases there is a serious illness that can rapidly spread out from one to another individual quickly evidence shows that the death rate of the epidemic is generally lesser than a pandemic outbreak for example the unfavorable pandemic in the history that caused the death of more than a hundred million people was the spanish flu 3coronavirus has rapidly spread to almost all countries of the world to date coronavirus is a big family of viruses which causes illness or sickness starting from the very common cold to very more acute or severe disease sars-cov-2 showed about 80 identity of sars-cov-1 and 50 to the middle east respiratory syndrome mars-cov from the genetic sequence and both have their origin from bats according to the phylogenetic reports and genetic sequence coronavirus is adequately similar to sars- cov most likely this disease has spread from bats as proof supports that this virus has a high grade of homology of ace2 angiotensin converting enzyme 2 receptor from a variety of animal species 4 the common sign of the coronavirus infection consists of high and consistent fever persistent dry cough respiratory syndromes such as breathing difficulties and breath shortness 5 the coronavirus infection has spread like a fire and transitioned into a globally pandemic in which as if now know medical researchers found any therapeutic vaccine or drug because of this serious issue it is very significant to identify the diseases at its early stage and quickly isolate people who are infected from the non-affected populationthe coronavirus should be the starting of an exciting time or decade in science and medicine because with the development and improvement of numerous digital technologies they can be applied and used to tackle different diseases and major clinical problems these are the technologies that include big-data analytics iot internet of things blockchain ai which uses machine learning ml and deep learning dl etc these are the advanced technologies that are being used in many aspects of healthcare especially ai and machine learning systems to predict the outcomes and understanding healthcare trends 6 and how ai-based technology and deep learning can help and enhance in the diagnosis of this coronavirus by using a different kind of radiographical images ct and x-ray scans of the chest can be used in diagnosing the pneumonia there are ai-based automated ct or x-ray images analysis techniques for the detecting monitoring and quantifying of coronavirus and to find out the patients from the healthy person have developed 7as of 14 april 2020 the total number of confirmed cases is 1 776 867 the confirmed number of deaths is 111828 and the overall number of countries affected by this virus is 213 as reported by who the usa china italy spain are the most affected countries initially in european countries the very fast and worst affected country was italy where the public health departments hospitals emergency medical systems are struggling to deal with the surge of affected patients the fatality rate of the coronavirus was increasing in the outbreak region of china the first 17 deaths reported by the national health commission of china was on 22nd january 2020 and 56 deaths on 25th january 2020 4 from the initial case in dec 2019 to the rise of new incidents outside the city of wuhan by 13th january 2020 41 number of cases or incidents were confirmed the epidemiologic analysis has shown which already in this early stage human-to-human space and transmission have been happened by close interaction on 13 january 2020 in thailand the first case which was outside china had been reported this was caused by ax resident of wuhan who traveled to thailand and 19 cases were reported in january from outside wuhan city in beijing city 8furthermore 858 of 37 269 confirmed cases had either lived in or traveled to wuhan or had close contact with persons who had been to wuhan the figure 1
depicted above shows the outbreak of the disease till 9th april 8 the coronavirus varies widely from the range of infection asymptomatic to severe condition and serious pneumonia along with the high number of fatality rates the main disease control centers of the chinese reported that the majority of the number of infected people were classified as a symptom of mild to moderate condition 138 as severe condition and only 47 classified as critical condition the total rate of mortality for coronavirus confirmed cases were detected higher in males as compared to the female patients and high risk of death in both cases with rising age the maximum fatality rate of the aged started from the 80 and above 10fig 2
it was very important to control the epidemic and lift the quarantine but only if specific measures could have been taken as much as possible usage of facial masks and restricting public contact is the most effected precaution that people can take until the vaccine is not available apart from these who announced other very significant measures to be taken by everyone such as frequent hand washing use of disinfectants avoid from touching the eye face nose and mouth use gloves to name a few which are adopted worldwide to reduce the probability of 2nd wave of this pandemicin the recent report of who 78 of infected cases were because of household spread or transmission and in the recent clinical report 5 of hospital-acquired infections from patients and medical staff until the vaccine is made available the studies recommended that keeping a reduction in person to person contact less than the pre-quarantine level is very important to contain the spread of the virusthe study has shown that from the previous experience coronavirus symptoms are mainly highlighted by checking the travel history rather than radiography of chest the treatment and detection for the isolation of coronavirus patient cases at an early stage are very important all hard works are being made to decrease the fast spreading of the disease and to provide time for better preparing of healthcare systems and also to the general public it is important to clearly characterize coronavirus to guide and help general public health recommendations and to build vaccines therapeutics and timely diagnosticslastly with the improvement and advancement of internet communication it increases the availability and broadcasting of knowledge the internet has the possibilities in terms of development and the spreading of fake news or misinformation so the government sector must be responsible for providing and delivering the accurate information and clarifying misinformation to help the general public to face this coronavirus infection the below figure depicts the percentage of the coronavirus symptomsin this article we have selected publications for review of literature that have assessed machine and deep learning algorithms applied in medical images to solve a clinical problem and compared each algorithm regarding their output and performancemachine learning is the branch of ai which is based on how the system can learn from previous data recognize patterns and to make decisions with minimum human intervention for example algorithms includes support vector machine svm logistic regression clustering etc deep learning dl is a subset of machine learning and in terms of medical images it can be defined as a computational model 20 21 which is composed of several processing layers to learn data representation and extract the features with multiple abstraction levels an example of a deep learning type is cnn 11in 12 has proposed a deep learning-based technique called deep transfer learning which can predict patients with coronavirus disease automatically it uses images of chest x-ray obtained from patients with coronavirus and from a healthy person dataset of 50 patients with coronavirus images of x-ray were taken from a shared github repository and 50 x-ray images of healthy humans have taken from a repository in kaggle in this study results showed that the pre-trained model resnet50 yielded 98 accuracy among the other three models they have also stated that we believe in our findings and this can help the public health care workers to make decision in clinical practice because of its high performance and accuracy also for patients with coronavirus early prediction of the infection can avoid the rapid spreading of the diseasethis paper study 13 presented automated techniques are used for classifying the x-ray of chest into pneumonia and the class of disease-free by using nine architectures of deep learning which includes the followingbaseline cnndensenet201vgg16 vgg19inceptionresnetv2 inceptionv3xceptionresnet50mobilenetv2
experiments have been conducted using a ct scan and x-ray dataset that includes 5856 images with 1583 normal and 4273 pneumonia and the performance was evaluated using different performance metrics the result shows that the mobilenetv2 inceptionresnetv2 and resnet50 have given more accurate results which is more than 96 in addition they have suggested that with the bigger datasets and more sophisticated techniques of feature extraction based upon deep learning image segmentation may improve the performancein 14 established a deep learning paradigm for the screening of coronavirus patients at an early stage the main aim of this paper is to distinguish coronavirus from influenza-a viral pneumonia and normal cases with the use of ct images ct samples have taken from three hospitals designated to coronavirus from china zhejiang province the total number of 618 samples was collected which includes 219 from 110 coronavirus patients 224 samples of ct from patients with the viral pneumonia influenza-a and ct samples of 175 healthy people the experiments result of this study shown an overall 867 accuracy from the viewpoint of ct cases as a whole they demonstrated that it can be a promising accompanying diagnostic tool for the clinical frontline doctorsas in 15 introduced a new approach of deep learning called covidx-net to help radiologists to automatically diagnose patients with coronavirus using x-ray images this technique is built on seven deep cnn classifiers which consists of densenet121 vgg19 resnetv2 inceptionresnetv2 xception inceptionv3 and mobilenetv2 in this model they have successfully experimented and evaluated the result which is based on 80 training phase 20 testing phase of x-ray images the vgg19 and the dense cnn densenet models have shown a better and similar functioning of automated classification of coronavirus with 089 f1-scores for normal and 091 for coronavirus respectively x-ray images of the public dataset used in this work which consists of 50 images divided into two classes as normal cases of 25 and positive coronavirus images of 25another paper implements an automated detection system of coronavirus diseases using deep learning convolutional neural network and chest x-ray images in this paper they have implemented three different cnn based models such as resnet50 inception- resnetv2 and inceptionv3 for the identification of coronavirus cases using x-ray images the dataset of 50 coronavirus patients has been taken from the open-source github repository dr joseph cohen and 50 images of normal chest x-rays have been selected from a repository in kaggle chest x-ray images the overall performance out of three models shows that the best results obtained from the pre-trained model of resnet50 with an accuracy rate of 98 and the other two models accuracy rate from inception-resnetv2 and inceptionv3 are 87 and 97 in future work they have mentioned that the different cnn models classification performance can be tested by adding the greater number of images in the dataset 7in this study 16 they present earlier detection of coronavirus using ct scan images by using machine learning methods and the dataset is taken from societa-italiana di radiologia medica-e interventistica which belongs to the 53 coronavirus cases and data involving ct abdominal images of 150 and 150 ct images then patch regions of the images were cropped and four different subsets of the patch were created the feature extraction techniques used in this study are the followinggrey -level co-occurrence matrixlocal directional patterngrey-level size-zone matrixgrey-level run-length matrixlast-discrete wavelet transform
the svm classifier was applied to classify the extracted features and the best classification outcomes were obtained from glszm future extraction techniques with an accuracy rate of 9968 in future work more classification and segmentation studies should be done on coronavirus disease by increasing the datasetas in 17 used different deep learning-based techniques for coronavirus detection diseases by using x-ray images different classification models based on svm using deep features of various deep learning architectures as followalexnetvgg16 vgg19googlenetresnet18 resnet50 resnet101inceptionv3inception resnetv2densnet201xceptionnet
are used for detecting the coronavirus patients for experimental work they have been conducting they use an x-ray images dataset that includes 50 images with 25 coronavirus cases from github dr joseph cohen and 25 normal cases from kaggle x-ray images of pneumonia the results show that svm  resnet50 obtained high accuracy fpr9552 f1 score 9552 mcc  9141 and kappa 9076 for detecting the coronavirus patients as compare to the other modelsvarious ml and dl-based algorithms and techniques used for classification of the novel disease known as coronavirus 2019 have been studied and reviewed different papers are studied in which the majority of the related paper used different deep learning architecture according to the literature review it is demonstrated that deep learning with convolutional neural networks might have remarkable impacts on the automatic detection and automatic extraction of highly essential features from chest images which is related to the diagnosing of coronavirus the below figure 3 figure 4
demonstrated the accuracy of different models using ct x-ray images used for the detection of this virusas in the following table on the next page we have categorized each paper with their what technique data modality data source they have used and the result they obtained respectively with the given referencesfor the treatment of coronavirus patients there is no effective drug present until now and due to the rapid increase in the number of cases of coronavirus patients effectual medicinal approach is urgently needed to treat the patients worldwide 18 earlier detection and prediction of coronavirus cases can decrease the spread of diseases 7 worldwide patients of coronavirus data will be a great source and useful for the researchers working on ai and ml to develop an automatic diagnostic tool therapeutic strategy against coronavirus patients and for the same type of pandemics for the coming future 18 19in this study we have summarized different ai-based approaches and the current situation of spreading coronavirus according to the results and studies reviewed it is indicated that using convolutional neural networks which is the deep learning-based technique might have significant effects on automatic tools in terms of detection distinguishing and extraction of essential features automatically from the x-ray images that are related to coronavirus diagnosisdue to the early stage of coronavirus there are still some limitations of the related studies that can be conquered or overcome in the future researches specifically an in-depth analysis requires a lot more patient data particularly those patients suffering from the novel coronavirus so the main point of focus for research work in the future could be distinguishing the patients indicating mild symptoms instead of pneumonia symptoms whereas these symptoms might not be visualized on x-rays more accurately or even not at all to be visualized as more authentic dataset will be available in the near future a more accurate ai-based prediction model can be formed we are working in this direction to procure a more authentic dataset as on today after reviewing all the papers mentioned in table 1
 we are working to develop cnn based deep learning methods for the prediction of coronavirus patientsai-based approaches are very useful for the automatic detection of coronavirus patients using x-ray and ct images the important point is to increase the number of datasets for coronavirus patients and using advance deep learning algorithms to achieve better performance for the detection and prediction of coronavirus also in spite of the fact that proper treatment or cure cannot be determined only from an x-ray or ct image these techniques would be useful as an initial screening of the patients appropriate use of quarantine actions should be implemented on the positive samples until a specific treatment and a complete examination procedure is followedthe outbreak of new coronavirus covid-19 infections has caused worldwide concern because this disease has caused illness including illness resulting in death and sustained person-to-person spread in many countries 1 2 covs are a large family of viruses including the middle east respiratory syndrome mers-cov severe acute respiratory syndrome sars-cov 3 4 and the new virus named sars-cov-2 1 in 2012 saudi arabia experienced the outbreak of mers-cov which is responsible for causing mild to moderate colds infection with mers-cov can lead to fatal complications mers-cov is responsible for causing severe acute respiratory illness that leads to death in many cases according to al-turaiki and his group 4 mers-cov symptoms include cough fever nose congestion breath shortness and sometimes diarrhoea unfortunately information on how the virus spreads and how patients are affected is limited 4 fifteen years after the first highly pathogenic human cov caused the sars-cov outbreak another severe acute diarrhoea syndrome-cov devastated livestock production by causing fatal diseases in pigs the two outbreaks began in china and were caused by covs of bat origin 5 6 on february 11 2020 the world health organisation named the ensuing disease covid-19 1 chinese health officials have reported tens of thousands of cases of covid-19 in china with the virus reportedly spreading from person-to-person in several parts of the country covid-19 illnesses where most of them are associated with travel from wuhan have been reported in a growing number of international locations including the united states 1artificial intelligence ai is gradually changing medical practice with the recent progress in digitised data acquisition machine learning ml and computing infrastructure ai applications are expanding into areas that are previously believed to be only the area of human experts 7 various types of data mining methods have been applied by a few researchers with real cov datasets eg mers-cov based on several types of ml classifiers 8 providing prediction systems that can accurately anticipate and diagnose such virus remains challenging the growth of ai-driven techniques to identify epidemiologic risks in advance will be the key to improving the prediction prevention and detection of future global health risks 9 the main contributions of this study are the exploration of the cov family by reviewing articles on data mining and ml algorithms the acquisition of a clear understanding of its enhancements and how previous research has addressed prediction regression and classification methods this study also aims to collect various information from the literature that are relevant to ml such as application nature the use of ml and data mining algorithms and evaluation methods and accuracy the datasets utilised in the literature are constructed and presented with url sources the motivations challenges and limitations of this approach are examined and recommendations on improving the approach efficiency are provided other important information collected especially on the types of case study used features and classes for cov are explained in separate tables the rest of this paper is organised as follows the second section describes the research methods used in the selected literature the third section presents the literature review the fourth section discusses the results motivations challenges recommendations and limitations case study used and features and classes of cov the fifth section provides a conclusiona comprehensive literature search was conducted in the five mentioned databases for english language citations published from 2010 to 2020 the selection of these indices was because of their sufficient coverage of studies related to our research considering that identified novel cov requires greater attention than other infections this study presented and conducted a three boolean search strategy using various keywords related to pervasive coronavirus eg cov or coronaviridae or coronavirus and keywords related to the detection diagnosis and classification of cov under the concept of ai and ml we used these query techniques to strengthen our search of different ai and ml systems and application studies for cov
the article is an english journal or conference paperthe main focus is on the development of different artificial intelligence and ml applications systems algorithms methods and techniquesthe development only focuses on the detection diagnosis and classification of adaptive cov
table 1 summarises the sequences of the boolean search query used in this paper and the resultsthis process was initiated by removing duplicated articles and screening nonduplicated articles by their titles and abstract to check their compatibility with our inclusion and exclusion criteria the relevant articles were subjected to a full reading process for collecting and extracting research data and constructing the review article in all research articles the entire research process was monitored and supervised by a senior author corresponding author to ensure the production of a highly reliable and beneficial research papergiven the multidisciplinary topic of this systematic review data extraction and classification of the selected studies including data concerning cov with ai applications especially ml techniques were conducted to evaluate the efficacy of this virus in terms of detection diagnosis and classification throughout ai enhancements data elements were extracted from academic literature and included authors nationalities date of publication number of articles per year and number of articles per database for conferring a comprehensive viewpoint of cov this study discussed the cov and analysed the growth scale of the worldwide epidemic in the context of ai using various data mining and ml algorithms such as classification regression and prediction for each study in the literature this study extracted the important feature names evaluation methods used and state of accuracy for each method brief motivation challenges limitation and recommendation were extracted from the reviewed papers to address the serious public health concern for covthe results of search queries conducted in this study are presented in figure 1 three search queries were accomplished to encompass all databases and their search engine mechanisms during data collection the first result comprised 1305 articles from all five databases the number of duplicated articles in all databases was 66 and the results were 1239 the next process was screening the articles based on the title and abstract followed by the mapping of inclusion and exclusion criteria and the results were 249 articles the final process was the full reading of all articles and the outcome was only 8 articles that met the inclusion and exclusion criteria our understanding of the purposeaim of these studies inspired us to analyse each study depending on two related sequences within the search query that was conducted in this systematic review the first sequence is the article should identify the cov and the second is the utilisation of mlthe findings of academic literature search showed that various algorithms are used by previous researchers figure 2 summarises these algorithms and methods the decision tree j48 algorithm was the most frequently used five times naive bayes and support vector machine svm algorithms were each used four times k-nearest neighbour k-nn was utilised two times and the others were each used once figure 3 presents the number of papers included in the academic literature review following the publication year the distribution of scientific papers from 2010 to 2020 is shown below three papers were published in 2016 two papers were published each in 2017 and 2018 only one paper was published in 2019 no paper was published in the other years table 2 illustrates the state-of-the-art cov prediction algorithms table 3 presents the cov dataset descriptions with available sourcesthe analysis indicated many important points that are discussed to identify the research gaps in 11 three ml techniques were applied to the mers-cov dataset to identify the best classification model for binary class and multiclass labels the results showed that the k-nn classifier is the best model for the two-class problems and the decision tree and nave bayes are the best models for multiclass problems in 4 two experiments are applied to the mers-cov infection dataset and the decision tree classifier shows higher prediction proficiency than the other models the experimental results indicated that age and symptoms are the two dominant features for the prediction model and that healthcare staff are likely to survivein 12 a study was conducted in saudi arabia to identify the dominant factors that influence human infection using statistical methods such as univariate and multivariate regression methods the results indicated four dominant features namely disease severity patient age the patient job as a healthcare staff or not and history of chronic disease interaction with camels does not have a high impact on recovery in 8 a study was conducted in saudi arabia between 2013 and 2017 to improve medical diagnosis systems for binary and multiclass problems in mers-cov datasets the experimental results showed that the decision tree classifier achieves the best accuracy for the multiclass labels and the svm classifier obtains the highest accuracy for the two binary class labels in the mers-cov datasetin 13 an emotional recognition system based on ml technique was proposed to understand human reactions to a widespread epidemic of transferrable diseases such as mers the study was conducted using a dataset collected in korea in 2015 and the results indicated the impact of lightening excessive panic in reducing infection in 14 the author investigated people over 50 years old using three ml methods to predict mers cov the results showed that elderly people are more likely to be infected than others in 15 an svm classifier based on sigmoid normal and polynomial iterations was used to analyse the mers and sars proteins the results showed their behaviour similarity and approximate dissimilarities in 16 data mining based on statistical methods was utilised to develop a cloud-based medical system with a high prediction accuracy to prevent mers-cov spread within different regions the dataset comprises the following attributes drug patient and cloud-based user medical recordthe role of ai in healthcare for enhancing the detection and prediction of numerous viruses and diseases has been previously discussed 9 in this review we aimed to obtain a large number and extensive contributions of published articles regarding the utilisation of ai for the detection and clinical diagnosis of mers-cov and sars-cov however the lack of studies on the recent outbreak of covid-19 indicates the need and opportunity to apply ai for predicting such outbreaks ml technique based on supervised and unsupervised learning provides the opportunity to develop a medical diagnosis system in supervised learning the target class of each sample in the dataset where mers-cov and sars-cov classes are previously identified and the developed system can be adapted to a new disease although mers-cov and sars-cov have similarity within the same cluster they are dissimilar to the objects in other clusters thus the clustering technique based on unsupervised learning is considered an efficient method to cluster the collected datasets as presented in table 3 consequently detection and diagnosis can be remarkably enhanced all studies in this review reported the use of ai techniques such as case-based reasoning and rule-based systems however none of the studies utilised other classification methods such as neural networks reinforcement learning and hybrid classification none of the studies utilised and integrated optimisation techniques such as genetic algorithms and particle swarm optimisation to their systems data mining and ml algorithms used in diagnostic operations primarily rely on classification algorithms including decision tree svm and naive bayes classifiers figure 2 and table 2 notably no study in the literature exploited clustering algorithms for the detection and diagnosis of the cov family this technique can be used as a pre-processing step before feeding data into the classification model to gain valuable insights into the case study data by understanding which groups of disease symptoms fall into when applying these algorithmsin this review the sample sizes representing the observations in each dataset are displayed in table 3 in 11 the sample size includes all mers-cov patients in saudi arabia in the second half of 2016 and in 8 the sample size includes the cases from 2013 to 2017 the sample size in 4 represents 1082 records of cases reported from 2013 to 2015 distributed as 633 new case records 231 recovery records and 218 death records the study in 12 includes 836 patient records and 52 patients are reported as dead and only 784 cases are used in 13 the sample size is represented by articles collected from the internet and reported by 153 news media outlets in korea and the comments associated with these articles from day 1 first confirmed case on may 20 2015 to the day 70 in 15 the dataset contains 322 records 92 infected cases and 230 uninfected cases in 16 synthetic data are generated for 02 million users most of the available datasets are related to mers and sars infection cases but no dataset is found for covid-19 because of its noveltyto date research areas in the field of ai such as data mining and ml technique-based applications have been rapidly developed because of their large impact on human life in terms of social scientific medical and engineering-based applications accordingly this section presents the motivation of studies conducted on the cov problem to save lives data mining for medical diagnosis systems is efficient and can be utilised to control the spread of mers-cov and protect humans 8 data mining can also be used to estimate and predict the recovery rates from cov infections 4 ml technique can be used to identify and predict the dominant factors affecting the recovery from mers-cov 12 13 thus studies conducted on identifying the best model can help minimise the effects of epidemic diseases 11 the distinction between sars and mers viruses can be considered a challenging task because of the similarities in their symptoms such as breathing problems and high fever 15 medical diagnosis systems play a significant role in identifying patient health conditions with mers-cov symptoms 14 studies such as 16 integrated the gps with their medical diagnosis systems to cluster the population of infected people based on their geographical areacovid-19 has spread worldwide and threatened human life accordingly several studies have been conducted to develop an intelligent medical diagnosis system using ai technique to control the effects of this virus however numerous challenges and research limitations have been indicated in the academic literature and need to be addressed in the future 8 some of these challenges are related to mers-cov nature and behaviour because understanding how the virus spreads and how people can be infected caused by the complexity of this epidemic disease is extremely difficult the lack of a large dataset in the academic literature for mers-cov is considered a challenging task for ai researchers because it hinders the understanding of viral patterns and features 4 12 the demand to construct a dataset that can be understood by ml algorithms has increased because the current dataset involves infographic data 11 other challenges are correlated with people and government responses to mers-cov that requires more new monitoring approaches and additional efforts compared with the traditional approach for controlling epidemic diseases 13 another challenge with mers-cov is the large variation in symptoms that are mostly similar to common cold symptoms with many other variations of diseases that may occur in cases but not in others some patients have unique symptoms and others have no symptoms at all activists have generated huge and complex volumes of data that render its analysis impractical and difficult to predict using linear classifiers 14 15 the protection of citizens by the government and health agencies is a significant challenge because no specific vaccine exists for this virus to date and requesting people to undergo medical checkups is difficult 16this study aimed to mitigate some of the challenges that have been addressed in the academic literature with their recommended solution for future studies studies such as 8 suggested a pre-processing method to solve the missing-value problem that directly impacts the classification accuracy for the mers virus they also suggested the use of an ensemble technique by combining the cosine method with k-nn ml algorithm to improve the classification accuracy to 50 another study 4 recommended increasing the number of samples for the cov dataset and collecting data from patients within the same geographical area by directly communicating with dedicated hospitals and health agencies 13 11 proposed the use of svm classifier for the binary class problem and conducted an empirical study for multiclass problems in mers-cov 17 recommended the use of the r language because of its efficiency and high functionality in supporting ai algorithms that can enable the development of an effective intelligent medical diagnosis system for cov another study 14 indicated the special medical issues related to the female status such as whether she is pregnant which need to be considered in the treatment of cov-infected patients 15 16 suggested the utilisation of the internet of things iot technology for developing a highly dependable medical diagnosis system for covid-19based on the discussion analysis and details in tables 2 and 3 a case study found in the literature review can be divided into two types namely real and analysis datasets table 4 real datasets consist of a number of real cases of infected and healthy patients within a specific period four studies provided real datasets for patients affected by cov 4 8 11 12 and most datasets in other studies are published and redistributed by the ministry of health website of the kingdom of saudi arabia in analysis datasets standardisation is intended to increase the consistency of review and assessment analysis for mers-cov and sars-cov an organised collection of data is found in four studies for the two viruses in 13 the massive media outlet data were collected during the nationwide outbreak of mers-cov in korea in 2015 in 14 mers-cov cases were recorded from several medical analytical papers focused on the early symptoms of this virus in 15 spike glycol protein sequence data of sars dq4125741 and mers kp2360921 were obtained 16 utilised the gps to represent each mers-cov user on google maps where 5000 users are adopted in r studio through the bnlearn packagetwo attributes namely 1 personal patient information attributes and 2 cov attributes were recognised in the collected studies to explore the effects of cov features and classes on case study datasets used with ml algorithms as shown in table 5 only four studies focused on personal patient information attributes only two studies considered cov attributes and two studies considered the two attributestable 5 shows that the details mostly encompass mers-cov and sars-cov attributes and classes age attribute is considered the most important and dangerous factor in the infected patients because people over the age of 50 are more likely to be at risk and to have this type of virus than others 4 8 12 14 16 gender attribute is an important predictor in four out of eight studies 4 8 11 12 the city was used in three studies 4 8 11 other related attributes are less frequently associated with personal patient information attributes including address sex and name although sob is mentioned in only two studies it is considered the most important concern with mers-cov and sars-cov attributes because the two studies focused on patients affected by the two virusesfrom a specialised medical perspective the features and classes of the cov family are similar to one another in this context the new epidemic of covid-19 depends on the same features and classes of mers-cov and sars-cov thus extensive research has been conducted to prove a new ai pathway as proof for the above discussion several reliable reports and government news have mentioned that age is the most important feature of patients with covid-19 patients over the age of 50 are susceptible to contract the disease and be exposed to its risks and complications the gender and city of an infected patient are the next concerns the medical team has reported that sob is the most important symptom attribute because it carries a high specificity for covid-19this systematic review provided an exhaustive overview of integrated ai based on data mining and ml algorithms with the cov family state-of-the-art cov prediction algorithms were presented distinct information such as application nature ml used the evaluation conducted for each study and extracted features and classes with accuracy percentages for the utilised ml algorithms were indicated a set of propositions for the risk recovery of this virus was established to serve as a guide for future research in the context of data mining algorithms despite the increasing rates of death and the number of people affected with cov developments based on ml algorithms to improve cov datasets remain at a redefinition stage especially for covid-19 the shortage of studies in the literature is a real concern and may have serious implications for detecting and minimising the spread of this virus an emerging rapidly evolving situation for the virus must be considered in the viewpoint of ai applications and researchers should provide updated contributions because they are necessary supportive information such as new datasets must be provided and many complex features and classes must be added close cooperation among researchers in the biomedical engineering field and the medical community is necessary to stop the growing public health threat posed by the 2019 cov the goal is to conduct new studies that can guide governments and communities in the early control of the impact of this virus by utilising the features and classes collected in the literature the need for integrated sensor technologies specifically for outdoor scenarios is highly recommended this process is only possible when the technique is interlinked with iot technologies focusing on evaluating and improving ml algorithms for cov datasets with increased efficiency in this context ai software developers in healthcare can develop different software packages to remotely help analyse the extracted features and classes for patients with covid-19we are currently faced with a potential global epidemic of a new coronavirus that has infected thousands of people in china and is spreading rapidly around the world this week the who has declared it an global emergency who 2020 the wuhan novel coronavirus 2019-ncov has already caused more infections than the previous severe acute respiratory syndrome sars outbreak of 2002 and 2003 the virus is a sars related coronavirus sarsr-cov and it is genetically associated with sarsr-cov strains that infect bats in china zhu et al 2020 lu et al 2020 it causes severe respiratory illness has high fatality rate huang et al 2020 can be transmitted from person to person and has spread to over 15 countries in less than two months who 2020this coronavirus outbreak has been unprecedented so too is the way that the scientific community has responded to it they have openly and rapidly shared genomic and clinical data as never seen before allowing research results to be released almost instantaneously this has helped the understanding of the transmission dynamics the development of rapid diagnostic and has informed public health response here we present a new contribution that can speed up this communal effort the genome detective coronavirus typing tool is a free-of-charge web-based bioinformatics pipeline that can accurately and quickly identify assemble and classify coronaviruses genomes the tool also identifies changes at nucleotides coding regions and proteins using a novel dynamic aligner to allow tracking new viral mutations figure 1a reference dataset of previously published coronavirus whole genome sequences wgs was compiled from the virus pathogen resource vipr database wwwviprbrcorg this dataset consisted of 386 whole genome sequences wgs of nine important coronavirus species these included 132 sequences of severe acute respiratory syndrome related coronavirus sarsr-cov 121 sequences of beta coronavirus 97 sequences of middle east respiratory syndrome related coronavirus mersr-cov 19 sequences of human coronavirus hku1 9 sequences of murine hepatitis virus 4 of rousettus bat coronavirus hku9 3 of rat coronavirus and one wgs of tylonycteris bat coronavirus hku4 zariabatcoronavirus and longquan rl rat coronavirus to this reference dataset we added 47 whole genomes of the current coronavirus 2019 2019-ncov outbreak that originated in wuhan china in december 2019 the 2019-ncov sequences were downloaded from the gisaid database httpswwwgisaidorg together with annotation of its original location collection date and originating and submitting laboratory the 2019-ncov data generators are properly acknowledged in the acknowledgements section of this paper and detailed information is provided in supplementary table 1the 431 reference wgs were aligned with muscle edgar 2004 the alignment was manually edited until a codon alignment was attained in all coding sequences cds a maximum likelihood phylogenetic tree 1000 bootstrap replicates was constructed in phyml guidon  gascuel 2003 lemoine et al 2018 and a bayesian tree using mrbayes ronquist  huelsenbeck 2003 were constructed the trees were visualized in figtree rambaut 2018 we selected 25 reference sequences that represent the diversity of each well-defined phylogenetic cluster with bootstrap support of 100 and posterior probability of 1 we identified five well supported phylogenetic clusters with more than two sequences of sarsr-cov and used them to set up our automated phylogenetic classification tool cluster 1 included sars strains from the 2002 and 2003 asian outbreaks in our tool we named this cluster sars-cov outbreak 2000s but may rename it as sars-a if a new proposed naming system for sarsr-cov is adopted in the near future rambaut 2020 cluster 2 provisionally named as sars related cov includes 7 sequences from bats which did not cause large human outbreaks cluster 3 named as bat sars-covhku3 includes three wgs sampled from rhinolophus sinicus ie chinese rufous horseshoe bats cluster 4 bat sars-cov zxc21zc45 includes two sarsr-cov sampled from rhinolophus sinicus bats in zhoushan china cluster 5 provisionally named as wuhan 2019-ncov which may be renamed as sars-b includes one public sequence from the outbreak in wuhan china we identified this cluster with many sequences from gisaid but kept only this one as this is the only genbank sequence accession number mn908947 which was kindly shared by prof yong-zhen zhang and colleagues in the virologicalorg website detailed information about the phylogenetic reference datasets are available in supplementary table 2the phylogenetic reference dataset was used to create an automated coronavirus typing tool using the genome detective framework vilsker et al 2019 fonseca et al 2019 to determine the accuracy of this tool each of the 431 test wgs was considered for evaluation ie 384 reference sequences from vipr and 47 public 2019-ncov sequences the sensitivity specificity and accuracy of our method was calculated for both species assignment and phylogenetic clustering of sarsr-cov sensitivity was computed by the formula tptpfn specificity by tntnfp and accuracy by tptntpfpfntn where tp  true positives fp  false positives tn  true negatives and fn  false negativesclassifying query sequences in an automated fashion involves two steps the first step enables virus species assignments and the second which is restricted to sarsr-cov includes phylogenetic analysis the first classification analysis subjects a query sequence to blast and aga analysi aga is a novel alignment method for nucleic acid sequences against annotated genomes from ncbi refseq virus database aga deforche 2017 expands the optimal alignment algorithms of smith-waterman smith  waterman 1981 and gotoh gotoh 1982 based on an induction state with additional parameters the result is a more accurate aligner as it takes into account both nucleotide and protein scores and identifies all of the polymorphisms at nucleotide and amino acid levels in the second step a query sequence is aligned against the phylogenetic reference dataset using -add alignment option in the mafft software katoh  standley 2013 in addition a neighbor joining phylogenetic tree is constructed using the hky distance metric with gamma among-site rate variation with 1000 bootstrap replicates using paup swofford the query sequence is assigned to a particular phylogenetic cluster if it clusters monophyletically with that clade or a subset of it with bootstrap support 70 if the bootstrap support is 70 the genotype is reported to be unassignedthe result of the phylogenetic and mutational analysis performed by aga is available in a detailed report this report contains an interactive phylogenetic tree and genome mapper supplementary figure 1 it also presents the virus species and cluster assignments and a detailed table that provides information about open reading frames orfs cds and proteins this table can be expanded to show nucleotide and amino acid mutations that differentiate a query sequence from their species refseq or from a sequence in the phylogenetic reference dataset all results can be exported to a variety of file formats xml csv excel nexus or fastathe genome detective coronavirus typing tool correctly classified all of the 175 sarsr-cov sequences at species level ie specificity sensitivity and accuracy of 100 furthermore all of the 47 2019-ncov wgs that were isolated in china n36 usa n  5 france n2 thailand n2 japan n1 and taiwan n1 were correctly classified at phylogenetic cluster level as 2019-ncov which may be renamed as sars-b in addition we classified with very high specificity sensitivity and accuracy ie 100 all of the 112 sars outbreak wgs of 2002 and 2003 we also achieved perfect classification ie specificity sensitivity and accuracy of 100 for all of beta coronavirus humancoronavirushku1 mers-cov rousettusbatcoronavirushku9 and tylonycterisbatcoronavirushku4 at species level for a detailed overview of assignment performance please refer to the supplementary table 3our tool also allows detailed analysis of coding regions and proteins for each of the coronavirus species for example the analysis of the first released 2019-ncov sequence the whhuman1china2019dec genbank mn908947 demonstrated at genome level the nucleotide nt identity was 790 to the reference strain of sarsr-cov accession nc0047183 and that the envelop small membrane protein protein e is the most similar protein in total 948 7377 of the amino acids were identical the four amino acid differences were located at positions 55 t55s 56 v56f 69 69deletion and 70 g70r the spike protein protein s which can be associated with virulence was 762 identical to the reference strain of sarsr-cov supplementary table 4a interestingly there were four amino acid insertions at position 237 a237f238inshrsy genome nt position 2220222203inscatagaagttat which is just upstream from a cleavage site the most diverse coding regions were the cds sars8a and sars8b in these two regions only 30 of the amino acids were identical sars8b protein was truncated early and its cds had four stop codons supplementary table 4saour coronavirus typing tool also allows a query sequence to be analysed against a sequence in the phylogenetic reference dataset for example the whhuman1china2019dec genbank mn908947 the identity was 875 to the bat sequence batslcovzxc21 genbank mg772934 this was one of the bat-cov sequences that were most related to n2019-cov lu et al 2020 the envelop small membrane protein protein e was 100 identical supplementary table 4b when the 2019-ncov isolated from france betacovfranceidf03732020 was analysed with our tool and compared with the 2019-ncov whhuman1china2019dec strain accession mn908947 this sequence was 999 identical and had only two nt mutations supplementary table 4c these two differences were located on positions 22551gt  26016gt which caused three amino acid mutations e2 glycoprotein protein mutation v354f 22551gt sars3a protein mutations g250v 26016gt and sars3b protein mutations v110f 26016gt detailed in supplementary table 4c-ii the analysis of a wgs in fasta format takes approximately 60 secondswe developed and released the genome detective coronavirus typing tool as a free-of-charge resource in the third week of january 2020 in order to help the rapid characterization of ncov-2019 infections this tool allows the analysis of whole or partial viral genomes within minutes it accepts assembled genomes in fasta format or raw ngs data in fastq format from illumina ion torrent pacbio or oxford nanopore technologies ont can be submitted to the genome detective virus tool vilsker et al 2019 to automatically assemble the consensus genome prior to executing the coronavirus typing tool user effort is minimal and a user can submit multiple fasta sequences at oncethe tool uses a novel and dynamic aligner aga to allow submitted sequences to be queried against reference genomes using both nucleotide and amino acid similarity scores this allows accurate identification of other coronavirus species and the tracking of new viral mutations as the outbreak expands globally it also performs detailed analysis of the coding regions and proteins moreover it can easily be updated to add new phylogenetic clusters if new outbreaks arise or if the classification nomenclature changes the tool has been able to correctly classify all the recently released ncov-2019 genomes as well as all the 20022003 sars outbreak sequencesin conclusion the genome detective coronavirus typing tool is a web-based and user-friendly software application that allows the identification and characterization of novel coronavirus genomesrecent pneumonia outbreak in wuhan china has brought closely into our sight the 2019 novel coronavirus 2019ncov this new coronavirus named 2019ncov belonging to the orthocoronavirinae subfamily distinct from middle east respiratory syndromecoronavirus and severe acute respiratory syndrome coronavirus sarscov was described by zhu et al
1
 the first case of an unexplained new pneumonia origin was detected on 12 december 2019 and was later determined by the chinese center for disease control and prevention cdc as a nonsars ncov the coronaviridae family consists of a group of large single and plus stranded rna viruses isolated from multiple species and it is known to cause the common cold and diarrheal diseases in humans
2
 
3
 in 2003 the sars outbreak was associated with a new coronavirus that is sarscov
2
 
3
 however a number of cases of unknown cause of pneumonia occurred in wuhan hubei china in december 2019 with clinical presentations closely resembling viral pneumonia
4
 a total of 1975 cases of pneumonia have been confirmed in china so far according to the state council information office in beijing chinas capital 26 january 2020
5
 
6
 yet the virus has tended to spread out of china since one case in thailand one case in japan and two cases in korea had been sequentially reported since 15 january 2020
7
 surprisingly the transmission of animals to humans is considered the origin of epidemics as in november many patients reported to have visited a local fish and wild animal market in wuhan apart from this recently evidence has been gathered for the animal to the human and interhuman transmission of the virus
6
 
8
 the situation is getting serious day by day and for further prevention and control it is imperative that we have a better understanding of its pandemic nature on 30 january 2020 world health organization who declared that covid19 outbreak as the sixth public health emergency of international concern following h1n1 2009 polio 2014 ebola in west africa 2014 zika 2016 and ebola in the democratic republic of congo 2019
9
 meanwhile on 11 february 2020 the who announced a new name for the epidemic disease caused by 2019ncov coronavirus disease covid19 until 24 february 2020 2019ncov has affected more than 79 331 patients in 29 countriesregions and has become a major global health concern on the basis of situational report35 by who china has confirmed 77 262 cases with 2595 deaths reported until 24 february 2020 however the rest of the world has confirmed 2069 cases 300 new cases with 23 deaths reported so far till now china reported 415 new confirmed cases with 150 new deaths in comparison there were 300 new confirmed cases reported outside of china with the number of new deaths being 6 httpswwwwhointdocsdefault-sourcecoronavirusesituation-reports20200224-sitrep-35-covid-19pdfsfvrsn1ac4218d2 with regard to the virus itself the international committee on virus taxonomy has renamed 2019ncov as sarscov2
10
 as the outbreak of the novel sarscov2 is expanding rapidly in china and beyond threatening to become a global pandemic epidemiological data need to be analyzed in a way so that the exploratory data analysis eda methods and visualization model will increase the situational awareness among the mass community in upcoming days health workers governments and the public therefore need to cooperate globally to prevent its spreadfor this study various sources of the dataset have been used for our analysis and visualizations mainly we have used three different sources of dataset including 2019 coronavirus dataset januaryfebruary 2020 which tracks the spread of 2019ncov covid19 ncov19 coronavirus spread dataset which consists of number of confirmed death and recovered reported and 2019ncov dataset which handles the day level information on 2019ncov affected cases table 1 provides insight on each dataset and their respective data files with their column description moreover we also developed table 2 for providing the data analyst with a comprehensive knowledge of every column for the used dataset we have enlisted each distinguished column from all three different sources of the dataset and assemble it according to their appearances in the datasetwe analyzed our datasets with different eda methods and visualize those data to provide a sufficient consciousness regarding the outbreak of covid19 all over the globe our exploit data performed with the 2019 coronavirus dataset januaryfebruary 2020 covid19 ncov19 coronavirus spread dataset and 2019ncov datasets here we present an effort to visualize and analyze data between 22 january 2020 and 16 february 2020 however a massive number of cases are reported in china compared to the rest of the world and interestingly the next few affected countries are the neighbors of china moreover even in china most of the cases reported are from a particular province hubei it is no surprise because hubeis capital is wuhan where the first cases are reported till now covid19 propagated almost 29 countries worldwide and 31 states or provinces in china outside china as expected there was not much death due to covid19 recorded only five deaths outside china are reported until 16 february 2020 there are however more cases of recovered than death and in comparison with 1770 deaths there were recovery cases of 10 865 patients we also provide a map representation of different countries with confirmed cases and death reported respectively till 16 february 2020 based on their longitude and latitude we have enlisted all 29 affected countries outside china and the number of confirmed cases of different chinese provinces for providing a vibrant depiction of this intense sarscov2 table 3this section will discuss different timeseries data by using some visual exploratory data analysis veda methods we designed a worldwide map and provides a knowledge of how sarscov2 spread from 22 january 2020 to 16 february 2020 all around the globe each map segment represents a region by using visual data analytics it helps the individuals to understand the epidemiological nature of covid19 from the map representation it is apparent that china reported the highest confirmed cases with a high number of 70 446 likewise china reported the highest number of death and it was 1765 till 16 february 2020 we also examine the timeseries data using veda to provide a strong and understandable outcome of this extreme outbreak of covid19 it is obvious that analyzing these data in realtime is extremely useful in capturing an epidemic behavior of this severe disease we believe this method of analyzing data will certainly increase the understanding of the situation and inform interventions all the data analysis and visualization models that we have analyzed for this study including eda and veda are available at this url httpsamratdeymevisualizationhtmlthis study analyzed three different categories of data including confirmed death and recovered cases inside china for a time period of 22 january to 16 february 2020 this will also provide a comparative analysis of all the cases reported inside and outside of china however we present different cases worldwide to comprehend the specific numbers of cases reported for a specific time period after analyzing there were 58 182 confirmed cases of covid19 on 16 february 2020 however the highest number of deaths reported in china on 16 february 2020 was 1696 surprisingly there was a significant number of recovered cases reported till 16 february 2020 and it was around 6639 figure 1another investigation on different cases of covid19 including confirmed death and recovered reported outside china also provided in this study this also contains three different data representations of confirmed death and recovered cases outside china for a time period of 22 january 2020 to 16 february 2020 after analyzing the data there were 399 confirmed cases of covid19 on 16 february 2020 globally however the highest number of deaths reported outside china on 16 february 2020 was 5 surprisingly there was also a significant number of recovered cases till 16 february 2020 and it is more than 100 according to the dataset we examined figure 2table 3 represents all the confirmed cases reported in china provinces between 22 january 2020 to 16 february 2020 for a better understanding of the scenario we designed a tree map and visualize the data according to different criteria our designed tree map contains all the provinces that confirmed the presence of sarscov2 patients in china according to the tree map it is evident that hubei province reported the highest number of confirmed cases and the number was 58 182 the next province is guangdong with most 1316 confirmed cases reported alternately we also visualize the tree map for the number of deaths and recovered cases reported between 22 january 2020 to 16 february 2020 the highest number of deaths reported in hubei province in china the greatest number of deaths reported in hubei was 1696 till 16 february 2020 and the next highest number found in henan with 13 deaths reported till the mentioned date however 6639 successful recovered cases were reported in hubei and 465 were in guangdong and 464 were in hunan table 3 moreover a tree map representation for all the countries that have reported confirmed deaths and recovered cases globally except china also provided in this exploration singapore reported the highest number of confirmed cases of covid19 immediately after china with a number of 75 and japan with a confirmed case of 59 is in the next position after singapore in terms of deaths reported globally except china all the five countries france japan hong kong taiwan and the philippines reported one death case between 22 january 2020 to 16 february 2020 table 3 however singapore reported the highest number of recovered cases of 2019ncov with a number of 18 and thailand with a recovered case of 14 is in the next position after singapore in terms of recoveryfigure 3 enlists the data of comparative analysis confirmed  c recovered  r and deaths  d of hubei other provinces of china and the rest of the world till 16 february 2020 this representation demonstrates that hubei has endured the largest number of infected patients c  58 182 however hubei has also maintained a significant recovery rate of r  6639 patients along with the mortalities of d  1969 persons on the other hand rest of the provinces in china has confirmed c  12 264 patients infected by sarscov2 virus till 16 february 2020 like hubei other provinces in china also showed a dramatic recovery rate of r  4109 patients along with confirmed deaths of d  69 persons as of 16 february 2020 data from the different sources showed that there was a total of c  425 confirmed cases of covid19 worldwide among them only five deaths have been reported globally with a steady recovery rate of r  117 patients from the observation it is apparent that there has been a steady rise in the daily total number of covid19 cases globally both within and outside china till 16 february 2020 regarding new cases of covid19 till 24 february 2020 both within and outside china there has been a dramatic increase in the number of new cases it was reported that china has confirmed n  41577 262 confirmed new cases while the rest of the world has confirmed n  3002069 confirmed caused by the sarscov2 virusanother example of the importance of animalhuman interface infections is the current outbreak of the covid19 disease and the issues resulting from the advent of a newly identified organism as it spreads through individuals and across national and international frontiers at the advent of an outbreak such as this readily available data and information are equally important to begin the evaluation needed to understand the risks and start containment outbreak activities such information includes initial reports of countries with confirmed death and recovered cases ratio also how the countries outside china are affecting how the province of china are struggling to handle the situation of covid19 and more importantly ratio analysis of these realworld data as well as information obtained from specific regions of globally from past outbreaks information and understanding of the consequences are needed to help us to refine the risk assessment as the outbreak continues and to ensure that patients are best managed much of this information emerges in realtime challenges our understanding and yet refines our responses the analysis presented here based on eda and veda with the help of the dataset provided by john hopkins university who cdc national health commission and dxy however we have preprocessed and cleaned the dataset information according to our needs for storing and analyzing the data we have used the pythonbased library of numpy httpsnumpyorg and pandas httpspandaspydataorg matplotlib httpsmatplotliborg plotly httpsplotly seaborn httpsseabornpydataorg and folium were also used to visualize the highlighted data in an interactive manner all the experiment with the dataset has been made by using the support of jupyter notebook httpsjupyterorg in a linux based local machine platform by using python language in the machine learning research lab at the dhaka international university we report here each and every single detail of different cases of covid19 between 22 january 2020 to 16 february 2020 currently there is an obvious urgency to understand the consequences of sarscov2 viruses not only in china but also worldwide to aware of ourselves for upcoming days therefore this is a minor initiative of analyzing realworld timeseries data and visualize them in such a manner so that people around the globe have better understandings of its severe nature we are still observing the undesirable prevalence of this sarscov2 virus and to date 24 february 2020 the number of death cases reported was 2618 and among them only 23 death cases reported outside china this is extremely alarming not only to china but to the rest of the world as well in this study we have enlisted the most reported cases in china outside china and in different provinces in china we also analyzed the number of affected countries with reported confirmed deaths and recovered cases apart from that we designed map view and tree maps view with an appropriate number to analyze the epidemiological outbreak of the covid19in conclusion the dataset we have used for our experiment 2019 coronavirus dataset januaryfebruary 2020 covid19 ncov19 coronavirus spread dataset and 2019ncov dataset can be useful to monitor the emerging outbreaks such as 2019ncov such activities can help us to generate and disseminate detailed information to the scientific community especially in the early stages of an outbreak when there is a little else available allowing for independent assessments of key parameters that influence interventions we observe an interesting different case reported based on the different datasets of 2019ncov which helps us to understand that it needs more epidemiological and serological studies we also investigated early indications that the response is being strengthened in china and worldwide on the basis of a decrease in the case of detection time and rapid management of internationally identified travelrelated cases as a caveat this is an early data analysis and visualization approach of a situation that is rapidly evolving to the best of our knowledge this is the very first attempt on covid19 which focuses on the veda based on different data sources however knowledge about this novel sarscov2 virus remains limited among general people around the globe raw data released by various sources are not adequately capable to provide an informative understanding of covid19 caused of sarscov2 therefore a userfriendly data visualization model will be more effective to understand the epidemic outbreak of this severe disease visualization model like map view and tree map view provides an interactive interface and visualize each and every raw fact in a comprehensive manner hopefully in the coming weeks we will continue to monitor this outbreaks epidemiology data that we have used in this study and from other official sourcesthe authors declare that there are no conflict of interestsskd and mdmr had the idea for and designed the study and had full access to all the data in the study and take the responsibility for the data and accuracy of the data analysis with their visualization urs and ah contributed to the writing of the study mdmr contributed to critical revision of the report all the visualization and data presentation methods were developed by skd and mdmr all authors contributed to data acquisition data analysis and reviewed and approved the final versionwe are currently faced with a potential global epidemic of a new coronavirus that has infected thousands of people in china and is spreading rapidly around the world in the end of january 2020 the who has declared it a global emergency who 2020 the novel coronavirus sars-cov-2 first isolated in wuhan china has already caused more infections than the previous severe acute respiratory syndrome sars outbreak of 2002 and 2003 the virus is a sars-related coronavirus sarsr-cov and it is genetically associated with sarsr-cov strains that infect bats in china lu et al 2020 zhu et al 2020 it causes severe respiratory illness which the who recently named covid-19 disease it has high fatality rate huang et al 2020 can be transmitted from person to person has infected over 70 000 individuals and has spread to over 30 countries in less than 2 months who 2020this coronavirus outbreak has been unprecedented so too is the way that the scientific community has responded to it they have openly and rapidly shared genomic and clinical data as never seen before allowing research results to be released almost instantaneously this has helped the understanding of the transmission dynamics the development of rapid diagnostic and has informed public health response here we present a new contribution that can speed up this communal effort the genome detective coronavirus typing tool is a free-of-charge web-based bioinformatics pipeline that can accurately and quickly identify assemble and classify coronaviruses genomes the tool also identifies changes at nucleotides coding regions and proteins using a novel dynamic aligner to allow tracking new viral mutations fig 1a reference dataset of previously published coronavirus whole-genome sequences wgs was compiled from the virus pathogen resource vipr database wwwviprbrcorg this dataset consisted of 386 wgs of nine important coronavirus species these included 132 sequences of severe acute respiratory syndrome related coronavirus sarsr-cov 121 sequences of beta coronavirus 97 sequences of middle east respiratory syndrome related coronavirus mersr-cov 19 sequences of human coronavirus hku1 9 sequences of murine hepatitis virus 4 of rousettus bat coronavirus hku9 3 of rat coronavirus and 1 wgs of tylonycteris bat coronavirus hku4 zariabatcoronavirus and longquan rl rat coronavirus to this reference dataset we added 47 whole genomes of the current coronavirus 2019 sars-cov-2 outbreak that originated in wuhan china in december 2019 the sars-cov-2 sequences were downloaded from the gisaid database httpswwwgisaidorg together with annotation of its original location collection date and originating and submitting laboratory the sars-cov-2 data generators are properly acknowledged in the acknowledgements section of this article and detailed information is provided in supplementary table s1the 431 reference wgs were aligned with muscle edgar 2004 the alignment was manually edited until a codon alignment was attained in all coding sequences cds a maximum likelihood phylogenetic tree 1000 bootstrap replicates were constructed in phyml guindon and gascuel 2003 lemoine et al 2018 and a bayesian tree using mrbayes ronquist and huelsenbeck 2003 were constructed the trees were visualized in figtree rambaut 2018 we selected 25 reference sequences that represent the diversity of each well-defined phylogenetic cluster with bootstrap support of 100 and posterior probability of 1 we identified five well-supported phylogenetic clusters with more than two sequences of sarsr-cov and used them to set up our automated phylogenetic classification tool cluster 1 included sars strains from the 2002 and 2003 asian outbreaks in our tool we named this cluster sars-cov outbreak 2000s but may rename it as sars-cov-1 if a new proposed naming system for sarsr-cov is adopted in the near future cluster 2 provisionally named as sars related cov includes seven sequences from bats which did not cause large human outbreaks cluster 3 named as bat sars-cov hku3 includes three wgs sampled from rhinolophus sinicus ie chinese rufous horseshoe bats cluster 4 bat sars-cov zxc21zc45 includes two sarsr-cov sampled from rhinolophus sinicus bats in zhoushan china cluster 5 virus named sars-cov-2 by the ictv committee and disease named covid-19 by the who includes three public sequences from the outbreak we identified this cluster with many sequences from gisaid but kept only three ones as these were the first genbank sequences the first whole genome of sars-cov-2 was kindly shared by prof yong-zhen zhang and colleagues in the virologicalorg website detailed information about the phylogenetic reference datasets is available in supplementary table s2the phylogenetic reference dataset was used to create an automated coronavirus typing tool using the genome detective framework fonseca et al 2019 vilsker et al 2019 to determine the accuracy of this tool each of the 431 test wgs was considered for evaluation ie 384 reference sequences from vipr and 47 public sars-cov-2 sequences the sensitivity specificity and accuracy of our method were calculated for both species assignment and phylogenetic clustering of sarsr-cov sensitivity was computed by the formula tptpfn specificity by tntnfp and accuracy by tptntpfpfntn where tp  true positives fp  false positives tn  true negatives and fn  false negativesclassifying query sequences in an automated fashion involves two steps the first step enables virus species assignments and the second which is restricted to sarsr-cov includes phylogenetic analysis the first classification analysis subjects a query sequence to blast and aga analysis aga is a novel alignment method for nucleic acid sequences against annotated genomes from ncbi refseq virus database aga deforche 2017 expands the optimal alignment algorithms of smith and waterman 1981 and gotoh 1982 based on an induction state with additional parameters the result is a more accurate aligner as it takes into account both nucleotide and protein scores and identifies all of the polymorphisms at nucleotide and amino acid levels in the second step a query sequence is aligned against the phylogenetic reference dataset using -add alignment option in the mafft software katoh and standley 2013 in addition a neighbor-joining phylogenetic tree is constructed using the hky distance metric with gamma among-site rate variation with 1000 bootstrap replicates using paup swofford 2003 the query sequence is assigned to a particular phylogenetic cluster if it clusters monophyletically with that clade or a subset of it with bootstrap support 70 if the bootstrap support is 70 the genotype is reported to be unassignedthe result of the phylogenetic and mutational analysis performed by aga is available in a detailed report this report contains an interactive phylogenetic tree and genome mapper supplementary fig s1 it also presents the virus species and cluster assignments and a detailed table that provides information about open reading frames orfs cds and proteins this table can be expanded to show nucleotide and amino acid mutations that differentiate a query sequence from their species refseq or from a sequence in the phylogenetic reference dataset all results can be exported to a variety of file formats xml csv excel nexus or fastathe genome detective coronavirus typing tool correctly classified all of the 175 sarsr-cov sequences at species level ie specificity sensitivity and accuracy of 100 furthermore all of the 47 sars-cov-2 wgs that were isolated in china n  36 usa n  5 france n  2 thailand n  2 japan n  1 and taiwan n  1 were correctly classified at phylogenetic cluster level as sars-cov-2 which may be renamed as sars-b in addition we classified with very high specificity sensitivity and accuracy ie 100 all of the 112 sars outbreak wgs of 2002 and 2003 we also achieved perfect classification ie specificity sensitivity and accuracy of 100 for all of beta coronavirus humancoronavirushku1 mers-cov rousettus bat coronavirus hku9 and tylonycterisbatcoronavirushku4 at species level for a detailed overview of assignment performance please refer to the supplementary table s3our tool also allows detailed analysis of coding regions and proteins for each of the coronavirus species for example the analysis of the first released sars-cov-2 sequence the whhuman1china2019dec genbank mn908947 demonstrated at genome level the nucleotide nt identity was 790 to the reference strain of sarsr-cov accession nc0047183 and that the envelop small membrane protein protein e is the most similar protein in total 948 7377 of the amino acids were identical the four amino acid differences were located at positions 55 t55s 56 v56f 69 69deletion and 70 g70r the spike protein protein s which can be associated with virulence was 762 identical to the reference strain of sarsr-cov supplementary table s4a interestingly there were four amino acid insertions at position 237 a237f238inshrsy genome nt position 2220222203inscatagaagttat which is just upstream from a cleavage site there is also a four amino acid insertion prra at the spike protein at positions 681 to 684 this is at the junction of s1 and s2 and creates a new polybase cleavage site our tool also allows us to compare mutations with other-related sequences such as the pangolin bat ratg13 the bat sars-cov and sars sin940 figure 2 and supplementary table s2 the most diverse coding regions were the cds sars8a and sars8b in these two regions only 30 of the amino acids were identical sars8b protein was truncated early and its cds had four stop codons supplementary table s4aour coronavirus typing tool also allows a query sequence to be analyzed against a sequence in the phylogenetic reference dataset for example the whhuman1china2019dec genbank mn908947 the identity was 875 to the bat sequence batslcovzxc21 genbank mg772934 this was one of the bat-cov sequences that were most related to n2019-cov lu et al 2020 the envelop small membrane protein protein e was 100 identical supplementary table s4b when the sars-cov-2 isolated from france betacovfranceidf03732020 was analyzed with our tool and compared with the sars-cov-2 whhuman1china2019dec strain accession mn908947 this sequence was 999 identical and had only two nt mutations supplementary table s4c these two differences were located on positions 22551gt and 26016gt which caused three amino acid mutations e2 glycoprotein protein mutation v354f 22551gt sars3a protein mutations g250v 26016gt and sars3b protein mutations v110f 26016gt detailed in supplementary table s4c-ii the analysis of a wgs in fasta format takes approximately 60 swe developed and released the genome detective coronavirus typing tool as a free-of-charge resource in the third week of january 2020 in order to help the rapid characterization of covid-19 infections this tool allows the analysis of whole or partial viral genomes within minutes it accepts assembled genomes in fasta format or raw next-generation sequencing data in fastq format from illumina ion torrent pacbio or oxford nanopore technologies ont can be submitted to the genome detective virus tool vilsker et al 2019 to automatically assemble the consensus genome prior to executing the coronavirus typing tool user effort is minimal and a user can submit multiple fasta sequences at oncethe tool uses a novel and dynamic aligner aga to allow submitted sequences to be queried against reference genomes using both nucleotide and amino acid similarity scores this allows accurate identification of other coronavirus species and the tracking of new viral mutations as the outbreak expands globally it also performs detailed analysis of the coding regions and proteins moreover it can easily be updated to add new phylogenetic clusters if new outbreaks arise or if the classification nomenclature changes the tool has been able to correctly classify all the recently released sars-cov-2 genomes as well as all the 20022003 sars outbreak sequencesin conclusion the genome detective coronavirus typing tool is a web-based and user-friendly software application that allows the identification and characterization of novel coronavirus genomesthe 2019 novel coronavirus disease covid-19 is highly infectious 1 2 outbreak of which has been announced as a global pandemic by the world health organization on 11 march 2020 the pathogen contributed to covid-19 is severe acute respiratory syndrome coronavirus 2sars-cov-2 a sister of sars-cov 3 4 as showed by the center for systems science and engineering at johns hopkins university latest updated at 05202020 the global cumulative number of confirmed cases has reached 5019609 with 1983479 cured cases and 325855 deaths 5 however there were currently no effective drugs and vaccines against sars-cov-2 which was partly limited by the lack of recognition of the mechanism of sars-cov-2 infection previous studies had reported that sars-cov-2 used angiotensin-converting enzyme 2ace2 as the host receptor but not other coronavirus receptors such as aminopeptidase n and dipeptidyl peptidase 4 3 6 the rna binding domain of sars-cov-2 spike protein binds to ace2 with a 20-30-fold higher affinity than sars-cov 6-9 which may contribute to the rapid transmission of covid-19 therefore the distribution of ace2 in human tissues may indicate the susceptibility of different human organs to sars-cov-2 infection 10 some studies explored the heterogeneity of ace2 expression in specific tissue at the single-cell level 10-13 also there were several studies using transcriptome data to analyze the distribution of ace2 mrna in human tissues 14-17 however all these researches only analyzed the mrna level of ace2 while failed to determine the distribution of ace2 protein indeed given the complex composition of a tissue the result of single-cell rna-sequencing also cannot reflect the average abundance of ace2 in the whole tissues further ace2 is a membrane and secreted protein while the abundance of ace2 in blood and common blood cells remains uncertainto obtain the accurate distribution of ace2 in human tissues we comprehensively investigated the level of ace2 mrna and protein across human tissues and blood using public transcriptome datasets mass spectrum-based tissues proteomic and secretome and antibody-based immunochemistry ihc our study would have implications for understanding the transmission routes of sars-cov-2 as well as the pathogenesis and future treatment for sars-cov-2to comprehensively investigate the mrna expression of ace2 in human tissues we collected the transcriptome datasets in three public databases including the tissue atlas of human protein atlas hpa genotype-tissue expression gtex and functional annotation of mammalian genomes 5 fantom5 cap analysis of gene expression cage 18-22 these data were separately analyzed according to the description in materials and methods given the samples of each tissue maybe come from the different individuals all rna-seq tissue data were present as mean protein-coding transcripts per million ptpm corresponding to mean values of the different individual samples from each tissue as indicated by the result of hpa ace2 mrna can be virtually detected in many tissues figure 1a the top 10 tissues with the highest abundance of ace2 mrna are small intestine ptpm 3663 duodenum 2645 gallbladder 1346 testis 1200 kidney 1072 heart muscle 311 colon 141 rectum 90 seminal vesicle 70 and thyroid gland 58 figure 1a most belonged to gastrointestinal tract-associated tissues or organs including the small intestine duodenum colon and rectum several were male reproductive system-associated organs including testis and seminal vesicle in accordance with the findings of previous publication 16 as showed by the result of gtex rna-seq data the top 10 tissue with the highest abundance of ace2 mrna were small intestine ptpm552 testis 367 adipose tissue 88 thyroid gland 70 kidney 68 heart muscle 65 colon 56 breast 44 ovary 24 salivary gland 18 and esophagus 18 figure 1b consistent with the result of hpa a relatively high abundance of ace2 mrna was observed in gastrointestinal tract-associated organs ie small intestine and colon the breast and female reproduction system-associated organs including breast and ovary also rank in the top 10 which is distinct from hpa figure 1b the vagina also expressed a low level of ace2 mrna with a ptpm of 14 which was close to the salivary gland and esophagus figure 1b the mrna expression of ace2 in tissue obtained from the fantom5 project was reported as scaled tags per million the top 10 tissue with the highest abundance of ace2 mrna in fantom5 project included small intestine scaled tags per million 4209 colon 1973 testis 923 gallbladder 526 heart muscle 316 kidney 315 thyroid gland 167 epididymis 102 ductus deferens 65 and adipose tissue 56 figure 1c of note despite small intestine and colon rank in top2 tissues with the highest abundance of ace2 mrna the male reproduction system-associated organs also occupied three of ten ie testis epididymis and ductus deferens figure 1c given the minor difference between these three data sets we analyzed the overlapped tissues among them using a venn diagram as demonstrated by the venn diagram there were six overlapped tissues with the top10 highest abundance of ace mrna including testis kidney heart muscle colon and thyroid gland figure 1dgiven the level of ace2 mrna cannot represent the abundance of a functional protein we investigated the distribution of ace2 protein in human tissues through analyzing the immunohistochemistry data from normal tissue in hpa and the public mass spectrometry ms-based proteomics data in human integrated protein expression database hiped the antibody-based protein profiles were analyzed by hpa which based on basic annotation and knowledge-based annotation to describe the rough relative abundance of ace2 proteins in various tissues detailed information can be obtained from the materials and methods as indicated by the quantitative result of immunohistochemistry there was a high abundance of ace2 protein in five tissues including the small intestine duodenum gallbladder kidney and testis figure 2a by contrast the adrenal gland colon rectum and seminal vesicle expressed a low level of ace2 protein figure 2a moreover ace2 protein was not detected in other tissues including the cerebral cortex cerebellum hippocampus caudate thyroid gland nasopharynx bronchus lung oral mucosa salivary gland esophagus stomach liver pancreas and urinary bladder etal based on the rough quantitative result of immunohistochemistry figure 2a next we analyzed the distribution of ace2 protein in human tissues using the ms-based proteomics dataset in hiped the level of ace2 protein was calculated based on the spectral counts the quantitative results suggested that the ace2 protein was enriched in the ovary log10ppm 22 urine 20 pancreatic juice 19 gut fetal 10 kidney 08 testis 07 heart 03 pancreas 03 placenta -03 heart fetal -07 and gallbladder -10 which were ordered by the abundance of ace2 protein figure 2b in particular ace2 protein was positively differentially expressed in that entity in the ovary urine and pancreatic juice as defined by the quantitative result in hiped figure 2b however the unique peptides of ace2 protein cannot be tested in both the fetal ovary and testis figure 2b moreover the ace2 protein also tested negative in human common blood cells including monocyte neutrophil b-lymphocyte t-lymphocyte cd4 t-cells cd8 t-cells nk cells and peripheral blood mononuclear cells figure 2bgive ace2 is a membrane and secreted protein we analyzed the level of ace2 mrna in the common blood cells using the public transcriptome data for the common human blood cells sorted by the flow cytometry in hpa blood atlas 23 24 consistent with the proteomic data for ace2 protein ace2 mrna was also tested negative in virtually all blood cells including the basophil eosinophil neutrophil classical monocyte non-classical monocyte intermediate monocyte regulatory t-cells memory cd4 t-cell naive cd4 t-cell memory cd8 t-cell naive cd8 t-cell memory b-cell naive b-cell nk cell and total pbmc et al as indicated by the quantitative results figure 3a indeed such results were further supported by the transcriptome in other different databases including monaco scaled dataset and schmiedel dataset 25 26
supplement figure 1 we also obtained the abundance of ace2 protein from human blood using ms-based proteomics in peptideatlas 27-29 and proximity extension assays-based protein profiling in hpa blood atlas 23 24 based on the spectral counts of ms-based proteomics in the peptideatlas the concentration of ace2 protein in plasma approximately reached to 85 ngl figure 3b further as showed by the quantity results of proximity extension assays-based protein profiling the average concentration of ace2 protein in plasma from male showed a minor higher than those from female across four visits during one year figure 3cwith the global outbreak of covid-19 the development of the drugs against sars-cov-2 had become an urgent work accomplishment of the virus life cycle largely depends on host factors therefore targeting the virus-host interactions and host cellular mechanisms are promising treatment options 30 on the theory the agents with the ability to target any step in the virus life cycle can be designed as antiviral drugs cell entry is the first step of cross-species transmission of the virus of which for sars-cov-2 was mediated by the spike proteins on its surface to bind to the ace2 receptor 3 6-9 based on the strategy of targeting ace2 several scientists have screened potential anti-sars-cov-2 drugs 31 32 therefore the comprehensive investigation of ace2 expression in human tissues has implications for understanding the transmission routes of sars-cov-2 and the development of anti-covid-19 drugs previous studies had investigated the distribution of ace2 mrna in human tissues and explored the expression heterogeneity among specific tissue using single-cell rna-sequencing but with a limited size of samples and a lack of determining the protein level of ace2 10-17 however given the great heterogeneity among humans the transcriptome and proteomic dataset with a larger number of samples and a wider range of tissues such as blood cells should be collected to analyze indeed a prior deep proteome and transcriptome of 29 healthy human tissues suggested a strong difference between mrna and protein quantities and that protein expression was often more stable across tissues than that of transcripts 33 therefore protein is a more accurate indicator than the mrna of reflecting the abundance of ace2 in this study we made a comprehensive investigation of the mrna and protein expression of ace2 in human tissues using public transcriptome proteomic datasets and antibody-based protein profiles given blood immune cells are also crucial for combating virus infection we analyzed the expression of ace2 mrna and protein in common blood cells and plasmadespite all these databases utilized in this study based on rna-seq there is a minor difference among the transcriptome result obtained from different databases which may be caused by tissue source technical artifacts inherent in the respective methodologies and gene model annotation issues among them in detail the rna data in hap based on surgically removed tissues18 while those in gtex based on postmortem samples 19 20 moreover the mrna without polyadenylation tails are excluded in hpa leading to the absence of many histone genes while which are present in the fantom further the cap analysis gene expression peaks mapping more than 500 base pairs from the transcription start site are absent in the fantom also the peaks mapping more than one location on the genome are removed from fantom 34of note we found that the lung expresses a low level of ace2 in both mrna and protein which seems to be controversial with the lung as the main tissue with the typical symptoms in response to sars-cov-2 infection such a result can be explained by several reasons as follows specifically and in particular as revealed by prior single-cell rna-sequencing ace2 expression positive is only observed in a small population approximately 1 of type ii alveolar cells while the remaining cell population in lung express a low level of ace2 10 11 which supported previous immunohistochemistry 35 however sars-cov-2 infection remarkably induces the expression of ace2 as an interferon-stimulated gene in human airway epithelial cells 36 37 therefore the type ii alveolar cells would represent a basic target of sars-cov-2 in the lung the infection of sars-cov-2 in type ii alveolar cells upregulates the level of ace2 in the lung and thereby further facilitates the infection of sars-cov-2 indeed we also cannot exclude the possibility that sars-cov-2 used other unknown factors as a receptor that may be highly expressed in lung especially given that previous study had revealed that both tmprss2 and cd147 also partly mediated the cell entry of sars-cov-2 32 38 also a host restriction factor that lowly expressed in the lung for sars-cov-2 cell entry needs to be considered indeed in accordance with previous research 39 we noted that a549 lung alveolar cells expressed a low level as indicated by hpa cell atlas data not show implying the cell line is not an ideal model to study sars-cov-2 in vitro the in vitro model of sars-cov-2 infection should be established using a549 with exogenous ace2 or other primary lung-derived cells such as normal human bronchial epithelial cells 39both testis and kidney tissues expressed a high level of ace2 mrna and protein which is consistent with previous publications 13 16 such results may explain the damage of testis and the impairment of male gonadal function caused by sars-cov-2 40 moreover both antibody-based ihc and tissue transcriptome data also showed a high abundance of ace2 in the small intestine which is supported by a single-cell transcriptome of revealing that the digestive system may be an important route of sars-cov-2 transmission 12 the high expression level of ace2 in the gastrointestinal tract may explain why most of covid-19 patients show gastrointestinal symptoms in the early stage of the infection 41 however the proteomic data of the small intestine is not available in the hiped by contrast some tissues harbor with a high abundance of ace2 mrna but show a low level of ace2 protein for example ace2 mrna can be detected in the bladder which is consistent with a previous study 13 while no ace2 protein was observed in urinary bladder as indicated by the quantitative result of proteomic data and antibody-based ihc given there was a divergence toward the potential of intrauterine vertical transmission in women who develop covid-19 pneumonia during pregnancy 42-44 we also paid attention to the expression of ace2 in the female reproduction-associated tissues of note the quantitative result of transcriptome supported that ovary virtually did not express ace2 while ovary was the organ with the highest level of ace2 protein as indicated by the proteomic data the placenta also expressed a high level of ace2 protein based on these results the intrauterine vertical transmission potential of sars-cov-2 cannot be underestimated despite uterus was tested negative for ace2 proteinof note all the transcriptome in different database revealed no ace2 mrna and protein in the common blood cells including basophil eosinophil neutrophil classical monocytes non-classical monocyte treg gd-t cell mait t-cell memory cd4 t-cell nave cd4 t-cell memory b-cell nave b-cell plasmacytoid dc myeloid dc nk cell and total pbmc suggesting the potential of resistance of immune cell against sars-cov-2 however these results did not suggest that viral particles cannot survival from blood because the public human secretome suggested the concentration of ace2 protein in plasma is approximately 85 ngl indeed according to the description in the latest new coronavirus pneumonia prevention and control program published by the national health commission of china the nucleotides of sars-cov-2 can be tested from the blood sample of patients sars-cov-2 infection also caused a remodeling myeloid in severe covid-19 patients 45 interestingly a prior study reported that covid-19 susceptibility seems to be related to blood group whereas whether such results are associated with the level of ace2 remains uncertain 46 further although our result found that there was virtually no ace2 mrna and protein in the central nervous system cns including the cerebral cortex brain cerebrospinal fluid and cerebellum the possibility of cns infection of sars-cov-2 cannot be neglected indeed accumulating evidence supported the neuroinvasive potential of sars-cov2 47 48 there are also several studies have shown that ace2 enzymatic activity can be detected in human brain tissue and csf samples 49 indicating that ace2 is expressed and functional in the cns of humans the way the tissue is fixed or processed can affect the result of ihc or proteomics of these databases specifically there is no need for an autopsy to study human blood by contrast unlike the data from blood cells for tissue like brain it required autopsy studyin summary our study reveals that the tissue distribution of ace2 mrna and protein might differ and their correlation is complex however our study was limited by only analyzed public datasets with a lack of confirmation by experiments nevertheless our study would be beneficial for understanding the risk of different human organs vulnerable to sars-cov-2 infectionto obtain the comprehensive information regarding the transcriptome of human tissues we collected the transcriptome from three public databases including the human protein atlas hpa tissues atlas genotype-tissue expression gtex project and functional annotation of mammalian genomes 5 fantom5 project all these databases update irregularly and the version of them we analyzed is the latest in detail the hpa shows the expression of human proteins across tissues and organs based on deep rna-sequencing from 37 major different normal tissue types 18 the mrna data in the hpa tissue atlas provide quantitative data on the average gene expression within an entire tissue to estimate the transcript abundance of each protein-coding gene the hpa integrates rna and protein expression data corresponding to approximately 80 of the human protein-coding genes with access to the primary data for both the rna and the protein analysis on an individual gene level the gtex project includes genotype data from approximately 714 donors and 11688 rna-seq samples across 53 tissues 19 20 rna-seq data from 36 of their tissue types were mapped based on rsemv1222 v7 and the resulting tpm values have been included in hpa for all corresponding genes both hpa and gtex rna-seq tissue of the protein-coding gene is reported as mean ptpm protein-coding transcripts per million corresponding to mean values of the different individual samples from each tissue the fantom5 project provides comprehensive expression profiles using cap analysis of gene expression cage 21 22 which is based on a series of full-length cdna technologies developed in riken cage data for 60 of their tissues were obtained from the fantom5 repository and mapped to ensembl the normalized tags per million for each gene were calculated in hpathe hpa tissue atlas shows the expression of human proteins across tissues and organs based on immunohistochemistry on tissue microarrays containing 44 different tissues 18 50 annotated protein expression profiles were obtained by single antibodies or independent antibodies two or more independent antibodies with non-overlapping epitopes on the same protein for independent antibodies the immunohistochemical data from all the different antibodies were taken into consideration to obtain a comprehensive overview of protein expression patterns in normal human tissues the basic annotation was combined with knowledge-based annotation to determine the rough relative abundance of proteins in these tissues as calculated by hpa tissue atlas basic annotation parameters include an evaluation of i staining intensity negative weak moderate or strong ii fraction of stained cells 25 25-75 or 75 and iii subcellular localization nuclear andor cytoplasmicmembranous knowledge-based annotation was achieved by stringent evaluation of immunohistochemical staining pattern rna-seq data from internal and external sources and available proteingene characterization data with special emphasis on rna-seq all immunohistochemical images are available and the annotation data can be found under primary data in hpahiped is an integrated proteomics platform residing within genecards which involved 69 normal anatomical entities tissues cells and fluids from four databases including proteomicsdb moped paxdb and maxqb 51 the ppm protein values were calculated for each sample if not provided so by data sources the intensity-based absolute quantification ibaq expression values were divided by the sum of values of each sample and multiplied by 1000000 ibaq is a proxy for protein abundance levels 52 for all samples data was gene centrically aggregated by summing expression values of all isoforms for each gene samples from similar tissues were averaged using geometric mean for better visualization of graphs expression values are drawn on a root scale which is an intermediate between log and linear scales 51 the protein expression images present a protein expression vector for each gene based on normalized abundances in 69 normal human anatomical entitiesprotein differential expression provides a list of anatomical entities for which a gene is positively differentially expressed based on the 69 integrated normal proteomics datasets in hiped genes with fold change value 6 and protein abundance value 01 ppm in an anatomical entity are defined as positively differentially expressed in that entity fold change values were calculated as the ratio between the tested dataset protein abundance and the average of all datasetsthe blood atlas contains single cell type information on genome-wide rna expression profiles of human protein-coding genes covering 18 cell types obtained by fluorescence-activated cell sorting 23 these cells include various b-cells t-cells nk-cells monocytes and dendritic cells the rna expression for each gene was analyzed by the online tools resided in hpa blood atlas the public transcriptome datasets from schmiedel bj 25 and monaco g 26 were also collected to analyze the mrna expression of ace2 in human common blood cells give ace2 is a membrane and secreted protein in the blood we further analyzed its abundance in the human blood using public ms-based proteomics in peptideatla 27-29 and hpa blood atlas 24 an analysis of the proteins detected in human blood was presented with an estimation of the respective protein concentrations determined with ms-based proteomics and proximity extension assays-based protein profiling hpa blood atlas provides the protein concentration in plasma based on proximity extension assays olink for a longitudinal wellness study covering 86 individuals with four visits during one year at three months intervals protein expression levels are reported as normalized protein expression npxmiddle east respiratory syndrome coronavirus mers-cov emerged as a global health concern in 2012 when the first human case was documented in saudi arabia1 now listed as one of the who research and development blueprint priority pathogens cases have been reported in 27 countries across four continents2 imported cases into non-endemic countries such as france great britain the united states and south korea have caused secondary cases35 thus highlighting the potential for mers-cov to spread far beyond the countries where index cases originate reports in animals suggest that viral circulation could be far more widespread than suggested by human cases alone68to help prevent future incidence of mers-cov public health officials can focus on mitigating zoonotic transfer however in order to do this effectively additional research is needed to determine where spillover could occur between mammals and humans previous literature reviews have looked at healthcare-associated outbreaks9 importation events resulting in secondary cases1011 occurrences among dromedary camels1213 or to summarize current knowledge and knowledge gaps of mers-cov1415 this database seeks fill gaps in literature and build upon existing notification data by enhancing the geographic resolution of mers-cov data and providing occurrences of both mammal and environmental detections in addition to human cases this information can help inform epidemiological models and targeted disease surveillance both of which play important roles in strengthening global health security knowledge of the geographic extent of disease transmission allows stakeholders to develop appropriate emergency response and preparedness activities httpswwwjeeallianceorgglobal-health-security-and-ihr-implementationjoint-external-evaluation-jee inform policy for livestock trade and quarantine determine appropriate demand for future vaccines httpcepinetmission and decide where to deliver them additionally targeted disease surveillance will provide healthcare workers with updated lists of at-risk countries patients with a history of travel to affected regions could then be rapidly isolated and treated thus reducing risk of nosocomial transmissionthis database is comprised of 861 unique geo-positioned mers-cov occurrences extracted from reports published between october 2012 and february 2018 it systematically captures unique occurrences of mers-cov globally by geo-tagging published reports of mers-cov cases and detections data collection database creation and geo-tagging methods are described below instructions on how to access the database are provided as well with the aim to contribute to future epidemiological analysis all data is available from the global health data exchange16 and figshare17we identified published reports of mers-cov by searching pubmed web of science and scopus with the following terms middle eastern respiratory syndrome middle east respiratory syndrome merscov and mers the initial search was for all articles published about mers-cov prior to april 30 2017 and was subsequently updated to february 22 2018 these searches were conducted through the university of washington libraries institutional database subscriptions we searched the web of science web of science core collection the subscribed edition includes science citation index expanded 1900-present social sciences citation index 1975-present arts  humanities citation index 1975-present emerging sources citation index 2015-present we searched the standard scopus database and the standard freely available pubmed database these products have a single version that is consistent across institutional subscriptions or access pointsin total this search returned 7301 related abstracts which were collated into a database before a title-abstract screening was manually conducted fig 1 flowchart articles were removed if they did not contain an occurrence of mers-cov for example vaccine development research or coronavirus proteomic analyses non-english articles were flagged for further review and brought into the full text screening stage the accompanying supplementary file highlight the title and abstract screening process and the inclusion and exclusion criteriafull text review was conducted on 1083 sources to meet the inclusion criteria articles must have contained both of the following items 1 a detection of mers-cov from humans animals or environmental sources and 2 mers-cov occurrences tagged with spatial information additionally extractors attempted to prospectively manually remove articles containing duplicate occurrences that were already extracted in the dataset extractors only prospectively manually removed articles if it was clear the articles contained data we were confident had already been extracted and had high-quality data we excluded 885 sources based on full text review in addition we reviewed citations and retroactively added relevant articles to our database if they were not already included we retroactively added and subsequently marked ten articles for extraction using this process in total we extracted 208 peer-reviewed sources reporting detection of mers-cov that included geographic and relevant epidemiological metadatagoogle maps or arcgis23 was used to manually extract location information at the highest resolution available from individual articles we evaluated spatial information as either points or polygons the geography was defined as a point if the location of transmission was reported to have occurred within a 5  5 km area point data are represented by a specific latitude and longitude a point references an area smaller than 5  5 km in order to be compatible with the typical 5  5 km resolution of satellite imagery used for global analysesthe geography was defined as a polygon if the location of transmission was less clear but known to have occurred in a general area eg a province or the location of transmission occurred within an area greater than 5  5 km eg a large city we used contextual information to determine location in instances where the authors spelling of a location differed from google maps or arcgis maps provided by authors were digitized using arcgiswe used three different types of polygons known administrative boundaries buffers and custom polygons relevant administrative units were sourced from the global administrative unit layers curated by the food and agricultural organization of the un24 for known administrative boundaries of governorates districts or regions and paired with the occurrence record buffers were created to encompass areas in cities and regions without corresponding administrative units to ensure that buffers encompassed the entirety of the area of interest google maps was used to determine the required radius in areas with unspecified boundaries eg table mountain national park and the border region between saudi arabia and uae arcgis was used to generate custom polygons which were assigned a unique code within a defined shapefile for ease of re-identificationthis database is publicly available online1617 each of the 861 rows represents a unique occurrence of mers-cov rows containing an index unspecified or imported case represent a single case of mers-cov rows containing mammal and secondary cases may represent more than one case but are still unique geospatial occurrences table 1 shows an overview of the content available in the publicly available dataset in addition online-only table 1 lists occurrences by geography origin 405 shape type and publication and online-only table 2 provides citations of the datanid a unique identifier assigned to each publication that was extractedtitle title of the publicationauthor articles authorsdoi articles doiabstract articles abstract if availablesourcetitle journal in which the article was publishedyear articles publication yearsource database where article was foundpmidifapplicable pmid if the article is from pubmedfulltextlinkifincluded link to the full text if availablefileid reference to pdf in format firstauthoryear eg smith2017occid unique identifier assigned to each occurrence of mers-cov a single pdf may represent more than one occurrence each row will have its own occid starting at 1 and numbered consecutively to 883organismtype what type of organism tested positive for mers-cov human mammal or environmentalorganismspecific specifies the exact organism that tested positive for mers-cov names are made consistent with wilson and reeder 2005 mammal species of the world25pathogen name the pathogen identified eg mers-cov bat coronaviruses and other mers-cov-like pathogenspathogennote miscellaneous notes regarding pathogenpatienttype index unspecified na secondary import or absentindex any human infection of mers-cov resulting after direct contact with an animal and no reported contact with a confirmed mers-cov case or healthcare settingunspecified cases that lacked sufficient epidemiological evidence to classify them as any other status eg serosurvey studiesna non-applicable field case was not a patient eg mammalsecondary defined as any cases resulting from contact with known human infections cases reported after the index case can be assumed to be secondary cases unless accompanied by specific details of likely independent exposure to an animal reservoirimport cases that were brought into a non-endemic country after transmission occurred elsewhereabsent suspected cases ultimately confirmed negative for mers-cov18transmissionroute zoonotic direct unspecified or animal-to-animalzoonotic transmission occurred from an animal to a humandirect only relevant for human-to-human transmissionunspecified lacked sufficient epidemiological evidence to classify a human case as zoonotic or directanimal-to-animal transmission occurred from an animal to another animal19clinical describes whether the mers-cov occurrence demonstrated clinical signs of infection denoted by yes no or unknownyes clinical signs of infection were presentreported clinical signs among humans may range from mild eg fever cough to severe eg pneumonia kidney failure clinical signs among camels include nasal dischargeno clinical signs of infection were not presentreportedunknown subjects may or may not have been demonstrating clinical signs of infection for example some authors did not explicitly mention symptoms but individuals reportedly sought medical care another example being when a diagnostic serosurvey was conducted during an ongoing outbreak the term unknown was used when articles lacked sufficient evidence for extractors to definitively label as yes or no20diagnostic describes the class of diagnostic method that was used pcr serology or reported21diagnosticnote more detailed information related to the specific test used eg rk39 igg or igm serology22serosurvey describes the context if serological testing was useddiagnostic testing of symptomatic patientsexploratory historic exposure determined among healthy asymptomatic individuals23country iso3 code for country in which the case occurred24origin open-ended field to provide more details on the specific in-country location of mers-cov case25problemgeography this field was utilized if the mers-cov case was reported in a location that could cause uncertainty when determining exact geographic occurrence eg hospital abattoir26lat latitude measured in decimal degrees27long longitude measured in decimal degrees28latlongsource the source from which latitude and longitude were derived29locconfidence states the level of confidence that researchers had when assigning a geographic location to the mers-cov case good or bad an answer of good meant the article stated clearly that the case occurred in a specific geographic location and no assumptions were required on part of the researcher an answer of bad meant the article did not clearly state the specific geographic location of the mers-cov case but the researcher was able to infer the location of occurrence the field sitenotes was utilized to detail the logic behind researchers decisions when inference was required30shapetype the geographic shape type assigned to the mers-cov occurrence point or polygon31polytype if the mers-cov occurrence was assigned a shapetype of polygon was it admin gaul custom or buffer32bufferradius if a mers-cov occurrence was assigned a buffer what is the radius in km33gaulyearorcustomshapefile file path used to reach the necessary shape file in arcgis users of this dataset can find custom shapefiles created for this dataset at httpscloudihmewashingtoneduindexphpsdgoykyqnbjg54f2download34polyid a standardized and unique identifier assigned to each gaul shapefile35polyfield which type of polygon was used to geo-position the occurrence eg if admin1 polygon was used enter adm1code36sitenotes miscellaneous notes regarding the site of occurrence37monthstart month that the occurrences began if the article provided a specific month of illness onset the month was assigned a number from 112 1  january 2  february etc if the article did not provide a specific month of illness onset then researchers assigned a value of na38monthend month that the occurrences ended defined as the date a patient tested negative for mers-cov if the article provided a specific month for recovery the month was assigned a number from 112 1  january 2  february etc if the article did not provide a specific month of symptom onset then researchers assigned a value of na39yearstart year that the occurrences began if the year of illness onset was not provided in the article the ihme standard was usedyearstart  publication year  340yearend year that the occurrences ended if the article did not provide a specific year for recovery the ihme standard was usedyearend  publication year  141yearaccuracy if years were reported this field was assigned a value of 0 if assumptions were required this field was assigned a value of 1figures 24 show the geographic distribution of the mers-cov occurrence database with distinctions made by epidemiological and geographic metadataall data extracted from the original search october 2012 to april 30 2017 was reviewed independently by a second individual to check for accuracy challenging extractions from the updated search may 1 2017 to february 22 2018 were selected for group review during bi-weekly team meetings upon extraction completion all data were checked to ensure they fell on land and within the correct countrywhile the protocol implemented above was designed to reduce the amount of subjective decisions made by extractors total elimination was not possible wherever a subjective decision had to be made the extractor utilized the various notes fields in order to document the logic behind decisions these decisions were subsequently reviewed by other extractorsthe techniques described here can be applied to collect and curate datasets for other infectious diseases as has been previously demonstrated with dengue20 and leishmaniasis18 additionally since these data were collected independently through published reports of mers-cov occurrence they may be used to build upon existing notification data2627 our ability to capture occurrences in this dataset is contingent on the data contained within published literature therefore this dataset does not represent a total count of all cases instead this datasets value lies within its geo-precision data were extracted with a focus on obtaining the highest resolution possible these data may be merged with other datasets such as who26 or oie27 surveillance records and are intended to complement not replace these resources together published reports and notification data can provide a more comprehensive snapshot of current disease extent and at-risk locationsan important consideration whether using the literature data alone or in combination with other databases is the potential for duplication various pieces of metadata can be used to evaluate where potential duplicates could lie such as common date fields monthstart monthend yearstart yearend or consistent geographic details lat long polyid shapetype or shared epidemiological tags patienttype researchers may wish to consider further steps such as fuzzy matching of geographic data eg matching a point with an overlapping buffer or temporal data eg matching a precise month with an overlapping month interval we acknowledge this duplicate-removal process will not catch all matching records but it will likely catch several we recommend this approach because it will allow researchers to remove several duplicates without erroneously deleting any two occurrences that are truly unique ie not duplicates essentially we recommend a sensitive approach above a more specific approach as the latter simply risks culling too many records that arent actually duplicateswhen merging with other databases consistency in metadata tagging is essential for the who disease outbreak news data feed2627 for instance nomenclature for case definitions is slightly different with who definitions of community acquired and not reported comparable to index and unspecified respectively in addition it is important to recognize what information is beyond the scope of these additional databases again when comparing to the who dataset it is important to recognize that serologically positive cases do not meet the case definition used in the who database these adjustments need to be identified on a dataset-to-dataset basisthis database can be combined with other covariates eg satellite imagery to produce environmental suitability models of mers-cov infection risk and potential spillover on both global and regional scales as achieved with other exemplar datasets2831 this information can be useful in resource allocation aimed at improving disease surveillance and contribute towards a better understanding of the factors facilitating continued emergence of index casesthe addition of sampling techniques and prevalence data may improve this dataset researchers were ultimately unable to add these data due to inconsistencies in the way literature reported sampling techniques and prevalence date by geography an attempt to extract these data using the current approach would have led to sporadic inclusion of this information and would not have been comprehensive for the entire dataset moving forward we recommend authors report sampling technique and prevalence data at the highest resolution geography possible as seen in miguel et al32 we encourage continued presentation of paired epidemiological and geographic metadata that would allow for more detailed analysis in the futurethis database may also be utilized in clinical settings to provide an evidence-base for diagnoses when used in conjunction with patient travel histories additionally it can be used to identify geographies for surveillance particularly areas where mers-cov has been documented in animals but not humans eg ethiopia and nigeria identifying locations for surveillance will in turn inform global health security while models will increase the resolution at which these questions can be addressed datasets such as this provide an initial baselinea major limitation of this database is the potential for sampling bias which stems from higher frequency of disease reporting within countries where there exists strong healthcare infrastructure and reporting systems this database does not attempt to account for such biases which must be addressed in subsequent modelling activities where such biases are of consequence similarly another limitation is potential duplicate documentation of singular occurrences this can happen when the same occurrence is assigned different geographies eg point polygon in multiple publications even though extractors made efforts to prospectively manually identify duplicate occurrences this was challenging because the process relied upon papers providing sufficient details for extractors to determine a duplicate occurrence eg geography patient demographics dates of occurrence diagnostic methods etc however the majority of papers did not report such details for each occurrence in those instances it was impossible for extractors to discern whether occurrences may have been duplicates from a previous artic le even case studies inconsistently reported patient details and demographic information these are some examples of challenges faced by extractors when we attempted to identify duplicates without sufficient contextual clues extractors lacked evidence to determine duplicity and thus likely extracted some unique occurrences more than once despite efforts to remove duplicate occurrences from the database it is possible that some remaingeographic uncertainty is similarly problematic for analyses such as this in some cases polygons as opposed to points are utilised as a geographic frame of reference reflecting the uncertainty in geotagging in the articles themselves for some occurrences there is a strong assumption that the geography listed corresponds to the site of infection while the use of 5 km  5 km as the minimum geographical unit allows for some leeway in this precision it is possible that even with the point data often corresponding to household clusters these may not map directly with true infection sites this must be considered in any subsequent geospatial analysisfinally this database represents a time-bounded survey of the literature while all efforts were made to be comprehensive within this period articles and therefore data will continue to be published efforts to streamline ongoing collection processes are still to be fully realized33 regardless we hope that this dataset provides a solid baseline for further iterationdiseases and bacteria or viruses which cause them often have different names the human immunodeficiency virus hiv for example induces the acquired immunodeficiency disease aids the virus that triggers the current outbreak is called coronavirus 2 a serious acute respiratory syndrome shortened to sars-cov-2 the illness shortened to covid-19 is called coronavirus disease the world health organization and the international committee on taxonomy of viruses ictv 1 gave these names in public speaking the who also refers to the virus as the virus accountable for covid-19 or the covid-19 virus the outbreak was first reported in wuhan city china wuhan is the capital of the hubei province and has a population of around 11 million chinese authorities reported a cluster of related pneumonia cases in the town on 29 december 2019 a novel coronavirus which was later called sars-cov-2 soon confirmed to cause these cases 27 the first covid-19 cases outside of china were found in thailand on january 13 and in japan on january 16 8 the chinese government put the city of wuhan and other cities in the area on lockdown on january 23 covid-19 has since spread to several more countries-cases have been recorded in all regions of the world it grew into a global pandemic by march 2020 and was announced by the who as such 911 while people sometimes refer to the virus that causes covid-19 as the coronavirus several different coronaviruses do exist the word refers to a group of viruses specific to humans coronaviruses cause about 30 percent of all cold cases 12 corona is latin for crownthis group of viruses is named because under an electron microscope its surface looks like a crown as the outbreak of the novel sarscov2 is increasingly spreading in china and beyond threatening to become a global pandemic epidemiological data need to be interpreted in such a way that the model of statistical data analysis and visualization can increase the understanding of situation among the mass population in the coming days 13 14the world health organization who johns hopkins university researchers and other agencies all maintain dataset on the number of confirmed infected cases deaths and disease recoveries all data obtained in this research work is from johns hopkins university and is freely accessible via the github repository the dataset covered the period from 22 january 2020 to 17 april 2020 which includes time-series and aggregated data 15we statistically analyzed our dataset with various methods of data analysis and visualized those data to provide a proper understanding of the covid19 outbreak worldwide our exploit analysis was carried out by johns hopkins university with the 2019 coronavirus dataset januaryapril 2020 here between 22 january 2020 and 17 april 2020 we present an effort to visualize and analyze the results covid19 has so far propagated nearly 185 countriesregions 83 citiesprovinces have been registered and 264 separate geographical locations combined using time-series data it estimated the number of individual cases such as confirmed infected deaths and recovered around the globe and the top 10 countries in the world as of 17 april 2020 the united states and spain are among the top ten countries in the world further to the discussion on different cases such as confirmed illnesses deaths and recovery in those countries as seen in the fig 1worldwide the total confirmed infected cases are 2152646 and the global average rate is 038 with a standard deviation of 215 the global average rate of the top 10 countries is 773 with a standard deviation of 849 in this circumstance the us ranked first with a total of 667801 the global percentage is 3102 and with a total of 184948 the global percentage of 859 spain is second the estimated number of deaths worldwide is 143800 with a global average of 361 for this situation the us occupied the first place with 32916 counts and with 22170 counts italy was second in the top 10 countries around the world the total number of cases recovered is 542107 in the world in this scenario germany ranked first with a total of 77000 with a total of 74797 spain ranked second and the us ranked fourth with a total of 54703 in the top 10 countries of the worldfrom a statistical data analysis it can be understood that 5 of deaths and 8 of recoveries occurred in reported cases in the united states in spain 10 of deaths and 40 of recoveries occurred in confirmed caseswe also explore time-series data using visual data analysis to provide a clear and understandable outcome of this extreme outbreak of covid19 this segment will analyze various time-series data using several visual data analysis approaches with the r programming language we have created a graph and given awareness of how sarscov2 spread around the globe from 22 january 2020 to 17 april 2020 it allows individuals to grasp the epidemiological essence of covid19 figure 1 indicates that the confirmed infected cases have been crossed by 2000000 cases around the globe many cases such as death recovery and active have also been shown new cases reported on a single day do not actually represent new cases on that day as the number of confirmed infected cases or deaths announced by any organizationincluding who ecdc johns hopkins university and othersdoes not reflect the total number of new cases or deaths on that day this is due to the long chain of reporting that occurs between a new case or death and its inclusion in national or international statisticsregression and generalized linear models glm of data from the covid-19 time series are used to analyze confirmed infected deaths and recovered cases the fitted models have yielded better statistical results the findings shown below represent all three cases in the usa from the models results obtained on the confirmed case the exponential model coefficients are  0807 and 017 the glm poisson model coefficients are 3469 and 0119 and the glm gamma model coefficients are  0433 and 017 both of which are statistically significant as shown in fig 2 in case of death the exponential model coefficients are  2774 and 0144 the glm poisson model coefficients are  2424 and 0151 both of which are statistically reasonable in the recovered case the exponential model coefficients are  2204 and 0137 the glm poisson model coefficients are  2864 and 0163 both of which are statistically significant from the findings it can be understood that all cases such as confirmed infected deaths and recovered are linearly increased the same thing is reflected in the upper part of the graph ie the output of linear and generalized linear models regression and generalized linear models of the covid-19 time series were also used to analyze confirmed infected death and recovered cases in spain the fitting models have provided better statistical results the findings shown below reflect all three cases in spain here too the count has risen linearly in the confirmed case the exponential model coefficients are  2278 and 0185 the glm poisson model coefficients are 4159 and 0093 both of which are statistically significant in case of death the exponential model coefficients are  2919 and 0152 the glm poisson model coefficients are 1329 and 0104 both of which are statistically fine in the recovered case the exponential model coefficients are  2876 and 0165 the glm poisson model coefficients are 0914 and 0124 both of which are statistically appropriatein the event of an outbreak of an infectious disease it is necessary not only to track the number of deaths but also the rate of increase in the number of deaths if there is a fixed number of deaths over a fixed period of time we call that linear growth but if they continue to double within a fixed time span we call it exponential growth based on the results looking at the rate of death growth we have understood that it is linear growth in the us and spain figure 3 indicates that changes every day occurred in confirmed cases between 22 january 2020 and 17 april 2020 from the usa and spain by this we will conclude that the reported cases will accelerate on 20 march 2020 and that the last day of change is 31451 in the us in spain the confirmed case rises linearly from 03 march 2020 to 15 april 2020 the last day of change is 7304 it is clear that the real-time analysis of these data is extremely useful in documenting the epidemiological behavior of this severe disease we believe that this method of data analysis will certainly increase understanding of the situation and inform behaviorthis study examined three separate categories of data including confirmed infected death and recovered cases across the globe for the period from 22 january to 17 april 2020 it will also include a comparative overview of all the cases reported in the united states and spain nevertheless we are discussing various cases internationally in order to explain the various cases identified over a particular time span after review 2152646 confirmed cases of covid19 occurred worldwide on 17 april 2020 in the us where the highest count is 667801 the global percentage is 3102 death cases were 143800 across the globe 668 with the us top count being 32916 493 the cases recovered were 542107 around the globe 2518 with germany at the top of the list with a total of 77000 cases the visual analysis of the growth rate of confirmed infected deaths and recovered cases between the us and spain is another investigationthe goal of this article on covid-19 is to summarize existing research collect relevant data and make it possible for readers to make sense of the published data and early research on the coronavirus outbreak much of our work focuses on known problems for which we can link with well-established research and evidence on covid-19 the research presented here is based on statistical and visual data analysis methods with the aid of a dataset provided by john hopkins university the research was done with r studio 125033 and r 40 beta versions of the windows 10 operating system each and every description of the different cases of covid19 is documented here between 22 january 2020 and 17 april 2020 we are now also observing the harmful outbreak of the sarscov2 virus to the world this is extremely troubling in this analysis we examined the top 10 countries most affected and comprehensive reported cases of the united states and spainin conclusion the dataset covid-19 2019-ncov from the johns hopkins csse data repository 22 january 2020 to 17 april 2020 was used for our experiment it has supported us to generate and disseminate detailed information to the scientific community and to the public especially at the peak phase in order to understand the growth and impact of the novel coronavirus nevertheless knowledge of this novel sarscov2 virus remains minimal among the general population around the globe raw data published from different sources are not adequately capable of offering an insightful understanding of covid19 as a consequence of sarscov2 a user-friendly data analysis platform would also be more effective in recognizing the epidemic of this severe disease the informative graphics of the visualization platform provide an intuitive interface and a simple view of all raw data hopefully in the coming days we will continue to track the epidemiological data of this outbreak that we have used in this study and from other official sourcescoronaviruses encode the largest positive sense single-stranded rna genomes known ranging from 27 to 31 kb in length although coronaviruses have been shown to possess proofreading ability 1 relatively high mutation rates mean that coronaviruses are one of the most diverse genetically distinct and recently emerging groups of viruses the emergence of these viruses are mainly triggered by the virus evolution which could occur due to high mutational rates selection pressure on genetic diversity inter- and intra-host selection frequency of recombination and genetic drifts during transmission bottlenecks within subfamily coronaviridae alphacoronaviruses and betacoronaviruses infect and cause diseases in mammals whereas gammacoronaviruses are mainly avian specific 2bovine coronaviruses bcovs together with human coronavirus oc43 hcov-oc43 equine coronavirus ecov and porcine hemagglutinating encephalomyelitis virus phev belong to the virus species betacoronavirus1 of the lineage a of the genus betacoronavirus 3 bcov causes infections both in respiratory and enteric systems in cattle of all ages like other coronaviruses bcov exhibit high genetic mutations one mutation per genome per replication round 4 5 the nucleotide nt substitutions per site per year were found to be 13  104 61  104 and 36  104 for rna-dependent rna polymerase rdrp s and n genes respectively 68 due to their evolutionary potential bcovs have been isolated from humans bcov-like human enteric coronavirus hecv-4408us94 and a recently isolated canine respiratory coronavirus crcov has also shown a high genetic similarity to betacoronavirus1 9 10taken together experimental data and mathematical models have reinforced the need for studying coronavirus dynamics and evolution which could provide bases for effective control measures recent availability of quantitative deep-sequencing methodologies has provided data that can be modelled for future prediction of transmission dynamics and to estimate relevant parameters in this protocol we used publically available s gene data on bcov as prototype coronavirus and analyzed to predict epidemiological linkage mutation-prone sites and evolution in the s gene of bcov the same protocol is applicable to other genes of the coronaviruses and viruses of other familiesto perform in silico analysis of the s genes of bcov the following equipment will be required see
note
1mac os x with minimum 24 ghz processor and 2 gb ramtextedit textwrangler stable release 18 or latestbioedit version v725mrbayes version 322 or latesta perl script for generating suitable file formatsbeast version 180 or latestbeauti version 17 or latesttracer version 16 or latestfigtree v123 or latestan appropriate internet access

define objectives see
note
2construct dataset and label it as bcovs genesfas see
note
3open the downloaded file bcovs genesfas in textedit and edit the sequence titles the sequence titles can be arranged depending upon objective in mind and the availability of downstream analysis tools one accepted way of labelling the sequence title will be to arrange them in hostisolateidgenotypecountryyear accession number remove all illegal characters along with empty spaces and replace them with underscoreunderstrike  however do not remove any greater than signs  which will destroy the fasta format and may require rebuilding of the data set 11 to do so use the find and replace with options in the textedit which can be opened with cmdf command in mac os x save the file before closing the datasetopen the file in bioedit and click on accessory application - clustalw multiple alignment save the newly opened aligned file and label it as bcovs genesalignfas see
note
4convert the fas file bcovsgenesalignfas to a nex file bcovs genesalignnex use either a perl script available to freely download at httpsgithubcomdrmuhammadmunirperlblobmasterconvertfastatophylip or using trial version of codoncode aligner wwwcodoncodecomaligner see
note
5move bcovsgenesalignnex file into the folder of mrbayes detailed description of the program can be found on the webpage of the program httpmrbayessourceforgenet briefly open terminal and type mb to start the mrbayes software double click on mrbayes application icon in window the following instructions should appearmrbayes v321 x64bayesian analysis of phylogenydistributed under the gnu general public licensetype help or help command for information on the commands that are availabletype about for authorship and general information about the programmrbayes 
to execute the file into the program type executespacefilename eg execute bcovsgenesalignnex then press enter the message reached end of file indicates successful execution of the file and the program is ready to run in any error either follow the instructions mentioned in the error or rebuilt datasets the most common error is the presence of illegal characters such as pipeline sign  colon  semicolon  slashstrokesolidus  apostrophe   quotation marks         and brackets        among others therefore remove these from the fasta file as described beforeto set the evolutionary model to the gtr substitution type lset nst6 ratesinvgamma after the mrbayes  prompt then press enter the message successfully set likelihood model parameters indicates the success in model setupto set the sample collection 200 from posterior probability distribution diagnostic calculation every 1000 generations and print and sample frequency to 100 type mcmc ngen20000 samplefreq100 printfreq100 diagnfreq1000 after the mrbayes  prompt then press enter program will start calculating the split frequency depending on the speed of the operating system and the size of the dataset note the message average standard deviation of split frequencies if it is below 001 after 2000 generations type yes after continue the analysis yesno prompt to set more generations continue this until the split frequency drops below 001 once reached type no which leads the users to mrbayes  promptto summarize the parameter type sump then press enterto summarize the tree type sumt then press enter this command will save the tree with extension nexcontre ie bcovs genesalignnexcontre in the mrbayes folder where the original file bcovs genesalignnex was kept the tree can be opened and annotated in the figtreeopen the desired file bcovsgenesalignnexcontre after launching figtreelabel your sequences by searching your sequence-tag such as isolate name or country in the search button when taxa is selected similarly select nod or clade to label the respective items see
note
6after annotation save your tree using file - export graphics - pdf or other desired file format from the list - ok path the resulting file can be used for further editing or for presentation 11

to analyze the occurrences of synonymous ds and non-synonymous dn substitutions in the s gene use the same fasta file bcovsgenesalignfas that was generated for phylodynamics see
note
7open the snap tool freely available at httpwwwhivlanlgovcontentsequencesnapsnaphtml and paste the sequence or upload the datasetboth accumulated cumulated dn-ds and per codon dn-ds selection sites can be calculated by the generated table of snapsince the selections are calculated on every nucleotide sites under positive or negative selection can be highlighted see
note
8

alternatively and to verify the robustness of the data generated by the snap the same alignment can be used to calculate selection pressure using gtr general time reversible substitution model on a neighbor-joining phylogenetic tree by the datamonkey web server freely available at httpwwwdatamonkeyorgdatauploadphpthe program uses the computational engine of the hyphy package 12 to estimate dnds with a variety of evolutionary models and can analyze selection even in the presence of recombination see
note
9

within the beast package open beauti program bayesian evolutionary analysis utility and import nexus bcovsgenesalignnex or fasta bcovsgenesalignfas file of the data set remember to execute the data by file - import data - openseveral parameters of the beast run ie the date of the sequences the substitution model the rate variation among sites the length of the mcmc chain can then be adjusted according to specific need 13 see
note
10once all desired parameters are set finally click on the generate beast file to generate xml file which will be used as input for beast analysislabel the file as bcovsgenesalignxml for consistency
this is a brief explanation in order to run beast program and summarize results using tracermove the xml files bcovsgenesalignxml into the beast folderopen the beast program double-click a white screen on java environment will appear wait for several seconds until a second screen appearschoose the file to analyze in this second screen before beginning the analyses enable the allow overwriting of log files option then press run and the analysis will beginafter few moments depending upon the processing capacity of the operating system and the size of the data the chain will begin to run there will be seven columns that extend vertically every column is one of the parameters that are being estimated however the first and the last column are crucial to observe the first column is the generation being sampled in every moment every chain has ten million steps and the last column shows how many millions of states will be run per hour remember ten million steps per chain depending on the length of the chain the length of the sequences and the number of sequences to be analyzed it may take variable time to complete the runonce the chain has run it is required to store the parameters close the beast window and open the beast folder every time a chain is run two files are generated xml file and several ends log and tre once the first run is complete change the name of the log and tre files for example after the completion of a run for bcovsgenealignxml bcovsgenealignlog and bcovsgenealigntre files will be generated rename these two files to bcovsgenealign1log and bcovsgenealign1trerun the bcovsgenealignxml at least for two more times steps 25finally three different log files and tre files will be available labelled as bcovsgenealign1log bcovsgenealign2log and bcovsgenealign3log these three files contain the estimations of the substitution rate that have to be summarized in tracerto summarize the run open the tracer program and select the option file and input trace file and open the first 1log file from the folder followed by the addition of the second 2log file finally add the third 3log log filethe estimations of the parameters are viewable in the graphic interface select the option combined from the trace files upper left and the estimations that will appear on the traces table are the main estimations for all the parameters see
note
11 generally the desired parameters are
tree model root this is the number of years that passed after the most recent common ancestor tmrca subtract this number from the most modern date to yield the tmrca for the dataset
clock rate this is directly the rate of evolution in substitutionsiteyear


this protocol is optimized for mac os x however all the software packages and tools used here are also available for windows which can be installed using recommended methodologies all the software used here are open access which do not require any subscription for any operating systems these software packages are only for demonstration purposes and there may be alternative solutions for the same purpose the overall time of the data analysis depends upon processing power of the operating system and the number and length of sequences in the datasetthe same phylogenetic tree can be used for different interpretations failing to create a proper objective can lead to drawing incorrect conclusions from phylogenetic studies it is therefore essential to define the objective for the downstream analyses before initiating the studyconstruction of datasets depends on the objectives one of the most common interests of bioinformaticians is to determine the epidemiological linking of the query sequence to that of sequences reported from the world and are available in the public domains for this purpose the basic local alignment search tool blast is the most widely used tool primarily owing to its speed of execution search the nucleotide sequences with objective-based keyword such as bovine coronaviruses s gene manual editing and investigations of the downloaded sequences are always suggested notably blast-explorer is primarily aimed at helping the construction of sequence datasets for further phylogenetic study and it can also be used as a standard blast server with enriched output use blast or blast-explorer or other suitable database for construction of datasetsthere are different algorithms for dna sequence alignment with variable degrees of utility in this protocol clustalw was used for simplicity any other algorithm can be used depending upon the preferences and interestnexus format is required input for mrbayes different tools both online and offline can be used to generate appropriate nexus output we have only presented two commonly used and easily achievable methodsdetailed demonstration for tree annotation is described in our earlier publication 11the file used for phylogenetic analysis may contain all available sequences in the public domain which increases the size of the file significantly however depending upon the objective in mind the datasets can be modified accordingly for the larger datasets the compiled data will be emailed to the email address provided once ready this is also important to keep a record for future usethe cut point is calculated to be zero all sites showing cumulated dn-ds values above 0 are under positive pressure whereas values below 0 are under negative pressurethe nature of parameter selection and interpretation is complex and is beyond the scope of this protocol please consult developers published report for thorough understating of the concepts and applications 12the parameters of the beast run are crucial and can determine the nature of output and may heavily influence the results however normally the default parameters are used 13when summarizing the beast results do not use the mean as it appears in the output this is the arithmetic mean instead use the geometric mean that appears in the summary statistic table right upper from a methodological point of view this is much more correct click on every parameter in the tracer table and the summary statistic table for every parameter will change
experts in healthcare and medicine communicate in their own languages such as snomed ct icd-10 pubchem and gene ontology these languages equate to gibberish for laypeople but for medical minds they are an intricate method of transporting important semantics and consensus capable of translating diagnoses medical procedures and medications among millions of physicians nurses and medical researchers thousands of hospitals hundreds of pharmacies and a multitude of health insurance companies these languages eg genes drugs proteins species and mutations are the backbone of quality healthcare however they are deeply embedded in publications making literature searches increasingly onerous because conventional text mining tools and algorithms continue to be ineffective given that medical domains are deeply divided locating collaborators across domains is arduous for instance if a researcher wants to study ace2 gene related to covid-19 he or she would like to know the following which researchers are currently actively studying ace2 gene what are the related genes diseases or drugs discussed in these articles related to ace2 gene and with whom could the researcher collaborate this is a strenuous position to be in and the aforementioned problems diminish the curiosity directed at the topicmany studies have been devoted to building open-access datasets to solve bio-entity recognition problems for example hakala et al1 used a conditional random field classifier-based tool to recognize the named entities from pubmed and pubmed central bell et al2 performed a large-scale integration of a diverse set of bio-entities and their relationships from both bio-entity datasets and pubmed literature although these open-access datasets are predominantly about bio-entity recognition researchers have also been interested in extracting other types of entities and relationships from pubmed including the mapping of author affiliations to cities and their geocodes34 author name disambiguation5 and and author background information collections6 although the focus of previous research has been on limited types of entities the goal of our study was to integrate a comprehensive dataset by capturing bio-entities disambiguated authors funding and fine-grained affiliation information from pubmed literaturefigure 1 illustrates the bio-entity integration framework this framework consists of two parts 1 bio-entity extraction which contains entity extraction named entity recognition ner and multi-type normalization and 2 integration which connects authors orcid and funding informationthe process illustrated in fig 1 can be described as follows first we applied the high-performance deep learning method bidirectional encoder representations from transformers for biomedical text mining biobert78 to extract bio-entities from 29 million pubmed abstracts based on the evaluation this method significantly outperformed the state-of-the-art methods based on the f1 score by 051 on average then we integrated two existing high-quality author disambiguation datasets author-ity5 and semantic scholar9 we obtained the disambiguated authors of pubmed articles with full coverage and quality of 9809 in terms of the f1 score next we integrated additional fields from credible sources into our dataset which included the projects funded by the national institutes of health nih10 the affiliation history and educational background of authors from orcid6 and fine-grained region and location information from the mapaffil 2016 dataset11 we named this new interlinked dataset pubmed knowledge graph pkg pkg is by far the most comprehensive up-to-date high-quality dataset for pubmed regarding bio-entities articles scholars affiliations and funding information being an open dataset pkg contains rich information ready to be deployed facilitating the effortless development of applications such as finding experts searching bio-entities analyzing scholarly impacts and profiling scientists careersthe ner task recognizes a variety of domain-specific proper nouns in a biomedical corpus and is perceived as one of the most notable biomedical text mining tasks in contrast to previous studies that have built models based on long short-term memory lstm and conditional random fields crfs1213 the recently proposed bidirectional encoder representations from transformers bert14 model achieves excellent performance for most of the nlp tasks with minimal task-specific architecture modifications the transformers applied in bert connect the encoders and decoders through self-attention for greater parallelization and reduced training time bert was designed as a general-purpose language representation model that was pre-trained on english wikipedia and bookscorpus consequently it is incredibly challenging to maintain high performance when applying bert to biomedical domain texts that contain a considerable number of domain-specific proper nouns and terms eg brca1 gene and triton x-100 chemical bert required refinement so bioberta neural network-based high-performance ner modelwas developed its purpose is to recognize the known biomedical entities and discover new biomedical entitiesfirst in the ner component the case-sensitive version of bert is used to initialize biobert second pubmed articles and pubmed central articles are used to pre-train bioberts weights the pre-trained weights are then fine-tuned for the ner task while fine-tuning bert biobert we used wordpiece tokenization15 to mitigate the out-of-vocabulary issue wordpiece embedding is a method of dividing a word into several units eg immunoglobulin divided into i mmuno g lo bul in and expressing each unit this technique is effective at extracting the features associated with uncommon words the ner models available in biobert can predict the following seven tags iob2 tags ie inside outside and begin16 x ie a sub-token of wordpiece cls ie the leading token of a sequence for classification sep ie a sentence delimiter and pad ie a padding of each word in a sentence the ner models were fine-tuned as follows81documentclass12ptminimal
				usepackageamsmath
				usepackagewasysym 
				usepackageamsfonts 
				usepackageamssymb 
				usepackageamsbsy
				usepackagemathrsfs
				usepackageupgreek
				setlengthoddsidemargin-69pt
				begindocumentplefttirightsoftmaxtiwtbkquad quad k01ldots 6enddocumentptisoftmaxtiwtbkk016where k represents the indexes of seven tags b i o x cls sep pad p is the probability distribution of assigning each k to token i and documentclass12ptminimal
				usepackageamsmath
				usepackagewasysym 
				usepackageamsfonts 
				usepackageamssymb 
				usepackageamsbsy
				usepackagemathrsfs
				usepackageupgreek
				setlengthoddsidemargin-69pt
				begindocumenttiin rhenddocumenttirh is the final hidden representation which is calculated by biobert for each token i h is the hidden size of ti documentclass12ptminimal
				usepackageamsmath
				usepackagewasysym 
				usepackageamsfonts 
				usepackageamssymb 
				usepackageamsbsy
				usepackagemathrsfs
				usepackageupgreek
				setlengthoddsidemargin-69pt
				begindocumentwin rktimes henddocumentwrkh is a weight matrix between k and ti k represents the number of tags and is equal to 7 and b is a k-dimensional vector that records the bias on each k the classification loss l is calculated as follows2documentclass12ptminimal
				usepackageamsmath
				usepackagewasysym 
				usepackageamsfonts 
				usepackageamssymb 
				usepackageamsbsy
				usepackagemathrsfs
				usepackageupgreek
				setlengthoddsidemargin-69pt
				begindocumentlleftvartheta right-frac1nmathopsum limitsi1nlogleftpleftyi tivartheta rightrightenddocumentl1ni1nlogpyitiwhere  represents the trainable parameters and n is the sequence lengthfirst a tokenizer was applied to words in a sentence on a dataset with labels in the conll format17 the wordpiece algorithm was then applied to the sub-words of each word consequently biobert was able to extract diverse types of bio-entities furthermore an entity or two entities with frequently-occurring token interaction would be marked with more than one entity type span 262 for all pubmed abstracts based on the calculated probability distribution we were able to choose the correct entity type when entities were tagged with more than two types according to the probability-based decision rules8because an entity may be referred to by several synonymous terms synonyms and a term can be polysemous if it refers to multiple entity types polysemy we require a normalization process for the extracted entities however it is a daunting challenge to build a single normalization tool for multiple entity types because there exist various normalization models that depend on the type of entity we addressed this issue by combining multiple ner normalization models into one multi-type normalization model that assigns ids to extracted entities table 1 illustrates the statistics of the proposed normalization modelthe multi-type normalization model is based on a normalization model per entity type table 1 to improve the number of normalized entities we added the disease names from the polysearch2 dictionary 76001 names of 27658 diseases to the sieve-based entity linking dictionary 76237 names of 11915 diseases we also added the drug names from drugbank18 and the us food and drug administration fda to the tmchem dictionary because there are no existing normalization models for species we normalized species based on dictionary lookup using tmvar 20 we created a dictionary of mutations with normalized mutation names in which a mutation with several names was assigned to one normalized name or iddespite a rigorous effort to create global author ids eg orcid and researcherid most articles in pubmed particularly those before 2003 the year in which the field orcid was added into pubmed provide limited author information with respect to last name first initial and affiliation only for first authors before 2014 author information is not effective meta-data to be used directly as a unique identifier because different people may have the same names and the names and affiliations of an individual can change over time and is essential for identifying unique authorsin recent decades researchers have made several attempts to solve the and problem using three types of methods the first type of method relies on manual matching of articles with authors by surveying scientists or consulting curricula vitae cvs gathered from the internet19 although this type of method ensures high accuracy a considerable amount of investment in labor is required to collect and code the data which is impractical for huge datasets the second type of method uses publicly-accessible registry platforms such as orcid or google scholar to help researchers identify their own publications which produces a source of highly accurate and low-cost accessible disambiguation of authorship for large numbers of authors however registries cover only a small proportion of researchers2021 which introduces a form of survivor bias into samples the third type of method uses an automated approach to estimate the similarity of author instance feature combinations and identify whether they refer to the same person the features for automated and include author name author affiliation article keywords journal names22 coauthor information23 and citation patterns24 automated methods typically rely on supervised or unsupervised machine learning in which the machine learns how to weigh the various features associated with author names and where to assign a pair of author names either to the same author or to two different authors2526 this type of method can potentially avoid the shortcomings of the previous two types moreover automated methods have been improved to a high level of accuracy after years of developmentfor pubmed automated methods are the optimal choice because they can overcome the shortcomings of the other two methods while simultaneously providing high-quality and results for the entire dataset several scholars have disambiguated the authors using automated methods although the evaluations of these results have exhibited different levels of accuracy and coverage limitations we believe that integrating them with due diligence can yield a high-quality and dataset with full coverage of pubmed articlesaccording to our investigation a high-quality pubmed and dataset with complete coverage can be obtained through the integration of the following two existing and datasetsauthor-ity the author-ity database uses diverse information about authors and publications to determine whether two or more instances of the same name or of highly similar names on different papers represent the same person according to the and evaluation based on the method discussed in the section technical validation the f1 score of author-ity is 9816 which is the highest accuracy result that we have observed however this dataset only covers authors before 2009semantic scholar the semantic scholar database trains a binary classifier to merge a pair of author names and use the pair to create author clusters incrementally according to the and evaluation based on the method discussed in the section technical validation the f1 score of semantic scholar is 9694 which is 122 lower than that of author-ity however it has the most comprehensive coverage of authorsbecause the author-ity dataset has a higher f1 score than the semantic scholar dataset we selected the authors unique id of the author-ity dataset as the primary andid andid is limited by time range containing pubmed papers before 2009 however we supplemented authors after 2009 using the and result from semantic scholar the following steps were appliedstep 1 we allocated the authors unique id to each author instance according to the author-ity and results such that authors from the author-ity dataset before 2009 have unique author idsstep 2 for authors that have the same semantic scholar andid but never appear in the author-ity dataset we generated a new andid to label them for example author pietranico r published two papers in 2012 and 2013 and had two corresponding author instances because all papers that pietranico r published were after 2009 they were not covered by author-ity and therefore had no andid allocated by author-ity however the authors disambiguated correctly by semantic scholar were allocated unique andids in semantic scholar to maintain the consistency in labeling we generated a new andid continuing andids of author-ity to label these two author instances as disambiguated by semantic scholarstep 3 for author instances with a unique andid in semantic scholar and in which authors at least one had the same author-ity andid we allocated the author-ity andid to all author instances as their unique id for example maneksha s published three papers in 2007 2009 and 2010 and the first two author instances had a unique author-ity andid however the last one had no author-ity andid because it was beyond the time coverage of the author-ity dataset nevertheless based on the and results of semantic scholar the three author instances had an identical andid therefore the last author instance with no author-ity andid could be labeled with the same id as the other two author instancesnih exporter provides data files that contain research projects funded by major funding agencies such as the centers for disease control and prevention cdc the nih the agency for healthcare research and quality ahrq the health resources and services administration hrsa the substance abuse and mental health services administration samhsa and the us department of veterans affairs va furthermore it provides publications and patents citing support from these projects it consists of 49 data fields including the amount of funding for each fiscal year organization information of the pis and the details of the projects according to our investigation nih-funded research accounts for 807 of all grants recorded in pubmedthe nih exporter dataset contains a unique piid for each scholar who received nih funding between 1985 and 2018 and his or her pmids of the published articles through the mapping of pmids in nih exporter to pmids in pubmed 1n connections between the pi and articles have been established paving the way for investigating the article details of a specific pi and vice versa furthermore by mapping pi names last name first initial and affiliation to author names that were listed in articles supported by the pis projects a 11 connection between the pi and the andid was established providing a way to obtain pi-related article information regardless of whether the article was labeled with a project idaccording to its website orcid is a nonprofit organization helping to create a world in which all who participate in research scholarship and innovation are uniquely identified and connected to their contributions and affiliations across disciplines borders and time27 it maintains a registry platform for researchers to actively participate in identifying their own publications information about formal employment relationships with organizations and educational backgrounds orcid provides an open-access dataset called orcid public dataset 20186 which contains a snapshot of all public data in the orcid registry associated with an orcid record that was created or claimed by an individual as of october 1 2018 the dataset includes 7132113 orcid ids of which 1963375 have educational affiliations and 1913610 have employment affiliationsas a result of the proliferation of orcid identifiers pubmed has used orcid identifiers as alternative author identifiers since 201328 using the following two steps we could map orcid records to the pubmed authors our first step was to map the author instances in pubmed to an orcid record based on the feature combinations of article doi and author name last name and first initial because the doi is not a compulsory field for pubmed we appended the feature combinations of article titles journals and author names to map the records between the two datasets the result contained many 11 connections between a disambiguated author of pubmed and an orcid record furthermore 11 connections between andid and orcid id and 1n connections between andid and background information education and employment were establishedthe mapaffil 2016 dataset3 resolves pubmed authors affiliation strings to cities and associated geocodes worldwide this dataset was constructed based on a snapshot of pubmed which included the medline and pubmed-not-medline records acquired in the first week of october 2016 affiliations were linked to a specific author on a specific article prior to 2014 pubmed only recorded the affiliation of the first author however mapaffil 2016 covered some pubmed records that lacked affiliations and were harvested elsewhere such as from pmc nih grants the microsoft academic graph and the astrophysics data system all affiliation strings were processed using mapaffil to identify and disambiguate the most specific place names the dataset provides the following fields pmid author order last name first name year of publication affiliation type city state country journal latitude longitude and federal information processing standards fips codethe mapaffil 2016 dataset does have a limitation because it does not cover the pubmed data after 2015 covering 629 affiliation instances in pubmed consequently we performed an additional step to improve the fraction of coverage we collected authors who published their first article before 2016 and continued publishing articles after 2015 by their andids the new affiliation instances of the author after 2015 succeeded their corresponding fine-grained affiliation data from the affiliation instances before 2016 fraction of affiliation instance coverage increased to 842 if the author did not change affiliation we also applied an up-to-date open-source library affiliation parser4 to extract additional fine-grained affiliation fields from all affiliation instances including department institution email zip code location and countrytable 2 summarizes the date coverage and version information of integrated datasets and open-access software used to extract datawe built pkg with bio-entities extracted from pubmed abstracts and results of pubmed authors and the integrated multi-source information this dataset is freely available on figshare29 it contains seven comma-separated value csv files named authorlist bioentitiesmain bioentitiesmutation affiliations researcheremployment researchereducation and nihprojects the details are presented in table 3 pubmed raw data are not included into figshare file set because the amount of pubmed raw data is too large and they are not generated or altered by our methods pubmed raw data can be freely downloaded from pubmed website30 we also provide the following download link httpertaccutexasedudatasetsped which contains both the pubmed raw data and pkg dataset to facilitate the application of pkg datasetthe statistics of all five types of extracted entities are presented in table 4each data field is self-explanatory by its name and fields with the same name in other tables follow the same data format that can be linked across tables tables 511 illustrate the field name format and short description of fields for each data file listed in table 3updating pkg is a complex task because it is subject to the update of different data sources and requires significant computation in the future we hope to refresh pkg quarterly based on pubmed updated files and updated datasets from other sources we may also develop an integrative ontology to integrate all types of entitiesto validate the performance of the bio-entity extraction we established bert and the state-of-the-art models as baselines then we calculated the entity-level precision recall and f1 scores of these models as evaluation metrics the datasets and the test results of biomedical ner are presented in table 12in table 12 we report the precision p recall r and f1 f scores of each dataset the highest scores are in boldface and the second-highest scores are underlined sachan et al31 reported the scores of the state-of-the-art models for the ncbi disease and bc2gm datasets presented in table 10 moreover the scores for the 2010 i2b2va dataset were obtained from zhu et al32 single model and the scores for the bc5cdr and jnlpba datasets were obtained from yoon et al13 the scores for the bc4chemd dataset were obtained from wang et al33 and scores for the linnaeus and species-800 datasets were obtained from giorgi and bader34according to table 12 bert which is pre-trained on the general domain corpus was highly effective on average the state-of-the-art models outperformed bert by 228 in terms of the f1 score however biobert obtained the highest f1 score in recognizing genesproteins diseases and drugschemicals it outperformed the state-of-the-art models by 051 in terms of the f1 score on averagewe used the multi-type normalization model to assign unique ids to synonymous entities table 13 presents the performance of the multi-type entity normalization modelas shown in table 13 with respect to genes and proteins there were 75 different species in the bc3 gene normalization bc3gn test set but gnormplus focused only on seven of these species consequently gnormplus achieved a considerably lower f1 score by 366 on the multispecies test set bc3gn than on the human species test set bc2gn for mutations tmvar 20 achieved f1 scores close to 90 on two corpora osirisv12 and the thomas corpusthe validation of author disambiguation remains a challenge because there is a lack of abundant validation sets we applied a method using the nih exporter-provided information on nih-funded researchers to evaluate the precision recall and f1 measures of the author disambiguation35nih exporter provides information about the principal investigator id piid for each scholar who received nih funding between 1985 and 2018 because applicants established a unique piid and used the piid across all grant applications these piids have extremely high fidelity nih exporter also provides article pmids as project outputs which can be conveniently used as a connection between piids and andidwe confirmed the bibliographic information of the nih-funded scientists who received nih funding during the years 19852018 our and evaluation steps were as follows first we collected project data for the years 19812018 in nih exporter including 304782 piid records and the corresponding 331483 projects next we matched the projects to articles acknowledging support by the grant which were also recorded in the nih exporter dataset we matched 214956 of the projects to at least one article and identified 1790949 articles funded by these projects some of these projects 116527 did not match articles and were excluded because the nih occasionally awards a project to a team that includes more than one pi we eliminated the 13154 records that contained multiple pis because they could result in uncertain credit allocation consequently our relevant set of pis decreased to 147027 individuals associated with 1749873 articles and 201802 projectswe then connected nih piids from nih exporter to andids using the article pmids and author pis last name plus the initials as a crosswalk this step resulted in 1400789 unique articles remaining associated with 109601 piids and 107380 andids finally we computed precision p based on the number of articles associated with the most frequent andid-to-piid matched over the number of all articles associated with a specific andid36 furthermore we computed recall r based on the number of articles associated with the most frequent piid-to-andid matched over the number of all articles associated with a particular piid36 figure 3 summarizes the precision recall and f1 calculationstable 14 illustrates the precision recall and f1 scores for author-ity semantic scholar and our integrated and resultas presented in table 14 after integrating the and results of author-ity and semantic scholar we obtained a high-quality integrated and result that outperformed semantic scholar by 115 in terms of the f1 score and had more comprehensive coverage until 2018 than author-ity until 2009the evaluation results of and might be slightly overestimated the pis of nih grants usually have many publications over a long period and might be more likely to have rich information such as affiliations and email addresses about publications therefore it should be easier to acquire higher performance on and tasks than that of new entrants who published fewer papers and may lack of sufficient information for and furthermore approximately 115 of the author instances cannot be disambiguated since they do not exist in the author-ity or semantic scholar and results which further slightly reduces the performance of and results theoretically however the semantic scholar and results and the and integration are evaluated based on the same baseline dataset with author-ity in this section and the evaluation of author-ity performance using a random sample of articles indicates reliably high quality the recall of the author-ity dataset is 988 the lumping putting two different individuals into the same cluster of the author-ity dataset affects 05 of the clusters and the splitting assigning articles written by the same individual to more than one cluster of the author-ity dataset affects 2 of the articles5 consequently we believe these factors have a limited impact on and performancefor dr silberstein 539 bio-entities including 342 diseases 142 drugs 24 genes 17 species and 14 mutations were extracted from 455 articles as depicted in fig 4a headache and migraine were his two most studied diseases reaching 21 and 19 articles respectively in 2004 we trended his research over time on triptans starting with sumatriptan cgrp began to emerge in his publications starting in 2015 we noted the five researchers that have collaborated with dr silberstein through his career and map with pkg their collaborations interactions and institutions over time visualizing the profiles of individual researchers can help to understand the trends in their topics of interest and collaboration patterns to enable an understanding of collaboration factors that may be associated with academic success or scientific discoveryfor cgrp there are currently 7877 articles by 32392 authors on cgrp dating back to 1982 figure 4b illustrates that there was a dramatic increase in the number of cgrp-related articles from 13 in 1982 to 1209 in 1991 with a steady increase to 1517 in 2018 the trend of the number of authors over time was similar to that of the volume of articles on cgrpas we demonstrated with a previous analysis of the repurposing of aspirin4243 we observe research on cgrp starting at approximately the same time as the research on triptans for the treatment of migraines research on the pathophysiology of migraines identified a central role of the neuropeptide calcitonin gene-related peptide cgrp which is thought to be involved with the dilation of cerebral and dural blood vessels release of inflammatory mediators and the transmission of pain signals44 research on the mechanism of the action of triptansserotonin receptor agonistshas led to an understanding that they normalize elevated cgrp levels which among other mechanisms has led to an improvement in migraine headache symptoms consequently papers in high-impact journals have called for identifying molecules and the development of drugs to directly inhibit cgrp45 which has since led to the development of cgrp inhibitors as a new class of migraine treatment medicationsa total of 28223 disambiguated authors and 5379 distinct bio-entities of coronavirus articles were used to construct author-bio-entity bipartite network figure 5 illustrated the bipartite network fig 5a and its author projection fig 5b and bio-entity projection fig 5c in fig 5a the author vertices are blue and the bio-entity vertices are pink a link between a bio-entity and an author exists if and only if this bio-entity has been researched by that author connections between two authors or between two bio-entities are not allowed the edge weight is set as the number of papers an author published that mention a bio-entity in fig 5bc the edge weight is set as the number of common neighbors for the author and bio-entity respectively vertices are marked with different colors to show their community attributionfigure 5a illustrates a distinct relationship between authors and their focused bio-entities for example the disease sars have been frequently studied by author baric r s yuen kwok-yung and zheng bo-jian in addition to sars baric r s is also interested in coronavirus infection and hbv infection figure 5b depicts the common research interest relationship between authors strong connections between authors may indicate that they collaborated multiple times such as chan kwok hung and yuen kwok-yung who published 69 papers together these connections may also indicate author pairs that have similar research interests but never collaborated such as baric r s and yuen kwok-yung which is crucial for the collaborative commendation similarly the connections between bio-entities in fig 5c indicate that they have been studied by authors with similar research interests which can be further applied to discover the hidden relations between bio-entitiesthe 2019 novel coronavirus or covid-19 first reported in wuhan china in december 2019 belongs to the family of viruses coronavirus cov was called severe acute respiratory syndrome coronavirus 2 sars-cov-2 before it was named covid-19 by world health organization who in february 2020 the outbreak was declared a public health emergency of international concern on 30 january 2020 1 and finally on march 11 2020 who declared covid-19 as pandemic after the outbreak the number of daily cases began to increase exponentially and reached 18 million cases and around 114698 deaths globally by 12 april 2020 the virus has engulfed more than 210 countries among which usa spain and italy are severely hit with 560433 166831 and 156363 active cases and 22115 17209 and 19899 deaths respectively 2once infected a covid-19 patient may develop various symptoms and signs of infection which include fever cough and respiratory illness like flu in severe cases the infection may cause pneumonia difficulty breathing multi-organ failure and death 23 due to the rapid and increasing growth rate of the covid-19 cases the health system of many advanced countries has come to the point of collapse they are now facing shortage of ventilators and testing kits many countries have declared total lockdown and asked its population to stay indoors and strictly avoid gatheringsa critical and important step in fighting covid-19 is effective screening of infected patients such that positive patients can be isolated and treated currently the main screening method used for detecting covid-19 is real-time reverse transcription polymerase chain reaction rrt-pcr 45 the test is done on respiratory samples of the patient and the results can be available within few hours to 2 days an alternate method to pcr screening method can be based on chest radiography images various research articles published in radiology journal 67 indicate that that chest scans might be useful in detecting covid-19 researchers found that the lungs of patients with covid-19 symptoms have some visual marks like ground-glass opacitieshazy darkened spots that can differentiate covid-19 infected patients from non covid-19 infected ones 89 the researchers believe that chest radiology based system can be an effective tool in detection quantification and follow-up of covid-19 casesa chest radiology image based detection system can have many advantages over conventional method it can be fast analyze multiple cases simultaneously have greater availability and more importantly such system can be very useful in hospitals with no or limited number of testing kits and resources moreover given the importance of radiography in modern health care system radiology imaging systems are available in every hospital thus making radiography based approach more convenient and easily availabletoday researchers from all around the world from various different fields are working day and night to fight this pandemic many researchers have published series of preprint papers demonstrating approaches for covid-19 detection from chest radiography images 1011 these approaches have achieved promising results on a small dataset but by no means are production ready solutions these approaches still need rigorous testing and improvement before putting them in use subsequently a large number of researchers and data scientists are working together to build highly accurate and reliable deep learning based approaches for detection and management of covid-19 disease researchers are focusing on deep learning techniques to detect any specific features from chest radiography images of covid-19 patients in recent past deep learning has been very successful in various visual tasks which include medical image analysis as well deep learning has revolutionized automatic disease diagnosis and management by accurately analyzing identifying classifying patterns in medical images the reason behind such success is that deep learning techniques do not rely on manual handcrafted features but these algorithms learn features automatically from data itself 12 in the past deep learning has had success in disease classification using chest radiography image chexnet 13 is a deep neural network model that detects pneumonia from chest x-ray image chexnet achieved exceptional results exceeding average radiologist performance another similar approach called chestnet 14 is a deep neural network model designed to diagnose thorax diseases on chest radiography imagesthe success of ai based techniques in automatic diagnosis in the medical field and rapid rise in covid-10 cases have necessitated the need of ai based automatic detection and diagnosis system recently many researchers have used radiology images for covd-19 detection a deep learning model for covid-19 detection covid-net proposed by wang and wong 10 obtained 835 accuracy in classifying covid-19 normal pneumonia-bacterial and pneumonia-viral classes hemdan et al 15 used various deep learning models to diagnose covid-19 from cheat x-ray images and proposed a covidx-net model comprising seven cnn models apostolopoulos and mpesiana 16 trained different pre-trained deep learning models on a dataset comprising of 224 confirmed covid-19 images and achieved 9875 and 9348 accuracy for two and three classes respectively narin et al 11 trained resnet50 model using chest x-ray images and achieved a 98 covid-19 detection accuracy for two classes however the performance for multi class classification is not known sethy and behera 17 used various convolutional neural network cnn models along support vector machine svm classifier for covid-19 classification their study states that the resnet50 model with svm classifier provided the best performance most recently ozturk et al 18 proposed a deep network based on darknet model their model consists of 17 convolution layers with leaky relu as activation function their model achieved an accuracy of 9808 for binary classes and 8702 for multi-class cases all these techniques except covid-net 10 either perform binary classification normal vs covid-19 or 3class classification normal vs pneumonia vs covid-19 other than covid-net none of the methods discussed above treat pneumonia bacterial and pneumonia viral as separate classesin this study we present a deep learning based approach to detect covid-19 infection from chest x-ray images we propose a deep convolutional neural network cnn model to classify three different types of pneumonia bacterial pneumonia viral pneumonia and covid-19 pneumonia we also implemented binary and 3-class versions of our proposed model and compared the results with other studies in the literature the proposed model is called coronet and will help us identifying the difference between three types of pneumonia infections and how covid-19 is different from other infections a model that can identify covid-19 infection from chest radiography images can be very helpful to doctors in the triage quantification and follow-up of positive cases even if this model does not completely replace the existing testing method it can still be used to bring down the number of cases that need immediate testing or further review from expertsdeep learning is all about data which serves as fuel in these learning models since covid-19 is a new disease there is no appropriate sized dataset available that can be used for this study therefore we had to create a dataset by collecting chest x-ray images from two different publically available image databases covid-19 x-ray images are available at an open source github repository by joseph et al 19 the authors have compiled the radiology images from various authentic sources radiological society of north america rsna radiopaedia etc of covid-19 cases for research purpose and most of the studies on covid-19 use images from this source the repository contains an open database of covid-19 cases with chest x-ray or ct images and is being updated regularly at the time of writing this paper the database contained around 290 covid-19 chest radiography images pneumonia bacterial pneumonia viral and normal chest x-ray images were obtained from kaggle repository chest x-ray images pneumonia 20 the dataset consists of 1203 normal 660 bacterial pneumonia and 931 viral pneumonia cases we collected a total of 1300 images from these two sources we then resized all the images to the dimension of 224  224 pixels with a resolution of 72 dpi table i
below shows the summary of the prepared dataset figure 1
below shows some samples of chest x-ray images from the prepared datasetin order to overcome the unbalanced data problem we used resampling technique called random under-sampling which involves randomly deleting examples from the majority class until the dataset becomes balanced we used only 310 normal 330 pneumonia-bacterial and 327 pneumonia-viral x-ray images randomly from this chest x-ray pneumonia databaseconvolutional neural network also known as cnn is a deep learning technique that consists of multiple layers stacked together which uses local connections known as local receptive field and weight-sharing for better performance and efficiency the deep architecture helps these networks learn many different and complex features which a simple neural network cannot learn convolutional neural networks are powering core of computer vision that has many applications which include self-driving cars robotics and treatments for the visually impaired the main concept of cnn is to obtain local features from input usually an image at higher layers and combine them into more complex features at the lower layers 21
22a typical convolutional neural network architecture consists of the following layersa
convolutional layer

convolution layer is the core building block of a convolutional neural network which uses convolution operation represented by  in place of general matrix multiplication its parameters consist of a set of learnable filters also known as kernels the main task of the convolutional layer is to detect features found within local regions of the input image that are common throughout the dataset and mapping their appearance to a feature map the convolution operation is given as1fijikijmniimjnkmn
where i is the input matrix image k is the 2d filter of size m x n and f represents the output 2d feature map here the input i is convolved with the filter k and produces the feature map f this convolution operation is denoted by ikthe output of each convolutional layer is fed to an activation function to introduce non-linearity there are number of activation functions available but the one which is recognized for deep learning is rectified linear unit relu relu simply computes the activation by thresholding the input at zero in other words relu outputs 0 if the input is less than 0 and raw output otherwise it is mathematically given as2fxmax0x

a
subsampling pooling layer

in cnn the sequence of convolution layer is followed by an optional pooling or down sampling layer to reduce the spatial size of the input and thus reducing the number of parameters in the network a pooling layer takes each feature map output from the convolutional layer and down samples it ie pooling layer summarizes a region of neurons in the convolution layer there most common pooling technique is max pooling which simply outputs the maximum value in the input region other pooling options are average pooling and l2-norm pooling
a
fully connected layer

in fully connected layer each neuron from previous layer is connected to every neuron in the next layer and every value contributes in predicting how strongly a value matches a particular class the output of last fully connected layer is then forwarded to an activation function which outputs the class scores softmax and support vector machines svm are the two main classifiers used in cnn softmax function which computes the probability distribution of the n output classes is given as3zkexki1nexn
where x is the input vector and z is the output vector the sum of all outputs z equals to 1 the proposed model coronet uses softmax to predict the class to which the input x-ray image belongs to
all the layers discussed above are stacked up to make a full cnn architecture in addition to these main layers mentioned above cnn may include optional layers like batch normalization layer to improve the training time and dropout layer to address the overfitting issuecoronet is a cnn architecture tailored for detection of covid-19 infection from chest x-ray images it is based on xception cnn architecture 23 xception which stands for extreme version of inception 24 its predecessor model is a 71 layers deep cnn architecture pre-trained on imagenet dataset xception uses depthwise separable convolution layers with residual connections instead of classical convolutions depthwise separable convolution replaces classic n x n x k convolution operation with 1  1 x k point-wise convolution operation followed by channel-wise n x n spatial convolution operation this way the number of operations are reduced by a factor proportional to 1kresidual connections are skip connections which allow gradients to flow through a network directly without passing through non-linear activation functions and thus avoiding the problem of vanishing gradients in residual connections output of a weight layer series is added to the original input and then passed through non-linear activation function as shown in figure 3
coronet uses xception as base model with a dropout layer and two fully-connected layers added at the end coronet has 33969964 parameters in total out of which 33969964 trainable and 54528 are non-trainable parameters architecture details layer-wise parameters and output shape of coronet model are shown in table ii
 to initialize the model parameters we used transfer learning to overcome the problem of overfitting as the training data was not sufficientwe implemented three scenarios of the proposed model to detect covid-19 from chest x-ray images first model is the main multi-class model 4-class coronet which is trained to classify chest x-ray images into four categories covid-19 normal pneumonia-bacterial and pneumonia-viral the other two models 3-class coronet covid-19 normal and pneumonia and binary 2-class coronet model covid-19 normal and pneumonia are modifications of the main multi-class modelthe proposed model coronet was implemented in keras on top of tensorflow 20 the model was pre-trained on imagenet dataset and then retrained end-to-end on prepared dataset using adam optimizer with learning rate of 00001 batch size of 10 and epoch value of 80 for training data shuffling was enabled which involves shuffling the data before each epoch all the experiment and training was done on google colaboratory ubuntu server equipped with tesla k80 graphics card we used 4-fold cross-validation 25 approach to assess the performance of our main 4-class model the training set was randomly divided into 4 equal sets three out of four sets were used to train the cnn model while the remaining set was used for validation this strategy was repeated 4 times by shifting the validation and training sets final performance of the model was reported by averaging values obtained from each fold plots of accuracy and loss on the training and validation sets over training epochs for fold 4 are shown in figure 4
to check the robustness we tested our proposed model on another dataset prepared by ozturk et al 18 the dataset-2 contains around 500 normal 500 pneumonia and 157 covid-19 chest x-ray images this dataset contains same covid-19 x-ray images as in our prepared dataset however normal and pneumonia x-ray images were collected from chestx-ray database provided by wang et al 26 after slight modification and fine-tuning our proposed model achieved an overall accuracy of 90 the results are illustrated in table vi
and corresponding confusion matrix is given in figure 7
 table vi shows accuracy precision recall and f-measure of coronet on dataset-2in this study we proposed a deep model based on xception architecture to detect covid-19 cases from chest x-ray images the proposed model was tested on two datasets and performed exceptionally well on both of them our model achieved an accuracy of 895 9459 and 99 for 4-classes 3-classes and binary class classification tasks respectively furthermore our model also achieved an accuracy of 90 on dataset-2 another positive observation from the results is the precision ppv and recall sensitivity for covid-19 cases higher recall value means low false negative fn cases and low number of fn is an encouraging result this is important because minimizing the missed covid-19 cases as much as possible is the main aim of this researchthe results obtained by our proposed model are superior compared to other studies in the literature table vii
presents a summary of studies conducted in the automated diagnosis of covid-19 from chest x-ray images and their comparison with our proposed model coronet figure 8
shows coronet results on some sample images from the test setwang and wong 10 presented a residual deep architecture called covid-net for detection of covid-19 from chest x-ray images covid-net is one of the early works done on covid-19 which uses deep neural network to classify chest x-ray images into four categories covid normal pneumonia bacterial and pneumonia viral covid-net achieved an accuracy of 835 for four classes table viii
presents performance comparison of covid-net and our proposed model coronet on 4-class classification taskapostolopoulos and mpesiana 16 evaluated various state-of-the-art deep architectures on chest x-ray images with transfer learning their best model vgg19 managed to achieve an accuracy of 9348 and 9875 for 3-class and 2-class classification tasks respectively on a dataset consisting of 224 covid-19 700 pneumonia and 504 normal x-ray imagesnarin et al 11 performed same experiment with three different cnn models resnet50 inceptionv3 and inceptionresnetv2 and resnet50 pre-trained on imagenet database achieved best accuracy of 98 for 2-class classification since they did not include pneumonia cases in their experiment it is unknown how well their model would distinguish between covid-19 and other pneumonia casescnns are deep models which perform automatic feature extraction from input data and based on these extracted features a classifier like softmax performs classification softmax classifier is a default but noncompulsory choice for cnns and can be replaced by any good classifier like support vector machine svm one such experiment was done by sethy and behera 17 they employed resnet50 cnn model along with svm for detection of covid-19 cases from chest x-ray images cnn model acts as feature extractor and svm serves the purpose of classifier their model achieved an accuracy of 9538 on 2-class problemozturk et al 18 proposed a cnn model based on darknet architecture to detect and classify covid-19 cases from x-ray images their model achieved binary and 3-class classification accuracy of 9808 and 8702 respectively on a dataset consisting of 125 covid-19 500 pneumonia and 500 normal chest x-ray imagesthe promising and encouraging results of deep learning models in detection of covid-19 from radiography images indicate that deep learning has a greater role to play in fighting this pandemic in near future some limitation of this study can be overcome with more in depth analysis which is possible once more patient data both symptomatic and asymptomatic patients becomes availableas the cases of covid-19 pandemic are increasing daily many countries are facing shortage of resources during this health emergency it is important that not even a single positive case goes unidentified with this thing in mind we proposed a deep learning approach to detect covid-19 cases from chest radiography images the proposed method coronet is a convolutional neural network designed to identify covid-19 cases using chest x-ray images the model has been trained and tested on a small dataset of few hundred images prepared by obtaining chest x-ray images of various pneumonia cases and covid-19 cases from different publically available databases coronet is computationally less expensive and achieved promising results on the prepared dataset the performance can further be improved once more training data becomes available notwithstanding the encouraging results coronet still needs clinical study and testing but with higher accuracy and sensitivity for covid-19 cases coronet can still be beneficial for radiologists and health experts to gain deeper understandings into critical aspects associated with covid-19 casesfor further research in this area we have made the source code trained model and dataset available at httpsgithubcomdrkhan107coronet
the authors have no conflict of interest to disclosecoronaviruses are enveloped single-stranded positive-sense rna viruses belonging to the family of coronaviridae 1 they cause generally mild respiratory infections even though they are occasionally lethal since their discovery and first characterization in 1965 2 three major large-scale outbreaks have occurred caused by emerging highly pathogenic coronaviruses namely the severe acute respiratory syndrome sars outbreak in 2003 in mainland china 3 the middle east respiratory syndrome mers outbreak in 2012 in saudi arabia 45 and the mers outbreak in 2015 in south korea 67 these outbreaks have resulted in more than 8000 and 2200 confirmed sars and mers cases respectively 8recently a fourth coronavirus outbreak has occurred in wuhan the capital city of the hubei province and the seventh largest city of peoples republic of china 91011 since 31 december 2019 when the wuhan municipal health commission reported 27 cases of viral pneumonia including 7 critically ill cases the pneumonia outbreak has received considerable global attention a novel coronavirus was identified as the causative agent by the chinese authorities on 7 january 2020 and on 10 january 2020 the world health organization who designated the novel coronavirus as 2019-ncov on the same day the who released a wide range of interim guidance for all countries on how they can get prepared for coping with this emergency including how to monitor for potentially infected people collect and test samples manage patients control and mitigate the burden generated by the infection in health centers maintain the right drug supplies and effectively communicate with the lay public regarding the new virus 12by the morning of 23 january 2020 more than 571 confirmed cases with 17 deaths had been reported in other parts of mainland china and in various countries including south korea japan thailand singapore the philippines mexico and the united states of america as of 6 february 2020 0245 gmt 28276 cases of which 3863 are in critical condition and 565 deaths had been reported the transmission potential often measured in terms of the basic reproduction number the outbreak peak time and value and duration under current and evolving intervention measures remain unclear and warrant further investigation on 20 january 2020 the chinese government revised the law provisions concerning infectious diseases to add the 2019-ncov as a class b agent a pathogen that can cause an epidemic outbreak on the same day public health officials announced a further revision to classify the novel virus as a class a agent a pathogen that can cause an epidemic in a short time some non-pharmaceutical interventions npis including intensive contact tracing followed by quarantine of individuals potentially exposed to the disease and isolation of infected symptomatic individuals were implemented but their effectiveness during the early stage is questionable quantifying the effectiveness of these interventions is of crucial importance for wuhan as well as for other cities in their preparedness and rapid response to the importation of infected cases with the arrival of the spring festival massive traveling is expected to mobilize a large segment of the population by which the novel coronavirus may be broadly reseeded extreme unprecedented measures have been taken for example on 23 january 2020 the chinese authorities introduced travel restrictions affecting five cities wuhan huanggang ezhou chibi and zhijiang effectively shutting down the movement of more than 40 million people however how these expensive and resource-intensive measures can contribute to the prevention and control of the infection in these cities and other parts of the country and how long these travel restrictions should be maintained remain to be determined in the context of a novel coronavirus affecting a nave population estimation of the basic reproduction number is important for determining the potential and severity of an outbreak and providing critical information for designing and implementing disease outbreak responses in terms of the identification of the most appropriate evidence-based interventions mitigation measures and the determination of the intensity of such programs in order to achieve the maximal protection of the population with the minimal interruption of social-economic activities 8 as recognized by the who 13 mathematical models especially those which are timely play a key role in informing evidence-based decisions by health decision- and policy-makers to the best of our knowledge only a few mathematical models have so far been publicly released including a bats-hosts-reservoir-people transmission network model and a returning traveler study aimed to compute underestimated coronavirus cases 1415 no study has focused on the practical implications of public health interventions and measures therefore the present study was undertaken to fill in this gap of knowledgewe obtained data of laboratory-confirmed 2019-ncov cases which occurred in mainland china from the who situation report the national health commission of the peoples republic of china and the health commission of wuhan city and hubei province 16171819 data information includes the cumulative number of reported cases as shown in figure 1a and the quarantined and released population as shown in figure 1b the data were released and analyzed anonymously since the identification of the 2019-ncov on 10 january 2020 some cases were ruled out and the cumulative number of reported cases per day was 41 from 10 to 15 january 2020 to obtain the relatively reliable data we used the exponential growth law to deduce the number of reported cases per day from 31 december 2019 to 10 january 2020 called datarev2 or from 10 to 15 january 2020 called datarev1 based on the 41 cases on that date as shown in figure 1a by inferring the effectiveness of intervention measures including quarantine and isolation figure 1b we estimated the required effectiveness of these interventions in order to prevent the outbreakhere we propose a deterministic susceptible-exposed-infectious-recovered seir compartmental model based on the clinical progression of the disease epidemiological status of the individuals and intervention measures figure 2 we parameterized the model using data obtained for the confirmed cases of 2019-ncov in mainland china and estimated the basic reproduction number of the disease transmissionin more detail we investigated a general seir-type epidemiological model which incorporates appropriate compartments relevant to interventions such as quarantine isolation and treatment we stratified the populations as susceptible s exposed e infectious but not yet symptomatic pre-symptomatic a infectious with symptoms i hospitalized h and recovered r compartments and further stratified the population to include quarantined susceptible sq isolated exposed eq and isolated infected iq compartments with contact tracing a proportion q of individuals exposed to the virus is quarantined the quarantined individuals can either move to the compartment eq or sq depending on whether they are effectively infected or not 20 while the other proportion 1  q consists of individuals exposed to the virus who are missed from the contact tracing and move to the exposed compartment e once effectively infected or stay in compartment s otherwise let the transmission probability be  and the contact rate be constant c then the quarantined individuals if infected or uninfected move to the compartment eq or sq at a rate of cq or 1  cq those who are not quarantined if infected will move to the compartment e at a rate of c1q the infected individuals can be detected and then isolated at a rate di and can also move to the compartment r due to recovery the transmission dynamics are governed by the following system of equations 1sccq1siasqec1qsiaeieiiia1eaasq1cqsiasqeqcqsiaqeqhiiqeqhhriiaahh
where  is the derivative with respect to time and the other parameters are summarized in table 1 given the model structure with quarantine and isolation figure 2 we used the next generation matrix 2122 to derive a formula for the control reproduction number when control measures are in force as follows2rcc1qiic11qas0we used the markov chain monte carlo mcmc method to fit the model and adopted an adaptive metropolishastings m-h algorithm to carry out the mcmc procedure the algorithm is run for 100000 iterations with a burn-in of the first 70000 iterations and the geweke convergence diagnostic method is employed to assess convergence of chainswe employed the likelihood-based method or generation interval-informed method of white and pagano 23 using the following formula3lrc pnt1texpttntnt1
where trcj1kpjntj k is the maximum value of the serial interval chosen as k6 here and x is the gamma function nn0n1   nt where nj denotes the total number of cases on day j and t is the last day of observations pj is the probability function for the generation interval on day j we assume that the generation interval follows a gamma distribution with mean e and variance v since the generation interval of the 2019-ncov is undetermined we investigated the sensitivity of rc to different e values ranging from 2 to 8 days given in table 2 the population of wuhan is around 11081000 inhabitants 18 hence we set s011081000 as of 10 january 2020 two patients had been recovered and were subsequently discharged from the hospital leading to r02 and 739 individuals were quarantined leading to sq0739 we set h01 corresponding to the reported confirmed case on 10 january 2020 the quarantined individuals were isolated for 14 days thus 114 according to the who 24 the incubation period of 2019-ncov is about 7 days hence 17likelihood-based estimation of rc during the outbreak in wuhan gives a mean value of 639 with mean and variance of generation time of 6 and 2 days on the basis of a revised data series datarev1 the reproduction number based on likelihood-based estimation ranges from 166 to 10 and it follows from table 2 that rc is sensitive to changes in mean generation intervals fitting to the other revised data series datarev2 gives a mean value of 632 with mean and variance of generation time of 6 and 2 days note that the estimates of rc based on the two time series agree well and consequently both revised data series can be used to fit the proposed dynamics transmission model in this study we chose the estimations based on datarev1 as the comparison reference to verify and validate our model-based estimation thus in the following sections of the manuscript we will use the revised dataset datarev1 to fit the proposed model by fitting the model without considering asymptomatic infections to the data of hospital notification for the confirmed 2019-ncov cases datarev1 we estimated the mean control reproductive number rc to be 647 95 ci 571723 whereas other parameter estimations are reported in table 1 note that the mean estimations of rc based on the likelihood method are within the 95 confidence interval of the model-based estimates table 2 using the estimated parameter values we predicted the trend of the 2019-ncov infection under the current intervention before 22 january 2020 the number of infected individuals it is expected to peak on around 10 march 2020 with a peak size of 163105 infectious individuals to examine the possible impact of enhanced interventions on disease infections we plotted the number of infected individuals it and the predicted cumulative number of reported cases with varying quarantine rate q and contact rate c this analysis shows that reducing the contact rate persistently decreases the peak value but may either delay or bring forward the peak as shown in figure 3 and table 3 in more detail our analysis shows that increasing quarantine rate q by 10 or 20 times will bring forward the peak by 65 or 9 days and lead to a reduction of the peak value in terms of the number of infected individuals by 87 or 93 this indicates that enhancing quarantine and isolation following contact tracing and reducing the contact rate can significantly lower the peak and reduce the cumulative number of predicted reported cases figure 4considering the spreading of the virus figure 5 and in order to examine the impact of the travel restriction on the infection in other cities such as beijing we initially calculated the daily number of exposed individuals imported from wuhan to beijing denoted by imet according to our model we get the exposed fraction as of 22 january 2020 approximately 40000 persons from wuhan to beijing via trains around 37000 and flights around 3000 25 then we haveimet  40000  etn4
with 40 individuals being imported exposed individuals as of 22 january 2020 however there could potentially exist an ascertainment bias in reported case data since cases may have been larger than 40 individuals but have not been reported or reported with a delay in timewe find that with travel restriction no imported exposed individuals to beijing the number of infected individuals in seven days will decrease by 9114 in beijing compared with the scenario of no travel restriction while given no travel restriction the number of infected individuals in seven days will decrease by 8884 only if we increase the quarantine rate by 100 thousand times as shown in figure 6a this means that the effect of a travel restriction in wuhan on the 2019-ncov infection in beijing is almost equivalent to increasing quarantine by a 100 thousand baseline value which is a rate that can hardly be achieved in any public health setting it follows from figure 6b that with travel restriction the number of cumulative individuals in seven days will significantly decrease by 7570 in beijing compared with the scenario of no travel restriction based on the 2019-ncov cases data until 22 january 2020 we have estimated the basic reproduction numbers using different methods likelihood-based and model-based approaches the mean control reproduction number was estimated to be as high as 647 95 ci 571723 in comparison with the values of the sars epidemics r0  491 in beijing china in 2003 26 and mers in jeddah r0  3567 and riyadh r0  2028 kingdom of saudi arabia in 2014 27 our value is higher than other published estimates for instance reference 28 such a high reproduction number is consistent with the opinion that the virus has gone through at least threefour generations of transmission in the period covered by this study 24 note that our estimation is based on a dataset collected during a period of intensive social contacts before the chinese new year 25 january 2020 there were lots of annual summing-up meetings andor parties with higher than usual close contacts leading to a higher likelihood of infection transmission than that of the earlier periods covered by other studies furthermore we noted that more recently published studies based on datasets during periods comparable with ours reported similar findings in terms of a high basic reproduction number for instance reference 29 where authors using an exponential growth method computed a basic reproduction number of 611 95 ci 451816 assuming no changes in reporting rate and with a serial interval of 84  38 days variability in the estimation of the basic reproduction number is also a well-known methodological issue and standardized methods both for calculating and reporting it are still lacking 30 during the initial phases of an epidemics outbreak only small datasetstime-points can be used some crucial information may be missing and the quality accuracy and reliability of data improves over time in these situations estimations are highly dependent on the specific datasets utilized and revisingupdating such datasets could influence the results we note that several key clinical parameters could be inferred from relevant clinical data based on sero-epidemiological surveys and the possibility of spreading the infection from asymptomatic cases was only reported recently 31our finding of a high reproduction number implies the potential of a very serious epidemic unless rather swift public health interventions are implemented 3233 during the season when the social contacts is the highest note that the serial interval is an essential factor affecting the accuracy of the likelihood function estimation according to the current report the incubation period of wuhan patients with coronavirus pneumonia is about 2 to 15 days we then assume that the serial interval follows the gamma distribution with varying mean and variance which allows us to examine the influence on the reproduction number with the distribution of serial interval with mean 6 days and variance 2 days the likelihood-based estimation of the reproduction number is consistent with the model-based estimation it shows that longer serial intervals induce greater reproduction numbers and hence more new infections which further confirms that the epidemic may be more serious than what has been reported until now 15 based on the reported data we have estimated that the number of people who were identified through contact tracing and quarantined was 5897 as of 22 january 2020 in comparison with the total population size of wuhan the effort of close contact tracing and quarantine was insufficient and appears to have a limited impact in terms of reducing the number of infected cases andor slowing down the epidemic the contour plot of rc  1 gives the threshold values of contact rate and quarantine rate for a city to avoid an outbreak this high threshold rate of quarantine puts an extremely high requirement for the citys public health infrastructure and its citizens adherence to personal protective and public health interventions including a reduction of transmission-effective contacts separation and restriction during the quarantine such a high level of quarantine rate and reduction of contact is possible only when the number of imported cases from the epicenter is minimal speaking in terms of the value of the travel restriction a strict travel restriction to the city of wuhan is expensive and resource-consuming imposing a substantial challenge to the decision- and policy-makers and the citys resilience moreover such a measure could only delay the transmission of the infectious disorder in conclusion our simulations show that the appropriate duration of this travel restriction depends on a combination of effective quarantine and reduction of contact within the cityconsidering the latest events the lock-down of wuhan on 23 january 2020 the adoption of the travel restriction strategy by other regions and provinces the introduction of new detection technologies etc the present model needs to be revised in that the basic reproduction number estimated here is no longer suitable for predicting future epidemic trends table 4 this will be the aim of a forthcoming articlecoronaviruses occasionally lead to major outbreaks with documented reproduction numbers ranging from 20 to 49 currently a fourth large-scale outbreak is occurring and spreading out from wuhan hubei province china to neighboring provinces and other countries there is a dearth of epidemiological data about the emerging coronavirus which would be of crucial importance to design and implement timely ad hoc effective public health interventions such as contact tracing quarantine and travel restrictions in this study we adopted a deterministic model to shed light on the transmission dynamics of the novel coronavirus and assess the impact of public health interventions on infection we found that the basic reproduction number could be as high as 647 95 ci 571723 which seems consistent with the special period prior to the spring festival when contacts were higher than usual and with the opinion that the virus has gone through at least threefour generations it is worth mentioning that our model made a very good prediction of the confirmed cases from 23 to 29 january 2020 as shown in table 4 particularly the predicted confirmed cases should be 7723 as of 29 january 2020 which is very close to the real number of cases of 7711 furthermore according to our model the outbreak under the most restrictive measures is expected to peak within two weeks since 23 january 2020 with a significant low peak value our investigation has major practical implications for public health decision- and policy-makers the rather high reproduction number suggests that the outbreak may be more serious than what has been reported so far given the particular season of increasing social contacts warranting effective strict public health measures aimed to mitigate the burden generated by the spreading of the new virusthe covid-19 pandemic has created unprecedented challenges for the medical and clinical diagnostic community the fight against covid-19 is being supported by a number of databases and artificial intelligence ai-based initiatives aimed at assessing dissemination of the disease 1 aiding in detection and diagnosis minimizing the spread of the disease and facilitating and accelerating research globally 2-7prominent among these initiatives are the covid-19 open research dataset cord-19 8-10 and databases curated by the cdc 1112 nlm 13 and the who 14 ai-powered tools such as those from wellai 1516 and the allen institute for ai scisight 17-19 and contact tracing based on mobile communication technology 2021the cord-19 dataset has resulted from a partnership between the semantic scholar team at the allen institute for ai and leading research groups chan zuckerberg initiative georgetown universitys center for security and emerging technology microsoft research the kaggle ai platform google and the national library of medicinenational institutes of health in coordination with the white house office of science and technology policypublications in the collection are sourced from pubmed central the biorxiv and medrxiv preprint servers and the who covid-19 database cord-19 is freely available downloadable and it is updated weekly the collection currently contains over 128000 publications with over 59000 full text as of 26 may 2020 on the disease covid-19 and the virus sars-cov-2 and related coronaviruses it is part of a call to action to the ai community to develop ai techniques in order to generate new insights to assist in the fight against covid-19 9 this call to action has been informed by a series of tasks described in the form of a series of questions that are listed in table 1 22wellai has developed a machine learning ml search and analytics tool based on four neural networks and incorporating the complete list of nih medical categories unified medical language system umls semantic types for interrogation of the cord-19 dataset and this is available at httpswellaihealthcovid 16 it is now widely agreed that ml has significant applications in the physical and biological sciences 28 in the wellai covid-19 application a subset of ml -- ie neural networks  is being used neural networks facilitate discovery of highly complex and nonlinear relationships between sets of variables without having to search for a closed form mathematical solution neural networks can contain tens of thousands to millions of variables and this is the basis of their power the complexity of relationships neural networks can uncover is difficult to fathom but is enabled by an ever-increasing computing power somewhat surprisingly one of the biggest trends of the past 10 years is the increasing scientific role of neural network models of a language at first glance it seems counterintuitive that something so qualitative and subjective as language plays a role in learning about physical or biological sciences which by their nature strive for precision however nlp is set to play a major role in scientific learning over the coming decades because arguably the biggest problem for scientists today is an ever-growing body of data which defies any traditional tools of comprehension 29 for example the cord-19 dataset already contains 128000 articles digesting such a vast amount of information quickly can only be done by the nlp methods and can extend beyond capturing known knowledge and reveal new information and hidden connections 27the wellai covid-19 application uses nlp neural networks to learn from the cord-19 dataset in order to summarize existing knowledge it can also be used to make discoveries in an unsupervised manner this application is based on unsupervised learning 19 20 but its main goal is to enable a researcher to generate ideas for the next set of concepts that are relevant to the discovery the umls concepts are used as variables in the model and these concepts provide a vast terminology crucially they deal with synonymy and by including all of the synonyms the number of umls concepts increased to 4224512 only 60892 concepts are used in the wellai covid-19 model grouped into 69 categories or umls semantic types broader wellai models are based on 25 million medical articles and use millions of conceptsthese concepts are a helpful starting point however they had to be altered for wellai models because they are somewhat outdated specifically when it comes to the terminology surrounding the novel coronavirus the altered concepts were applied to the cord-19 dataset this whole process was not trivial because application of concepts requires context different words can mean different things in different contexts complex ml models sensitive to the context of an article needed to be developed a series of wellai neural network models have been utilized to learn relationships between medical concepts relationships of any single concept to a set of concepts along with probabilities strength of the relationship is routine however it is more difficult to work with a group of concepts as inputs especially if the number of variables is not constant a researcher may use any number of concepts as a starting point of their research and a model was developed that can accept any number of concepts as inputs and update predicted related concepts along with actionable probabilitiesat a practical level searching the cord-19 data-set using the wellai tool begins with the results of the initial analysis based on covid-19 and sars coronavirus as the preloaded concepts and this produces a list of 69 concept categories each concept category has an associated list of concepts ranked according to their significance in relation to covid-19 based on log probability or negative log likelihood loss 30 of the strength of the concept relationship to covid-19 according to the wellai neural networksfor clinical diagnostics there are several relevant major concept categories in the list including diagnostic procedure laboratory procedure laboratory or test resultassociated with each major concept category is a list of related concepts each linked to relevant publications read articles the search can be refined by adding any of the concepts to the selected concepts list a rerun of the search find by selected concepts option produces the new lists of concepts that are most related to the new list of selected concepts figure 1underlying this ai-powered tool is a network of servers that make the searching quick and seemingly effortless significantly most of the questions in table 1 could be answered by the wellai covid-19 tool by entering a concept eg transmission mode or looking at the relevant concept category eg gene or genome for virus genetics and virus origin questionscisight is an ai-powered visualization tool for exploring associations between concepts appearing in the cord-19 dataset and visualizing the emerging literature network around covid-19 17-1931 it is available at httpsscisightappsallenaiorg 17 scisight is based on scibert a pretrained language model trained on a large corpus of scientific publications to provide improved performance in natural language processing 32 initially scisight provides four different search options namely two scientific concepts that are important to the study of the virus proteinsgenescells and diseaseschemicals and a network of science search and a faceted searchthe user can explore associations between either of two preselected scientific concepts  proteinsgenescells or diseaseschemicals in the cord-19 dataset as follows selection of one of the preselected concepts displays the try list below the search box and this lists salient keywords with high relevance to sars-cov-2 there is also a graphical display of the network of associations between the preselected scientific concept and the top related terms mined from the dataset the thickness of the edges signifies that terms are co-mentioned more often in close proximity to each other in publications in the database clicking on an edge reveals the list of linked full text papers and hovering over a term reveals co-mentioned terms this is illustrated in figure 2 for the associations between the preselected concept diseaseschemicals and the key words virus infection selected from the try list alternatively one of two preselected scientific concepts can be chosen and a search term entered this generates and displays a list of autocompleted search suggestions selecting one of these suggestions again displays the network of top associations in the dataseta network of science search option allows the user to visualize research groups and their ties in the context of covid-19 searches can be by topics affiliation or authors or by the seven preloaded topics in the try list multiple combinations of topics affiliation or authors can be selected results are shown as a network of boxes that are color coded from high to low relevance each box shows top authors top affiliations and top topics in a group and the color-coded links between boxes reveal shared authors or topics selection of a box provides a list of publications relating to the contents of that particular box also results are ranked within each topic category eg author by means of a shaded baranother search option is faceted search this reveals how authors and topics interact over time in the context of covid-19 searches can be made by selecting combinations of author co-author characteristic intervention outcome journal license or source andor by selecting one of seven preloaded topics in the try list multiple combinations of topics affiliation or authors can be selected results are ranked within each topic category eg author by means of a shaded bar and a list of relevant publications and a graphic shows the number of papers per yearpopulation-wide datasets are now emerging that show the response of society to covid-19 the data includes commonly used terms in internet search engines satellite mapping data of human activity and the emerging interactive data from digital contact tracing contact tracing is an essential monitoring process for combating the spread of an infectious disease 19-21 it comprises three basic steps 1 contact identification 2 contact listing and 3 contact follow-up - and it forms one part of the test trace and quarantine mantra conventionally contact tracing is a manual process relying on finding individuals who have tested positive and then interviewing those individuals to identify all individuals who need to be quarantined the widespread availability of mobile communication technology eg smartphones is providing new ways of enabling contact tracing by using bluetooth to track nearby phones keep logs of those contacts and to warn people about others with whom they have been in contact in the digital age contact tracing can be passively achieved and integrated with diagnostic testing results on an individual level the actions can be bi-directional an individual can test positive and then initiate a cascade of notifications of all recent contacts alternatively an individual can be notified that they were in bluetooth proximity to an anonymous person who has tested positive public health authorities empowered with digital tracing can quickly identify positive contacts with a minimal workforcein the us apple and google are collaborating on tracking technology for ios and android smartphones 33 elsewhere in the world an example of a contact tracing app is trace together which has been deployed in singapore 3435 if a person is found to be positive for covid-19 then the app uses a smartphones bluetooth network to notify every participating trace together user that person was within 2 meters of for more than 30 minutesin china the alipay health code on the alipay app dictates freedom of travel based on three categories green for unrestricted travel yellow for a seven-day quarantine and red for a two-week quarantine 36 in south korea people receive location-based emergency text messages from the government to inform them if they have been in the vicinity of a confirmed case of covid-19 37 in italy the app immuni 3839 combines a personal clinical diary and contact tracing anonymous identification codes are generated by the users app rather than a central server in order to improve privacy by placing identification on the individual users device the contact tracing information is separate from identification the app complies with the european model outlined by the pepp-pt pan european privacy-preserving proximity tracing consortium 40 it is delivered for free and on a voluntary basis there has been resistance to app-based monitoring 39 but the italian government expect 60-70 of people will download the app in the uk a contact tracing app nhs covid-19 is currently being trialed in a limited geographical area with a population of 140000 41 this app registers duration and distance between devices and the data is fed into a centralized system where a risk algorithm estimates infection risk and triggers notificationsother examples of pandemic data infrastructures include the google tool covid near you to identify patterns and hot spots by location zip-code 42 covid trace 43 that warns of exposure to covid-19 by comparing your locations over the previous 3 weeks against the time and locations of reported exposures coronapp which provides localized real-time data about covid-19 based on the geographic location of their smartphones 44 and a hashtag tracking tool for the evolution of covid hashtags on twitter 628 million tweets about covid-19 45 twitter is also being used to understand the impact of covid-19 eg psychological impact 46 one significant concern over digital contact tracing has been ethical issues eg privacy and the consequent impact on the rate of adoption of the apps 4748 some technology developers are focused on developing tracing apps that ensure privacy protection 49currently in response to covid-19 clinical laboratories and the ivd industry are grappling with test development test validation fast-track clearance eg emergency use authorization 50 availability of analyzers tests and related supplies and testing capacity for both molecular tests for sars-cov-2 and tests for igmigg antibodies against this virus 5152 once these issues have been resolved the next major hurdle will be contact tracing to reduce the risk of future outbreaks ai-powered tools will be valuable to identify trends and associations between digital contact tracing tests and outbreaks of diseaseeasily accessible ai-powered tools and databases are valuable in all types of research but especially so in the context of the urgent diagnostic and therapeutic challenges presented by the covid-19 pandemic it is hoped that the new ai-powered search tools will accelerate research and development in covid-19 as the world strives to develop efficient and timely testing and effective therapies to combat this disastrous pandemic another important part of our fight against covid-19 will be efficient digital contact tracing enabled by mobile communication technology linked with massively scaled-up testing as outlined in the recent roadmap to pandemic resilience 53coronavirus disease code-named covid-19 is an infectious disease caused by a virus a member of the betacoronavirus family named severe acute respiratory syndrome coronavirus 2 sars-cov-2 previously referred to as 2019 novel coronavirus 2019-ncov 1 2 it is thought that the virus outbreak has animal origins and it was first transmitted to humans in wuhan province china in novemberdecember 2019 35at present no approved vaccines or specific antivirals are available for covid-19 6 7 previous sars pandemic in 2002 and 2003 was controlled and finally stopped by conventional control measures including travel restrictions and patient isolation currently these measures are applied in almost all countries with the covid-19 outbreak however their effectiveness depends on how rigorous they are 8 9 it follows that the methods enabling reliable prediction of spreading of covid-19 would be of great benefit in persuading public opinion why it is crucial to adhere to these measures in the past decade 10 11modeling viral diseases such as covid-19 is extremely important in determining their possible future impact modeling the spread and the effect of such a disease can be supremely important in understanding its impact 12 while traditional statistical modeling can offer precise models 13 artificial intelligence ai techniques could be the key to finding high-quality predictive models 14 in this paper the authors present a machine learning solution a multilayer perceptron mlp artificial neural network ann 15 to model the spread of the disease which predicts the maximal number of people who contracted the disease per location in each time unit maximal number of people who recovered per location in each time unit and maximal number of deaths per location in each time unit mlp has been selected for its simplicity in comparison to other ai algorithms due to authors wishing to test the possibility of modeling using comparatively simple methods due to shorter training time associated with such methods because the quick generation of results is important when modeling diseases due to the as-fast-as-possible requirement for models with good enough regression performance modeling can be done on existing data using statistical analyses but when it comes to extremely complex models statistical analysis can fail to comprehend the intricacies contained in the analyzed data 16 more complex algorithms namely ai algorithms and especially machine learning algorithms can be used to learn not just the general trend but the intricacies of the data which results in higher quality models produced 10 ai algorithms have become increasingly applicable in various branches of science and industry ie medicine 17 for the classification of various diseases as well as creating regression models for estimation and prediction models obtained by machine learning techniques adjust their parameters to fit their predictions to existing data no matter what it contains by doing this the models take into account interinfluences of various input parameters that might not have been taken into consideration if traditional modeling methods were used 11 this ability to take into account hard to observe intricacies stored inside data should lend itself well when used in an attempt of regressing a complex model such as spread of covid-19 currently existing models of covid-19 spread have relatively poor results 18 or have made predictions which were proven to not correlate to real data 19 20in the research presented the aim was to achieve an accurate regression model through the utilization of an ai algorithm using the data that existed during the time in which this research was performed this was done in order to demonstrate the possibility of using ai algorithms in early modeling of infective disease such as covid-19 spread the aim of the model is to observe all the collected data together instead of separating it into localities as that mode of observation could allow a machine learning method to achieve a better global model of viral spread mlp algorithm is trained using a novel coronavirus covid-19 cases 21 by john hopkins csse at the time of this research being performed the dataset contained 20706 data points and was split into the training 7515530 data points and testing 255176 data points sets the hyperparameters of the mlp are determined using a grid search algorithm the robustness of the different models is tested using k-fold cross-validation algorithm achieved results are then evaluated using the r2 metric a detailed look upon the techniques used has been given in materials and methodsdataset used in this research is obtained from a publicly available repository operated by the johns hopkins university center for systems science and engineering jhu csse and supported by esri living atlas team and the johns hopkins university applied physics lab jhu apl 21 it contains the data for the coronavirus patients which describe the number of patients in a certain location defined by the name of location latitude and longitude for each day since the start of the covid-19 infections 22nd of january 2020 until 12th of march 2020 dataset is split into three groupsinfected recovered and deceased at the time of this research being performed the dataset contained the data for 406 locations and 51 days the geographical distribution of data contained in the dataset is given in figure 2 which shows the geographical distribution of infected patients at various points in timedataset as published is organized as time-series datashowing the spread of disease in various locations over time the data collected at the time of this research being performed was insufficient to attempt a time-series ai modeling to train the mlp the dataset is rearranged to create a set of inputs and outputs for each number of cases the latitude and longitude of the location as well as the date of data collection is added the date is converted into the number of days since the first entry into the dataset in this way each data point contains information about the number of patients contracted recovered or dead at a given location at a given day since the first noted case latitude longitude and the number of days since the first case are used as input data with the output data being the number of patients in each group in this manner the time-series dataset is rearranged in a manner that makes it appropriate to train a regressive mlpfinally the dataset consisting of a total of 20706 data points is randomly split into five equal parts or so-called folds each of these parts is used as a testing set with the remaining parts used as a training set this means that training for each architecture is repeated 5 times with an 8020 16565 randomly selected data points for training and 4141 data points for testing set training-testing distributionmultilayer perceptron mlp is a type of a fully connected feed-forward artificial neural network ann consisting of neurons arranged in layers 11 at least three layers make up mlp an input layer an output layer and one or more hidden layers the output layer consists of a single neuron the value of which is the output of the mlp annin the presented research this is the predicted number of patients the input layer consists of the neurons in the same number as the dataset inputs 22 mlps used in this research will as such have 3 neurons in the input layerone for each of the input data points latitude longitude days since infectionthe reason for selecting mlp as the method used in this research was the ease of implementation of such methods mlp is also known to provide high-quality models while keeping the training time relatively low compared to more complex methodsmlp is based on calculating the values of neurons in a current layer as the activated summation of weighted outputs of neurons in a previous layer connected to the neuron 22 23 activation refers to the sums of weighted inputs being used as inputs to the so-called activation function which maps the input to the output either directly identity activation within certain limits sigmoid or tanh or maps it while removing unwanted values eg relu which removes negative values and maps positive ones directly 24 the weights of the neuron connections are initially random but then adjusted through the backward propagation process in which the error for a forward propagated of the mlp results gets back-propagated through and weights are adjusted proportionally to the error 25due to the fact that mlp regressor can only regress a single value if the problem consists of multiple output values a modular model consisting of multiple models must be used while similarities are possible between models training the models completely separately means that all the architectures will be tested giving a higher chance to finding a better prediction model for each goal in the research presented three separate mlps are trainedone for each of the goalsinfected recovered and deceased patientsto confirm the validity of the results the cross-validation process has been performed the cross-validation method used in this research is the k-fold algorithm 22 26 during this process the dataset is split into k subsets in presented case k  5 then each of them is used as a testing set while the remaining k  1 subsets are used as a training dataset 27 the result is then presented as the average of achieved scores with standard deviation notedthe solution has been implemented using python 38 programming language using scikit-learn library 28 scikit-learn has been selected due to ease of use as well as the fact that it contains the implementation of most of the methods used in this research 29 activestate activepython implementation of python and needed libraries has been used 30 training has been performed using a high-performance computer hpcbura supercomputer to train the models 16 hpc nodes each containing 48 logical cpus 24 physical cores on intel xeon e5 with 64 gb of ram per each node 31resulting in total of 768 logical cpus used the operating system used is red hat enterprise linux with kernel version 3100-957hyperparameters are values which define the architecture of the ann model correct values of hyperparameters are crucial in achieving a quality model to determine the best hyperparameter combination the grid search algorithm has been usedthe grid search algorithm takes a set of possible parameters for each of the adjusted hyperparameters then each possible combination of hyperparameters is determined 32 each of the combinations is used to train the mlp to avoid the possibility of poor solutions due to the initial random setting of the weights each set of hyperparameters is used for training three times each of the achieved models is then evaluated the hyperparameters adjusted in performed research are 28 29
solverthe algorithm used for recalculating the weights of the mlp during back propagation process in traininginitial learning rate value of learning rate at the beginning of trainingadjustment of learning ratethe way the learning rate will change during the training and if it will be adjusted depending on the current value of cost function or notnumber of hidden layers and neuronsdefined as tuple in which each integer defines a single hidden layer and the integer value defines the number of neurons in that layeractivation functionfunction used to transform the input values of the neuron to the output value of the neuron andregularization parameter l2parameter which limits the influence of input parameters to avoid the ann being trained with a bias towards a single input value which has a high correlation to the output larger the parameter more is the influence loweredpossible hyperparameter values are given in table 1every obtained model is evaluated using the coefficient of determination r2 the coefficient of determination defines how well is the variance which exists in the real data explained with the predicted data the real output data the actual number of patients is contained in the vector y while the predicted data obtained from the trained model is set into the vector y with that the coefficient of determination r2 can be determined as the coefficient between the residual variance and total variance 33
1r21sresidualstotal1i0myiyi2i0myi1mi0myi2with m being the number of evaluated samples length of vectors y and y r2 is defined in the range r2 01 with the value of 00 meaning that none of the variances in real data is explained in the predicted data and the value of 10 being the best possible value meaning all of the variances is explained in the predicted datadue to cross-validation being used each architecture is trained 5 timeson differing data to present the results of cross-validation the average of r2 scores is calculated r215i15ri2 to show the variance between the scores on different folds the standard deviation of the r2 scores is also presented t15rt2r25best models achieved show a high-quality regression with r2 scores of 098599 for the confirmed patient model 097941 for the recovered patient model and 099429 for the deceased patient modelthe best models achieved for all three goals number of infections recoveries and deaths have a same basic ann architecture these architectures consist of four hidden layers and 16 total hidden neurons distributed equally among layers4 neurons eachbest models for all three outputs also use the relu activation function and the lbfgs solver the best model for confirmed cases has a constant learning rate of 01 and has a regularization parameter of 00001 for the recovered cases mlp uses a constant learning rate of 05 and a regularization parameter of 0001 the model for predicting the number of deceased patients uses the adaptive learning rate of 001 with the regularization parameter set at 01 the hyperparameters of the best models are listed in table 2
figure 3 shows the comparison of real data to data obtained from the model real data sorted by days as well as trends for all three modeled cases are shown in subfigures subfigures a c and e demonstrate the comparison of real data sorted by date for various locations and the data predicted by model each bar presents a number of patients in a given group per location for easier viewing the maximum of each daily count is plotted as the envelope of the plotted data in b d and f these envelopes show an approximation of maximal disease spread per patient group for both real data and modeled data which shows that the modeled data follows the collected data closely  table 3 shows the cross-validation results achieved for the best models shown in table 2training time using 5-fold cross-validation on the system used and described in the materials and methods section is shown in table 4 taking into account 5376 training items and training repeated 5 times due to cross-validation for a total of 26880 models trained this means that the average model training time is 0088 minutes or 526 secondsresults show that a similar architecture can be used for all three models suggesting a similar trend between all three goals the use of the relu activation function is not unexpected as it eliminates the negative values it is logical it is going to lend itself well to a model which predicts only positive values learning rates differ between models both the models for infected and recovered use a relatively high constant learning rate while the deceased model uses a significantly lower learning rate but adapts over iterations the regularization parameter is relatively low for the model of infections but raises for the recovered and deceased modelspointing to the fact that there is a higher influence of certain input parameters on the output of those models which needed to be suppressedmodels show poor tracking of sudden and unexpected changes such as the sudden jump in infections around day 22 still the model demonstrates good tracking of overall model change giving good predictions even after such unexpected leapsif given time to adjust due to the largest number of cases being located in china the model is largely fitted to that data future changes in the maximum number of infected deceased or recovered patients should be included in the model to further test its robustnesscross-validation performed shown across the solution space shows a drop in r2 scores the model for deceased patients shows the lowest drop in scoring used the model of confirmed cases shows a more significant drop from 0986 to 094 but these results are still acceptable the highest drop is shown in the model of recovered patients where r2 score drops from 097941 to 0781 showing the low robustness of the model for recovered patients the architectures of the models that show the best results remain the same when cross-validation is appliedthe aim of this research which was to generate a model of coronavirus disease spread on a global level using machine learning methods was achieved the created models show a high fidelity to existing data with the exception of the model for recovered patients in comparison to already designed models presented models show a higher accuracy as well as tracking of deaths and recoveries additionally the presented model is created using a simpler ai algorithm and uses a comparatively simple architecture which has performance benefits in terms of computational time and resources 22 results demonstrate a clear ability to mathematically model a spread of an infective disease using ai on a relatively limited dataset meaning that comparatively long periods of data collection are not strictly necessary to achieve a good model with ai algorithms obtained results point towards the ability to use such algorithms to model similar phenomena in the futurethe achieved models show that it is possible to acquire a quality model of novel viral infections using ai methods with geographical and time data as inputs in this research high accuracy models have been achieved for all regression goals achieved results prove the fact that ai models can be used in modeling problems such as the spread and effect of infectious diseases this means that the application of ai methods should be attempted in modeling the present and future spread of infective diseases in an attempt to predict the impact of such infections on humankind model fitting to largely the chinese patient population shows that using the number of patients per country is not necessarily a good metric to use as a training goalfurther research should be invested in testing how different types of metrics eg percentage of disease in population affect model quality the code and models achieved can be found at a public repository made available by the authors 34 authors are also planning on the implementation of achieved models inside an easy to use and widely accessible web-interfacefuture work should apply other methods in an attempt to find even better models or models that are simpler to use or more transparent than ones observed with mlp comparison of models for different infective diseases would be interesting more data being acquired should enable the use of other techniques such as recurrent neural networks to be applied on the analyses of infection models using time-series datathe pandemic of the atypical pneumonia coronavirus disease covid-19 caused by a novel beta coronavirus sars-cov-2 has significantly impacted global society from both an economic and public health standpoint as a result biomedical scientists around the world  from academic and government laboratories to biotechnology companies and pharmaceutical corporations  have mobilized to understand the disease to develop therapeutic interventions to mitigate its impact and to develop protective vaccines this rapid research response has resulted in the initiation of repurposing clinical trials for a range of agents including three that have received emergency use authorizations euas from the federal drug agency fda in the united states remdesivir1 chloroquine and hydroxychloroquine these drugs and others that have entered clinical trials were prioritized based on clinical observations or a contemporary understanding of sars-cov-2 biology in addition numerous drug repurposing efforts have been undertaken screening both approved and experimental agents210 yet many published reports solely focus on active hits and do not disclose the majority usually 95 of tested compounds that were inactive  information that is critical for understanding and validating disease and drug mechanism-of-action and for nominating repurposed and novel clinical lead candidates rapid and open sharing of complete screening datasets including negative results will greatly accelerate the research and discovery process essential to the covid-19 pandemic responseto address this the national center for advancing translational sciences ncats has developed an online open science data portal for its covid-19 drug repurposing campaign  named opendata  with the goal of making data across a range of sars-cov-2 related assays available in real-time figure 1 this approach allows researchers rapid access to drug repurposing datasets that can support subsequent mechanistic study of compounds that perturb viral infectivity11 in this manner open data sharing can facilitate important insight and associated publications towards the development of interventions against covid-19 the opendata dashboard first shared publicly on may 25 2020 makes quantitative high-throughput screening hts data and detailed protocol information available for every assay screened the goal is to provide clinicians and researchers with a user-friendly tool that allows direct comparison of compounds across multiple assays with all primary concentration-response data made freely available through direct download httpsopendatancatsnihgovcovid19the assays that have been developed to date cover a wide spectrum of the sars-cov-2 life cycle figure 2 including both viral and human host targets grouped into the following five categories based on different mechanisms of experimental design viral entry viral replication in vitro infectivity live virus infectivity and counter-screens which could flag false positives due to assay interference artifacts or cytotoxic effects these assays encompass protein-based assays such as the sars-cov-2 spike protein-ace2 interaction and viral enzyme activity assays in addition to cell-based pseudotyped particle entry and live virus cytopathic effect assays as additional assays are validated and screened this list will be expanded and updated importantly all assay documentation including assay overview methodology and detailed assay protocols are available and readily retrievable on the opendata site to facilitate adoption and ensure that other laboratories can replicate these assays table 1in total over 10000 compounds are being tested in full concentration-response ranges from across multiple annotated small molecule libraries including 1 the ncats pharmaceutical collection npc a library of 2678 compounds approved for use by the food and drug administration and related agencies in other countries1213 2 a collection of 739 anti-infective compounds with potential anti-coronavirus activity that have been reported in the literature as repurposing candidates and 3 an annotatedbioactive collection of diverse small molecules with known mechanisms of action including as small molecule probes and experimental therapeutics designed to modulate a wide range of targets such as natural products epigenetic-associated compounds or compounds developed for oncology indications1415 together these libraries yield 9958 compound responses 8624 of which represent structurally unique compounds of which 1820 21 are approved for use in humans with an additional 989 11 having entered human clinical evaluation phase 13 trials importantly of these unique compounds 5224 60 have at least one annotated target providing insight into potential mechanism-of-action underlying active compounds that perturb the sars-cov-2 life cycle in some mannera key goal of the opendata portal is to allow users to view and inspect the concentration-response data for all compounds screened not limited to only active compounds these complete datasets including full concentration-response information and compound annotations can be directly downloaded providing extensive information for further analysis and data mining in addition a user-friendly heatmap visualization has been implemented to allow direct and convenient comparison of compound activity across the panel of all assays tested including orthogonal and counter assays figure 3currently the opendata portal can be queried by a search term eg drug name primary mechanism-of-action gene symbol and ordered by any assay data field for increased interpretability a high-level overview of compound activity across multiple different assays is displayed by heatmap with sort functions based on curve class efficacy and potency in the heatmap darker colors indicate compounds that are more potent and efficacious ie high-quality actives lighter colors indicate less potent and efficacious compounds low-quality actives beige represents inactive compounds and slashed boxes denote compoundsassays not yet testedin addition to the ncats covid-19 drug repurposing screening data described above two regularly updated external resource sections have also been incorporated into the opendata portal a collection of publications focusing on small molecule drug repurposing screens and a list of publicly available multiomics datasets generated to evaluate aberrant biochemical pathways or identify putative biomarkers for covid-19in summary the opendata portal described herein has been designed to share ncats sars-cov-2 complete datasets openly and without restriction and importantly in real-time given the time urgency of covid-19 pandemic response in addition we have constructed the portal such that hts datasets from studies published by other investigators can be integrated into the portal to allow a global view of covid-19 drug repurposing efforts and enable comparison of screening hits across multiple centers we envisage this site could act as a central portal and a unique resource to compare complete repurposing data generated in both the public and private sectorsthe authors welcome contributions of external hts data we hope that this platform will help research scientists clinical investigators and public health officials to facilitate open data sharing and analysis to expedite the development of sars-cov-2 interventions and to prioritize promising compounds and repurposed drugs for further development in treating covid-19on 30 january 2020 the world health organization who declared the current outbreak of the novel coronavirus 2019ncov which was first detected in the chinese city of wuhan on 31 december 2019 a public health emergency of international concernan alarm it reserves for events that pose a risk to multiple countries and which requires a coordinated international response previous studies have confirmed that this virus can spread from person to person after identifying clusters of cases among families as well as transmission from patients to healthcare workers
1
 
2
 as of 3 february 2020 there have been 20 438 cases of 2019ncov confirmed in mainland china including 2788 serious 425 deaths and 632 discharged as well as 15 in hong kong 8 in macao and 10 in taiwan more than 150 cases had also been confirmed in at least 18 other countries on four continents in epidemiological studies the basic reproductive number r
0 is defined as the possible number of infection cases generated from a single infected person at a particular time point during an outbreak and is often used to describe transmission dynamics over the course of a disease epidemic on the basis of earlier research the initial r
0 was estimated to be 22 95 confidence interval 14 to 39 among the first 425 patients with 2019ncovinduced pneumonia
2
 consistent with the preliminary estimate of 14 to 25 presented by the who during their international health regulations emergency committee meeting on the 2019ncov outbreak it is possible that subsequent control measures such as the strict travel restrictions in wuhan and china as well as overseas may change or reduce the r
0 value over the course of the virus outbreak of note the coronaviridae family not only includes 2019ncov but also severe acute respiratory syndrome coronavirus sarscov middle east respiratory syndrome coronavirus merscov and the common cold viruses in immunocompetent individuals eg 229e oc43 nl63 and hku1
3
 the sarscov pathogen was responsible for the 20022003 outbreak of sars in guangdong province china which resulted in more than 8000 cases and 774 deaths in 37 countries worldwide
4
 
5
 
6
 the merscov pathogen was responsible for the 2012 outbreak of mers which resulted in 2494 cases and 858 deaths in 27 countries worldwide
7
 
8
 notably both sarscov and merscov are zoonotic in origin with prior studies revealing bats to be the animal host source
9
 
10
 
11
 
12
 and masked palm civets
13
 
14
 
15
 and camels
16
 
17
 to be the intermediate animal hosts between bats and humans of the two diseases respectively recent research has also reported that the 2019ncov virus is 96 identical at the genome level to a previously detected bat coronavirus which belongs to a sarsrelated coronavirus species ie sarscov
18
 like sarscov merscov and many other coronaviruses 2019ncov likely originated in bats but it remains unclear whether an intermediary animal host was involved before the virus jumped to humans as reported in earlier research however although bats could be the original host of 2019ncov the virus may have initially been transmitted to an intermediate animal host sold at the wuhan huanan seafood wholesale market thus facilitating the emergence of 2019ncov in humans
19

in the present study we investigated the time origin and genetic diversity of 2019ncov in humans based on 32 genomes of virus strains sampled from china thailand and the usa with known sampling dates between 24 december 2019 and 23 january 2020 we conducted a comprehensive genetic analysis of four 2019ncov genome sequence datasets ie dataset14 dataset24 dataset30 and dataset32 and elucidated the transmission dynamics and evolutionary history of the virus outbreak in china thailand and the usa these analyses should extend our understanding of the origins and dynamics of the 2019ncov outbreak in china and elsewhereas of 28 january 2020 33 genomes of 2019ncov obtained from humans have been released on gisaid httpgisaidorg
20
 the betacovwuhanipbcamswh022019 epiisl403931 sample shows evidence of sequencing artifacts due to the appearance of clustered spurious singlenucleotide polymorphisms and thus was excluded in this study the final dataset dataset32 included 32 genomes of 2019ncov from china n  25 thailand n  2 and usa n  5 with sampling dates between 24 december 2019 and 23 january 2020 of the 25 samples collected from china 14 were from wuhan hubei province 6 were from shenzhen guangdong province 2 were from zhuhai guangdong province 2 were from hangzhou zhejiang province and 1 was from taiwan table s1 the sampling dates of betacovshenzhenhkusz0052020 and betacovshenzhenhkusz0022020 were known to the nearest month january 2020 for this dataset the 2019ncov genomes were aligned using mafft v7222
21
 and then manually curated using bioedit v725
22
 in addition we subsampled three other datasets that is dataset14 collected between 24 december 2019 and 1 january 2020 comprising 14 genomes from wuhan hubei province china dataset24 collected between 24 december 2019 and 18 january 2020 comprising 24 genomes from china and thailand and dataset30 collected between 24 december 2019 and 23 january 2020 comprising 30 genomes from china thailand and usato assess the recombination for the full dataset ie dataset32 we employed the pairwise homoplasy index phi test to measure the similarity between closely linked sites using splitstree v4151
23
 the bestfit nucleotide substitution model for dataset32 was identified according to the akaike information criterion aic smallsample corrected aic aicc bayesian information criterion bic and performancebased decision theory dt method with 3 24 candidate models or 11 88 candidate models substitution schemes in jmodeltest v2110
24
 to evaluate the phylogenetic signals of the datasets we performed likelihoodmapping analysis
25
 using treepuzzle v53
26
 with 35 000 to 80 000 randomly chosen quartets for the four datasets maximumlikelihood ml phylogenies were reconstructed using the hasegawakishinoyano hky nucleotide substitution model in phyml v31
27
 bootstrap support values were calculated with 1000 replicates and trees were midpoint rooted regression analyses were used to determine the correlations among sampling dates and roottotip genetic divergences of the four ml phylogenies using tempest v15
28

to reconstruct the evolutionary history of 2019ncov bayesian inference through a markov chain monte carlo mcmc framework was implemented in beast v184
29
 with the beagle library program v212
30
 used to improve computation for each dataset we employed hky as well as a constant size coalescent tree prior and strict molecular clock model to estimate the time to a most recent common ancestor tmrca we then used two schemes to set the time scale prior for each dataset that is constrained evolutionary rate method with a lognormal prior mean  10  103 substitutions per site per year 95 bayesian credible interval bci 1854  1044  103 substitutions per site per year placed on the evolutionary rate parameter based on previous studies
31
 
32
 
33
 and the tipdating method for which the evolutionary rate for each dataset was also estimated to ensure adequate mixing of model parameters mcmc chains were run for 100 million steps with sampling every 10 000 steps from the posterior distribution convergence was evaluated by calculating the effective sample sizes of the parameters using tracer v171
34
 all parameters had an effective sample size of more than 200 indicative of sufficient sampling trees were summarized as maximum clade credibility mcc trees using treeannotator v184 after discarding the first 10 as burnin and then visualized in figtree v144 httptreebioedacuksoftwarefigtreethe hiv transmission cluster engine httpwwwhivtraceorg
35
 was employed to infer transmission network clusters for the full dataset ie dataset32 all pairwise distances were calculated and a putative linkage between each pair of genomes was considered whenever their divergence was less than equal to 00001 001 or less than equal to 000001 0001 substitutionssite tn93 substitution model multiple linkages were then combined into putative transmission clusters clusters comprised of only two linked nodes were identified as dyads this approach detects transmission clusters in which the clustering strains are genetically similar implying a direct or indirect epidemiological connectiondataset32 included 32 genomes of 2019ncov strains sampled from china wuhan n  14 shenzhen n  6 zhuhai n  2 hangzhou n  2 taiwan n  1 thailand n  2 and usa n  5 with sampling dates between 24 december 2019 and 23 january 2020 table s1 the samples were primarily from china 78125 and wuhan 4375 the chinese city identified as the region of the original 2019ncov outbreakfor dataset32 the hky model provided the best fit across the four different methods ie aic aicc bic and dt and two different substitution schemes ie 24 and 88 candidate models and was thus used in subsequent likelihoodmapping and phylogenetic analyses for the four datasets the phi test of dataset32 did not find statistically significant evidence for recombination p  10 likelihoodmapping analysis of dataset14 revealed that 100 of the quartets were distributed in the center of the triangle indicating a strong starlike topology signal reflecting a novel virus which may be due to exponential epidemic spread figure 1a likewise 919 818 and 747 of the quartets from dataset24 dataset30 and dataset32 respectively were distributed in the center of the triangle indicating relatively more phylogenetic signals as additional sequences were analyzed over time figure 1bd ml phylogenetic analysis of the four datasets also showed starlike topologies in accordance with the likelihoodmapping results figure 2 roottotip regression analyses between genetic divergence and sampling date using the bestfitting root showed that dataset14 had a relatively strong positive temporal signal r
2  2967 correlation coefficient  5446 figure 3a in contrast dataset24 had a minor negative temporal signal r
2  44428  102 correlation coefficient  2108 figure 3b whereas dataset30 and dataset32 both had minor positive temporal signals r
2  12155  102 correlation coefficient  1102 and r
2  11506  102 correlation coefficient  1073 figure 3cd on the basis of bayesian timescaled phylogenetic analysis using the constrained evolutionary rate method with a lognormal prior mean  10  103 substitutions per site per year 95 bci 1854  1044  103 substitutions per site per year placed on the evolutionary rate parameter we estimated the tmrca dates for 2019ncov from the four datasets that is 1 november 2019 95 bci 21 july 2019 and 29 december 2019 10 november 2019 95 bci 16 july 2019 and 16 january 2020 21 october 2019 95 bci 20 may 2019 and 19 january 2020 and 15 october 2019 95 bci 2 may 2019 and 17 january 2020 for dataset14 dataset24 dataset30 and dataset32 respectively table 1 furthermore based on bayesian timescaled phylogenetic analysis using the tipdating method we also estimated the tmrca dates and evolutionary rates from dataset30 and dataset32 with resulting showing 6 december 2019 95 bci 16 november 2019 and 22 december 2019 and 6 december 2019 95 bci 16 november 2019 and 21 december 2019 respectively and 17926  103 substitutions per site per year 95 bci 7216  10430558  103 and 18266  103 substitutions per site per year 95 bci 75813  10430883  103 respectively table 1 due to poor convergence in the mcmc chains we did not obtain the tmrca date and evolutionary rate from dataset14 and dataset24 the estimates of the mcc phylogenetic relationships among the 2019ncov genomes from the bayesian coalescent framework using the constrained evolutionary rate method with a lognormal prior mean  10  103 substitutions per site per year 95 bci 1854  1044  103 substitutions per site per year placed on the evolutionary rate parameter and using the tipdating method are displayed in figures 4 and 5 respectively as shown three phylogenetic clusters number of sequences 26 posterior probability 9910 were identified that is guangdong20sf0282020 and guangdong20sf0402020 from zhuhai guangdong province china reported from a family cluster infection usaca22020 and taiwan22020 from usa and taiwan guangdong20sf0122020 guangdong20sf0132020 guangdong20sf0252020 shenzhenhkusz0022020 shenzhenhkusz0052020 and usaaz12020 from shenzhen guangdong province china and usa which included five genomes guangdong20sf0122020 guangdong20sf0132020 guangdong20sf0252020 shenzhenhkusz0022020 and shenzhenhkusz0052020 reported from a family cluster infectionwe considered individuals as genetically linked when the genetic distance between 2019ncov strains was less than 001 substitutionssite this allowed us to identify a single large transmission cluster that included 30 of 32 9375 genomes thus suggesting low genetic divergence for dataset32 figure 6a we also considered individuals as genetically linked when the genetic distance between 2019ncov strains was less than 0001 substitutionssite this allowed us to identify three transmission clusters that included 15 of 32 46875 genomes for dataset32 figure 6b clusters ranged in size from two to nine genomes two clusters which contained two guangdong20sf0282020 and guangdong20sf0402020 and four genomes guangdong20sf0122020 guangdong20sf0132020 guangdong20sf0252020 and shenzhenhkusz0022020 respectively included individuals sampled exclusively from zhuhai and shenzhen respectively the largest cluster of nine genomes included five sampled from wuhan wuhanhu12019 wuhanivdchb012019 wuhanwiv042019 wuhanwiv062019 and wuhanipbcamswh042019 one sampled from hangzhou zhejiangwz022020 two sampled from thailand nonthaburi612020 and nonthaburi742020 and one sampled from usa usail12020on the basis of dataset32 which included 32 genomes of 2019ncov strains sampled from china wuhan n  14 shenzhen n  6 zhuhai n  2 hangzhou n  2 taiwan n  1 thailand n  2 and usa n  5 with sampling dates between 24 december 2019 and 23 january 2020 and subsampled dataset14 dataset24 and dataset30 which included 14 24 and 30 2019ncov strain genomes respectively our likelihoodmapping analysis confirmed additional treelike signals from 0 to 82 182 and 254 over time thus indicating increasing genetic divergence of 2019ncov in human hosts figure 1 of note the strong starlike signal 100 of quartets were distributed in the center of the triangle from dataset14 at the beginning of the virus outbreak suggests that 2019ncov initially exhibited low genetic divergence with recent and rapid humantohuman transmission this result is consistent with the ml phylogenetic analyses which showed polytomy topology from dataset14 figure 2a the genetic divergence from dataset32 and dataset30 was higher than that for dataset14 but still demonstrated minor temporal signals figure 3 using the constrained evolutionary rate method the mean tmrca dates for 2019ncov based on the four datasets ranged from 15 october to 10 november 2019 when using a lognormal prior mean  10  103 substitutions per site per year 95 bci 1854  1044  103 substitutions per site per year placed on the evolutionary rate parameter table 1 this is considered reasonable given the limited genetic divergence and strong starlike signals and is also consistent with our previous study
36
 using the tipdating method the mean tmrca date and evolutionary rate for 2019ncov based on the dataset30 and dataset32 ranged from 16 november to 22 december 2019 and from 17926  103 to 18266  103 substitutions per site per year respectively table 1 the tmrca estimated by the tipdating method was relatively narrower than that determined by the constrained evolutionary rate method we identified three phylogenetic clusters with posterior probabilities between 99 and 10 using bayesian inference figures 4 and 5 we also identified three transmission clusters when the genetic distance between the 2019ncov strains was less than 0001 substitutionssite figure 6 intriguingly only one cluster guangdong20sf0282020 and guangdong20sf0402020 from zhuhai was identified by both phylogenetic and networkbased methods this is a good example showing the differences between phylogenetic posterior probability or bootstrap value and networkbased genetic distance methods however our conclusions should be considered preliminary and explained with caution due to the limited number of 2019ncov genome sequences presented in this studythe first genome sequence of 2019ncov was made public in early january 2020 with several dozentaken from various peoplenow available the genome sequences of 2019ncov have already led to diagnostic tests as well as efforts to study its dispersal and evolution as the outbreak continues we will require multiple genome sequences of samples over the course of the outbreak and from different locations to determine how the virus evolves we also need to gain a better understanding of the viruss biology especially compared to findings from previous studies on the sars and mers viruses for instance 2019ncov can kill cultured human cells entering them via the same molecular receptor as sarscov
18
 therefore it is essential that we isolate share and study virus samples both in china and elsewhere to identify animals that exhibit similar infection to humans for drug and vaccine testing to better understand virus transmission eg airborne or close contact and to develop blood tests for viral antibodies currently 2019ncov has primarily caused severe illness and death in older people particularly those with preexisting conditions such as diabetes and heart disease although this virus does not typically infect or kill young and healthy individuals a 36yearold wuhan man with no known preexisting health conditions has been the youngest victim reported so far in situations where a virus jumps from one animal host to another specieswhich is probably how this coronavirus initially infected humansmost mutations are detrimental to or have no effect on the virus and selection pressure may improve survival in the new host therefore we predict that one or more mutations may be selected and sustained during the 2019ncov outbreak as the virus adapts to human hosts and possibly reduces its virulence as reported in the previous study
37
 however we are uncertain whether this will influence its transmissibilityin conclusion our results emphasize the importance of likelihoodmapping transmission network and phylogenetic analyses in providing insights into the time origin genetic diversity and transmission dynamics of 2019ncov improving the linkage between patient records and genome sequence data would also allow largescale studies to be undertaken such research could directly influence public health in terms of prevention efforts introduced to reduce virus transmission in realtimethe authors declare that there are no conflict of interestsxl conceived and designed the study and drafted the manuscript xl and ac analyzed the data xl ww xz jz qz yl and ac interpreted the data and provided critical comments all authors reviewed and approved the final manuscriptinfection by coronaviruses cov represents a major current global public health concern signaling within and between airway epithelial and immune cells in response to infections by cov and other viruses is coordinated by a complex network of signaling pathway nodes these include chemokine and cytokine-activated receptors signaling enzymes and transcription factors and the genomic targets encoding their downstream effectors takeda et al 2003 stark et al 1998 darnell et al 1994 we recently described the signaling pathways project spp ochsner et al 2019 an integrated omics knowledgebase designed to assist bench researchers in leveraging publically archived transcriptomic and chip-seq datasets to generate research hypotheses a unique aspect of spp is its collection of consensus regulatory signatures or consensomes which rank genes based on the frequency of their significant differential expression across transcriptomic experiments mapped to a specific signaling pathway node or node family by surveying across multiple independent datasets we have shown that consensomes recapitulate pathway node-genomic target regulatory relationships to a high confidence level ochsner et al 2019placing the transcriptional events associated with human cov infection in context with those associated with other signaling paradigms has the potential to catalyze the development of novel therapeutic approaches the cov research community has been active in generating and archiving transcriptomic datasets documenting the transcriptional response of human cells to infection by the three major cov species namely middle east respiratory syndrome coronavirus mers and severe acute respiratory syndrome coronaviruses 1 sars1 and 2 sars2 dediego et al 2011 josset et al 2013 sims et al 2013 yoshikawa et al 2010 to date however the field has lacked a resource that fully capitalizes on these datasets by firstly using them to rank human genes according to their transcriptional response to cov infection and secondly contextualizing these transcriptional responses by integrating them with omics data points relevant to host cellular signaling pathways here as a service to the research community to catalyze the development of novel cov therapeutics we generated consensomes for infection of human cells by mers sars1 and sars2 covs we then analyzed the extent to which high confidence transcriptional targets for these viruses intersected with genes with elevated rankings in transcriptomic and chip-seq consensomes for cellular signaling pathway nodes integration of the cov consensomes with the existing universes of spp transcriptomic and chip-seq data points in a series of use cases illuminates previously uncharacterized intersections between cov infection and human cellular signaling pathways the cov infection consensome and its underlying datasets provide researchers with a unique and freely accessible framework within which to generate and pressure test hypotheses around human cellular signaling pathways impacted by cov infectionreflecting their well-documented roles in the response to viral infection we observed appreciable significant overlap between all tc95s and those for the toll-like tlr totura et al 2015 interferon ifnr hensley et al 2004 and tumor necrosis factor tnfr w wang et al 2007 receptor families fig 2 interestingly these signatures were particularly highly enriched in the sars2 tc95  potentially reflecting a particularly strong antiviral response to infection by sars2 tc95 overlaps for receptor systems with previously uncharacterized connections to cov infection including epidermal growth factor receptors glucocorticoid receptor and notch receptor signaling are consistent with the known roles of these receptor systems in the context of other viral infections hayward 2004 ito et al 2011 ng et al 2013 ostler et al 2019 zheng et al 2014 the relatively strong enrichment for xenobiotic receptors reflects work describing a role for pregnane x receptor in innate immunity s wang et al 2014 and points to a potential role for members of this family in the response to cov infectionin general chip-seq enrichments for transcription factors and other nodes were more specific for individual cov infection tc95s compare fig 2 with figs 3 4 and 5 this is likely due to the fact that chip-seq consensomes are based on direct promoter binding by a specific node antigen whereas transcriptomic consensomes encompass both direct and indirect targets of specific receptor and enzyme node families not unexpectedly  and speaking again to validation of the consensomes - the strongest and most significant cov tc95 overlaps were observed for cc95s for known transcription factor mediators of the transcriptional response to cov infection including members of the nfb ludwig  planz 2008 poppe et al 2017 ruckle et al 2012 irf chiang  liu 2018 and stat blaszczyk et al 2016 frieman et al 2007 garcia-sastre et al 1998 transcription factor families consistent with its known role in the regulation of interferon-stimulated genes hasan et al 2013 we also observed appreciable overlap between the cc95 for tfeb and the all cov tc95 moreover the strong overlap between the gtf2btfiib cc95 and all viral tc95s reflects previous evidence identifying gtf2b as a target for orthomyxovirus haas et al 2018 herpes simplex virus gelev et al 2014 and hepatitis b virus haviv et al 1998compared to the roles of receptors and transcription factors in the response to viral infection the roles of signaling enzymes are less well illuminated  indeed in the context of cov infection they are entirely unstudied through their regulation of cell cycle transitions cyclin-dependent kinases play important roles in the orchestration of dna replication and cell division processes that are critical in the viral life cycle cdk6 which has been suggested to be a critical g1 phase kinase bellail et al 2014 grossel  hinds 2006 has been shown to be targeted by a number of viral infections including kaposis sarcoma-associated herpesvirus kaldis et al 2001 and hiv-1 pauls et al 2014 consistent with this common role across distinct viral infections we observed robust overlap between the cdk95 tc95 fig 2 and the cdk6 cc95 fig 4 and those of all viral tc95s as with the tlrs ifnrs and tnfrs which are known to signal through cdk6 cingoz  goff 2018 handschick et al 2014 hennessy et al 2011 overlap with the cdk6 cc95 was particularly strong in the case of the sars2 tc95 fig 4 ccnt2 is a member of the highly conserved family cyclin family and along with cdk9 is a member of the viral-targeted p-tefb complex zaborowska et al 2016 reflecting a potential general role in viral infection appreciable overlap was observed between the ccnt2 cc95 and all viral tc95s fig 4 finally in the context of enzymes dna topoisomerase top1 has been shown to be required for efficient replication of simian virus 40 wobbe et al 1987 and ebola takahashi et al 2013 viruses the prominent overlap between its cc95 and those of sars2 and iav fig 4 suggest that it may play a similar role in facilitating the replication of these viruseswe have coined the term co-nodes as a convenient catch-all for cellular factors that are not members of the three principal signaling pathway node categories receptors enzymes and transcription factors ochsner et al 2019 the breadth of functions encompassed by members of this category reflects the diverse mechanisms employed both by viruses to infect and propagate in cells as well as by hosts to mount an efficient immune response consistent with its characterized role in the recruitment of p-tefb by iv-1 tat protein schulze-gahmen et al 2013 we observed consistently strong enrichment of the aff4 cc95 in all viral tc95s fig 5 the targeting of cnot3 for degradation in response to adenoviral infection chalabi hagkarim et al 2018 is reflected in the significant overlap between its cc95 and the viral tc95s particularly in the case of the sars2 fig 5by way of additional independent validation of the cov and iav consensomes gene set enrichment analysis subramanian et al 2005 reflected significant overlap between the cov and iav tc95s and a variety of viral infection and inflammatory transcription factor target gene sets supplementary information section 8we previously showed figs 2 and 3 that the overlap of the cov tc95 genes was most robust among consensomes for members of the ifnr tlr and tnf receptor families fig 2 and the nfkb rela irf and stat transcription factor families fig 5 to investigate this further we ranked genes in the all cov consensome by their aggregate 80th percentile rankings across these consensomes supplementary information section 2 column v transcriptomic consensomes for ifnrs section 9 tlrs section 10 and tnfrs section 11 are provided in supplementary information as are links to the chip-atlas lists used to generate the chip-seq consensomes section 12this redundancy ranking elevates genes with known critical roles in the response to viral infection that are acutely responsive to a spectrum of inflammatory signaling nodes such as ncoa7 doyle et al 2018 stat chapgier et al 2009 and tap1 gruter et al 1998 interestingly genes such as psmb9 csrnp1 and mrpl24 have all cov discovery rates that are comparable to or exceed those of many of the classic viral response isgs fig 1 but are either largely or completely uncharacterized in the context of viral infection this use case the reflects the potential of consensome-driven data mining to illuminate novel and potentially therapeutically relevant transcription pathway effectors in the response to cov infectionalthough a lack of clinical data has so far prevented a definitive evaluation of the connection between pregnancy and susceptibility to sars2 infection in covid-19 pregnancy has been previously associated with the incidence of viral infectious diseases particularly respiratory infections sappenfield et al 2013 siston et al 2010 we were interested therefore to see consistent overlap between the progesterone receptor pgr tc95 and all the viral tc95s with the enrichment being particularly evident in the case of the sars2 tc95 fig 2 to investigate the specific nature of the crosstalk implied by this overlap in the context of the airway epithelium we first identified a set of 16 genes that were in both the all cov and pgr tc95s we then retrieved two spp experiments involving treatment of a549 airway epithelial cells with the pgr full antagonist ru486 ru alone or in combination with the gr agonist dexamethasone dex as shown in figure 6 there was nearly unanimous correlation in the direction of regulation of all 16 genes in response to cov infection and pgr loss of function these data indicate that antagonism between pgr and ifnr signaling in the airway epithelium may predispose pregnant women to infection by sars2although telomerase activation has been well characterized in the context of cell immortalization by human tumor virus infection gewin et al 2004 klingelhutz et al 1996 yang et al 2004 no connection has previously been made between cov or iav infection and telomerase we were therefore intrigued to observe robust overlap between all viral tc95s and that of the telomerase catalytic subunit tert in support of this finding nfkb signaling has been shown to induce expression yin et al 2000 and nuclear translocation akiyama et al 2003 of tert and direct co-regulation by telomerase of nfkb-dependent transcription has been linked to chronic inflammation ghosh et al 2012 inspecting the all cov consensome underlying data points data not shown we found that the tert gene was not transcriptionally induced in response to infection by any of the covs indicating that the overlap between its tc95 and those of the covs might occur in response to an upstream regulatory signal if functional interactions between tert and inflammatory nodes did indeed take place in response to cov infection we anticipated that this would be reflected in close agreement regarding the direction of differential expression of cov infection-regulated genes in response to perturbation of tert on the one hand and on the other to stimulation of the classic viral response ifnrs to test this hypothesis we took the same set of 20 isgs referred to previously fig 1 and compared their direction of regulation across all experiments underlying the all cov tert and ifnr consensomes for reference the tert consensome section 13 and its underlying data points section 14 are provided in the supplementary information with respect to the ifnr and tert data points we observed a nearly universal alignment in the direction of regulation of all genes tested with those in the cov infection experiments fig 6 with agreement in the direction of regulation across 99 of the underlying probesets we should note that of the 1859 p  005 cov infection isg data points we observed repression rather than induction in response to cov infection in 303 15 which may be attributable to the impact of differences in cell type cell cycle stage or virus incubation time across the independent experiments our results are consistent with a model in which activation of telomerase is a component of the human innate immune response to viral infectionepithelial to mesenchymal transition emt is the process by which epithelial cells lose their polarity and adhesive properties and acquire the migratory and invasive characteristics of mesenchymal stem cells lamouille et al 2014 emt is known to contribute to pulmonary fibrosis hill et al 2019 and acute interstitial pneumonia h li et al 2014 both of which have been reported in connection with sars2 infection in covid-19 adair  ledermann 2020 p zhou et al 2020 moreover emt is widely accepted as a core component of the process by which renal tubular cells transform into mesenchymal cells during the development of fibrosis in kidney disease y liu 2006 a signature comorbidity of sars2 infection durvasula et al 2020 of the 834 cc95s analyzed overlap p  005 was specific to the sars2 cc95 for only five snai2slug sox2 gata6 ctbp1 and prmt1 strikingly a literature search indicated that these five nodes were connected by documented roles in in the promotion of emt avasarala et al 2015 herreros-villanueva et al 2013 martinelli et al 2017 nieto 2002 sahu et al 2017 in addition to these nodes whose c95 genes were exclusively enriched p  005 in the sars2 c95 genes we identified several other emt-linked nodes whose cc95 genes were preferentially enriched p  005 in the sars2 tc95 genes figs 35 including the homeodomain transcription factor six2 c-a wang et al 2014 smad4 siraj et al 2019 and the co-nodes pygo2 chi et al 2019 ski tecalco-cruz et al 2018 brd7 t liu et al 2017 and stag2 nie et al 2019to investigate this further we computed overlap between the individual viral tc99s and a list of 335 genes manually curated from the research literature as signature emt markers supplementary information section 15 zhao et al 2015 consistent with the node consensome enrichment analysis we observed significant enrichment of members of this gene set within the sars2 cc99 but not those of the all cov sars1 mers or iav consensomes supplementary information section 16 one possible explanation for this was the fact that the sars2 consensome was comprised of airway epithelial cell lines whereas the sars1 and mers consensomes included non-epithelial cell biosamples supplementary information section 1 to exclude this possibility therefore we next calculated airway epithelial cell-specific consensomes for sars1 and mers and computed overlap of their tc95s against the 864 pathway nodenode family cc95s  tc95s we found that significant overlap with the cov tc95s remained specific to sars2 data not shown confirming that significant overlap with the emt node signature was specific to the sars2 tc99we next applied consensome redundancy analysis see use case 1 to isolate a set of sars2 regulated genes cpv p  005 that were high confidence targets ie in the cc80 for at least two of the emt nodes snai2 sox2 gata6 ctbp1 and prmt1 supplementary information section 4 column m a literature survey showed that 13 of these 21 genes had a documented connection to emt supplementary information section 5 column n figure 9 compares the percentile rankings for these genes across the three cov infection consensomes and the iav consensome although some emt genes such as cxcl2 and irf9 had elevated rankings across all four consensomes the collective emt gene signature had a significantly higher mean percentile value in the sars2 consensome than in each of the three others fig 9although emt has been associated with infection by transmissible gastroenteritis virus xia et al 2017 this is to our knowledge the first evidence connecting cov infection and specifically sars2 infection to emt interestingly several members of the group of sars2-induced emt genes have been associated with signature pulmonary comorbidities of cov infection including adar diaz-pina et al 2018 cldn1 vukmirovic et al 2017 and sod2 gao et al 2008 of note in the context of these data is the fact that signaling through two sars2 cellular receptors ace2at2 and cd147basigin has been linked to emt in the context of organ fibrosis kato et al 2011 ruster  wolf 2011 c wang et al 2018 moreover overlap between of the cov tc95s and the tert cc95 was particularly robust in the case of sars2 a finding of potential relevance to the fact that telomerase has been implicated in emt z liu et al 2013 collectively our data indicate that emt warrants further investigation as a sars2-specific pathological mechanismhaving validated the all cov consensome we next wished to make it freely available to the research community for re-use in the characterization of signaling events associated with cov infection firstly the viral infection datasets were curated accordingly to our previously described protocol ochsner et al 2019 made available for browsing in the spp dataset listing httpswwwsignalingpathwaysorgdatasetsindexjsf as with other spp datasets and per fair data best practice cov infection datasets were associated with detailed descriptions assigned a digital object identifier and linked to the associated article to place the dataset in its original experimental context loading the cov datasets into the spp also automatically made the underlying data points discoverable by the spp query tool ominer ochsner et al 2019 these reports represent a summary of the current state of transcriptomic and chip-seq knowledge on the regulatory relationship of a given gene with upstream regulatory pathway nodes or in clinical and model experiments the full value of the integration of the cov consensome with the existing spp framework can perhaps be best appreciated in the context of the one click links to ominer regulation reports from the individual cov datasets these reports provide researchers with a wealth of contextual data on signaling pathways impacted by cov infection in the context of a specific gene table 2 shows links to regulation reports for the top twenty ranked genes in the all cov consensome the order of sections in the reports is receptors enzymes transcription factors co-nodes clinical and models the last section including data points from the cov infection model experiments that form the basis of this studyan effective research community response to the impact of covs on human health demands systematic exploration of the transcriptional interface between viral infection and human cell signaling systems it also demands routine access to existing datasets that is unhindered either by paywalls or by lack of the informatics training required to manipulate archived datasets in their unprocessed state moreover the substantial logistical obstacles to bsl3 certification only emphasizes the need for fullest possible access to and re-usability of existing cov infection datasets to focus and refine hypotheses prior to carrying out in vivo cov infection experiments to this end we generated a set of cov infection consensomes that rank human genes by the reproducibility of their significant differential expression in response to infection of human cells by covs we then computed the cov consensomes against high confidence transcriptional signatures for a broad range of cellular signaling pathway nodes affording investigators with a broad range of signaling interests an entrez into the study of cov infection of human cells the five use cases described here represent illustrative examples of the types of analyses that users are empowered to carry out in the cov infection knowledgebaseto democratize access to the cov consensome and its 3000000 underlying data points by the broadest possible audience we have integrated them into the spp database to create a cell signaling knowledgebase for cov infection incorporation of the cov data points into spp in this manner places them in the context of millions more existing spp data points documenting transcriptional regulatory relationships between pathway nodes and their genomic targets in doing so we afford users a unique appreciation of the cellular signaling pathway nodes whose gain or loss of function in response to cov infection gives rise to these transcriptional patternsthe human cov and iav consensomes and their underlying datasets are living resources on spp that will be updated and versioned with appropriate datasets this will be particularly important in the case of sars2 as datasets involving infection of human cells with this virus are necessarily currently limited in number this will allow for hardening of observations that are intriguing but whose significance is currently unclear such as the overlap of the cov tc95s with the tert tc95 as well as the enrichment of emt genes among those with elevated rankings in the sars2 consensome we welcome feedback and suggestions from the research community for the future development of the spp cov infection consensomesdifferential expression values were calculated for each gene in each experiment using the limma analysis package from bioconductor then committed to the consensome analysis pipeline as previously described ochsner et al 2019 briefly the consensome algorithm surveys each experiment across all datasets and ranks genes according to the frequency with which they are significantly differentially expressed for each transcript we counted the number of experiments where the significance for differential expression was 005 and then generated the binomial probability referred to as the consensome p-value cpv of observing that many or more nominally significant experiments out of the number of experiments in which the transcript was assayed given a true probability of 005 a more detailed description of the transcriptomic consensome algorithm is available ochsner et al 2019 the consensomes and underlying datasets were loaded into an oracle 13c database and made available on the spp user interface as previously described ochsner et al 2019gene overlap analysis was performed using the bioconductor geneoverlap analysis package httpswwwrdocumentationorgpackagesgeneoverlapversions180topicsgeneoverlap  implemented in r briefly given a whole set i of ids and two sets a  i and b  i and s  a  b geneoverlap calculates the significance of obtaining s the problem is formulated as a hypergeometric distribution or a contingency table which is solved by fishers exact test the universe for the overlap was set at a recent estimate of the total number of coding genes in the human genome 21500 pertea et al 2018 paired two sample t-test for comparing the mean percentile ranking of emt genes in the mers sars1 sars2 and iav consensomes was performed in prism at 12 degrees of freedomthe procedure for generating transcriptomic consensomes has been previously described ochsner et al 2019 to generate the chip-seq consensomes we first retrieved processed gene lists from chip-atlas which rank human genes based upon their average macs2 occupancy across all publically archived datasets in which a given transcription factor enzyme or co-node is the ip antigen of the three stringency levels available 10 5 and 1 kb from the transcription start site we selected the most stringent 1 kb according to spp convention ochsner et al 2019 we then mapped the ip antigen to its pathway node category and class and the experimental cell line to its appropriate biosample physiological system and organ we then organized the ranked lists into percentiles to generate the node chip-seq consensomethe spp knowledgebase is a gene-centric java enterprise edition 6 web-based application around which other gene mrna protein and bsm data from external databases such as ncbi are collected after undergoing semiautomated processing and biocuration as described above the data and annotations are stored in spps oracle 13c database restful web services exposing spp data which are served to responsively designed views in the user interface were created using a flat ui toolkit with a combination of javascript d3js ajax html5 and css3 javaserver faces and primefaces are the primary technologies behind the user interface spp has been optimized for firefox 24 chrome 30 safari 519 and internet explorer 9 with validations performed in browserstack and load testing in loaduiweb xml describing each dataset and experiment is generated and submitted to crossref to mint dois ochsner et al 2019the entire set of data points used to generate the cov consensome has been uploaded in an r file to figshare and a link included for reviewer access the entire set of metadata for these data points is available in supplementary information section 1 consensome data points are in supplementary information sections 26spp is freely accessible at httpswwwsignalingpathwaysorg programmatic access to all underlying data points and their associated metadata are supported by a restful api at httpswwwsignalingpathwaysorgdocs all spp datasets are biocurated versions of publically archived datasets are formatted according to the recommendations of the force11 joint declaration on data citation principles 74 and are made available under a creative commons cc 30 by license the original datasets are available are linked to from the corresponding spp datasets using the original repository accession identifiers these identifiers are for transcriptomic datasets the gene expression omnibus geo series gse and for cistromicchip-seq datasets the ncbi sequence read archive sra study identifier srp dois for the consensomes and datasets are pendingthe full spp source code is available in the spp github account under a creative commons cc 30 by license at httpsgithubcomsignaling-pathways-projectominerthroughout history several infectious diseases have alleged the lives of many people and induced critical situations that have taken a long time to overcome the situation the terms epidemic and pandemic have been used to describe the disease that emerges over a definite period of time 1 during a particular course of time the existence of more cases of illness or other health situations than normal in a given area is defined as epidemics 2 on the other hand pandemics are outbreaks of the infectious disease that can enormously increase the morbidity and mortality over a vast geographical area due to the factors such as raise of worldwide travel urbanization changes in usage of land and misusing of the natural environment the occurrence of the pandemics has increased from the past century 3 in the past the outbreak of smallpox has killed of nearly 500 million world population in the last 100 years of its survival 4 due to the outbreak of spanish influenza in 1918 an estimate of 17 to 100 million deaths occurred 5 from the last 20 years several pandemics have been reported such as acute respiratory syndrome coronavirus sars-cov in 2002 to 2003 h1n1 influenza in 2009 and the middle east respiratory syndrome coronavirus mers-cov in 2012 since december 2019 the novel outbreak of coronavirus has infected more than thousand and killed above hundreds of individuals within the first few days in wuhan city of hubei province in south china in the 21st century the pandemics such as sars-cov has infected 8096 individuals causing 774 deaths and mers-cov has infected 2494 individuals causing 858 deaths while the sars-cov-2 has infected more than 348 million individuals causing 248144 deaths across 213 countries as on may 3 2020 these evidential facts state that the transmission ratio of sars-cov-2 is greater than other pandemics a list of some dangerous pandemics happened over time is listed in table 1
due to the rapid increase of patients at the time of outbreak it becomes extremely hard for the radiologist to complete the diagnostic process within constrained accessible time 6 the analysis of medical images such as x-rays computer tomography and scanners plays a crucial role to overcome the limitations of diagnostic process within constrained accessible time now-a-days machine learning and deep learning techniques helps the physicians in the accurate prediction of imaging modalities in pneumonia ml is a wing of artificial intelligence that has the ability to acquire relationships from the data without defining them a priori 7 due to the availability of large number of intelligent tools for the analysis collection and storage of large volume of data machine learning techniques have been extensively utilized in the clinical diagnosis machine learning approaches can be efficiently used in applications of healthcare such as disease identification diagnosis of disease discovery and manufacturing of drug analysis of medical images collection of crowd sourced data research and clinical trials management of smart health records prediction of outbreak etc some recent studies show the usage of machine learning techniques in the time series forecasting of ebola outbreak 8 in order to select the better performing classifier for forecasting ebola casualties experiments were conducted on ten different classifiers further results demonstrate that the proposed model achieves 9095  accuracy 539  mae and 4241  rmse value even though machine learning approaches have rapidly used in the diagnosis of outbreaks these approaches still have some limitations such as complete utilization of biomedical data temporal dependency owing to high-dimensionality sparsity heterogeneity and irregularity 9 10 11 on the other hand due to the deep architectural design the deep learning models are the best accurate models for handling medical datasets such as classification of brain abnormalities classification of different types of cancer classification of pathogenic bacteria and segmentation of biomedical images 12 13 14 15 16 several studies show that dl models are adopted in the diagnosis and classification of pneumonia and other diseases on radiography a deep learning model build on mask-rcnn has been utilized for the detection and localization of pneumonia in chest x-ray images 17 in order to perform pixel-wise segmentation the model makes use of global and local features the robustness of the system is achieved through the modification of training process and post processing step further results show that the model outperforms in the identification of pneumonia in chest x-ray images to improve the performance of prediction a bioinspired meta-heuristic optimization algorithm has been presented by martinez-alvarez et al 18 in this approach to prevent the researches from initializing with arbitrary values the input parameters are initialized with the disease statistics also this approach has the ability to stop after certain number of iterations without setting this value further to explore wider search space in less number of iterations a parallel multi-virus approach has been proposed finally it has been integrated with dl models for finding the optimal parameters in the training phase deep learning prototypes have been widely used in the prediction and forecasting of outbreak over machine learning models because of its features such as greater performance feature extraction without human intervention and identification and not making the use of engineering advantage in training phasethe major objective of this paper is to provide a review of different machine learning approaches used in the prediction classification and forecasting of covid-19 first we describe the origin of sars-cov-2 virus its transmission rate comparison of sars-cov-2 with other pandemics in the history and its impact on the global health then the analysis is broaden by describing the advantages of computing approaches such as statistical and mathematical models ml and dl approaches in the prediction of covid-19 along with its applications further an analysis number of articles published in different computing approaches by different countries till date impact of the nature of data in the prediction of covid-19 have been presented as the researchers and technocrats are the main targets of this review we highlighted some of the challenges in the ongoing research of different computing approaches at the end of the paper the remaining section of the paper is systematized as follows section 2 describes the origin of covid-19 and its impact the application of statistical ml and dl models in the diagnosis and prognosis of covid-19 has been portrayed in section 3 section 4 illustrates the critical investigation on the analysed data types of covid research growth in publication of ml approaches for covid comparative analysis on the type of methods etc few challenges in ml related to covid-19 have been focused in section 5 section 6 outlines the conclusion with a brief discussion on covid-19 impact in real life and novel research directionsin the 21st century human corona viruses such as sars-coronavirus sars-cov and mers-coronavirus mers-cov that have emerged from the animal reservoirs caused global epidemic with distressing morbidity and mortality these human corona viruses belong to the subfamily of coronavirinae that is a part of coronaviridae family it was named as corona because of the presence of spike like structure on the outer surface of the virus under electron microscope its rna is a single stranded with a diameter of 80-120 nm and nucleic material range varying from 26 to 32 kbs in length 19 these are basically divided into four types of genera named as alpha  beta  gamma  and delta  - and -cov usually infects mammals while - and -cov tends to affect birds among the six susceptible human viruses hcov-229e and hcov-nl63 of -covs and hcov-hku1 and hcov-oc43 of -covs shows low pathogenicity and moderate respiratory symptoms as common cold the other two familiar -covs such as sars-cov and mers-cov exhibit acute and malignant respiratory diseases 20 the figure 1
shows the transmission process of corona viruses from animal sources to humanthe people in wuhan city of hubei province in south china were reported in local hospitals with an unidentified pneumonia on december 2019 21 initially these cases were related to huanan seafood wholesale market which is famous for variety of live species all these cases have clinical characteristics similar to those of viral pneumonia such as dry cough fever dyspnea and lung infiltrates on imaging after the analysis of samples collected from the throat swab the authorities from centers for disease control cdc announced the unidentified pneumonia as novel coronavirus pneumonia ncp on 7th january 2020 22 later it was named as severe acute respiratory syndrome coronavirus 2 sars-cov-2 by the international committee on taxonomy of viruses 23 24 and the disease was renamed as covid-19 by the who on 11th february 2020 25 the covid-19 generated by sars-cov-2 is a -coronavirus the sequence analysis of sars-cov-2 matches with the typical structure of coronaviruses as depicted in figure 2
the structure of sar-cov consists of 14 binding remnants that collaborate precisely with human angiotensin-converting enzyme 2 as eight binding residues of the sars-cov has sustained in the sars-cov-2 the structure of sars-cov-2 genome contributes 795 similarity to sars-cov 27 in addition both bat cov and human sars-cov-2 share the identical ancestor as the genome sequencing of covid-19 shows 962  identity to bat cov ratg13 28 due to the genetic recombination occurrence at s protein in the rbd area of sars-cov-2 the sars-cov-2 has greater transmission ability than sars-cov 29 after the spread of covid-19 to 18 countries through human-to human transmission the who announced the epidemic as public health emergency of international concern pheic on 30th january 2020 in addition critical situation was created when the first case not imported from china was registered in the united states on 26th february 2020 the who declared the covid-19 as pandemic on 11th march 2020 when it imposes serious hazard to public health as the number of cases outside the china has raised 13 times and the number of countries distressed by covid-19 has increased by three times since the last two months the number of covid-19 cases registered has crossed all the previous records of the viral disease due to its rapid spread it is considered to be the most dangerous disease till date according to the who the sars-cov-2 has infected about 348 million people and caused 248144 deaths across 213 countries of the world as on may 3 2020 among the countries the usa has reported about 1188122 positive cases and 68595 deaths as on may 3 2020 and stood in first place in both positive cases as well as in death rate similarly other countries like spain italy uk france germany russia turkey iran brazil canada belgium peru and netherland are placed as top countries with more than 50000 cases after the pandemic of covid-19 outside the mainland of china the number of deaths per day due to covid1-9 pandemic is also gradually increasing from the starting day of transmission to till date fig 3 fig 4
 predicts the top countries in the world having more than 50000 and number of deaths per day as on may 3 2020random forest algorithm rf is one of the most promising and recognized classifier that uses multiple trees to train and predict data samples this approach has been extensively used in the fields of chemometrics and bioinformatics 32 33 because of its praiseworthy characteristics random forest has been used in resolving issues of the ncovid-19 infection for precise and rapid recognition of covid-19 a tool based on random forest algorithm to extract 11 key blood indices from clinical available blood samples was suggested by wu et al 34 in this study random forest algorithm is used as a discrimination tool to explore patients with covid-19 symptoms the proposed method achieved better outcome in the prediction of covid-19 with accuracy of 09795 for the cross-validation set and 09697 for the test set further the tools also achieved better performance in terms of sensitivity specificity and overall accuracy of 09512 09697 and 09595 respectively on an external validation set moreover it achieved an accuracy of 09167 in a detailed clinical estimate of 24 samples collected from infected covid-19 patients after multiple verifications the proposed approach has been emerged as a precise tool for the recognition of covid-19 infection to predict the hospital stay of patients infected with novel coronavirus a model based on linear regression and random forest has been suggested by qi et al 35 the proposed model based on 6 second-order characteristics was refined on features obtained from pneumonia lesions in training and inter-validation datasets further the predictive efficiency has been evaluated using lung-lobe and patients-level test dataset from the conclusions it is observed that model was efficient in segregating short and long-term stay of patients in hospital infected with coronavirus infection moreover linear regression model exhibited a sensitivity and specificity of 10 and 089 while a sensitivity and specificity of 075 and 10 has been exhibited by the random forest model the following table 2
depicts the usage of random forest approach in the prognosis of sars-cov-2 infectionas svm is used as a powerful tool for data regression and classification it has superior performance in many real world applications such as medical image analysis over other machine learning approaches because of its better performance it has been used in the classification and analysis of covid-19 to predict the threat of positive covid-19 diagnosis different machine learning approaches such as neural networks random forests gradient boosting trees logistic regression and support vector machines for training the sample data was suggested by batista et al 41 the performance of the different machine learning approaches was trained on arbitrary sample data of 70 of patients and was tested on 30 of new not seen data form the results it concludes that the support vector machine algorithm outperforms with auc sensitivity specificity and brier score of 085 068 085 and 016 respectively when compared with other machine learning algorithms for the diagnosis of covid-19 infected patients form the chest x-ray images a machine learning model developed on multi-level thresholding and svm has been suggested by hassanien et al 42 furthermore the results depict that the proposed model achieves better performance with an average sensitivity of 9576 specificity of 997 and accuracy of 9748 respectively table 3
represents the usage of machine learning approaches in the recognition and diagnosis of covid-19besides random forest and support vector machine other approaches of machine learning approaches such as linear and logistic regression xgboost k-means neural network have also been used in the clinical and public health approach many research works are being performed and table 4
represents the usage levels of these approaches in solving some of the conflicts of covid-19convolutional neural network has proven to be one of the most successful algorithms in the analysis of medical image with high accuracy previously the identification of the nature of pulmonary nodules in ct images prediction of pneumonia in x-ray images labeling of polyps automatically at the time of colonoscopic videos have been done using convolutional neural networks 58 59 60 the authentication features for identifying covid-19 in medical images are bilateral distribution of patchy shadows and ground glass opacity 61 abbas et al 62 have developed a decompose transfer and compose detrac model based on convolutional neural network to categorize the covid-19 chest x-ray images using the class decomposition mechanism the class boundaries are investigated that helps the model to accord with any anomalies in the image dataset further the results show that an accuracy of 9512 was attained by detrac in the recognition of covid-19 x-ray images from other normal and pneumonia cases to recognize covid-19 patient from chest x-ray images distinct convolutional neural network frameworks namely resnet50 inceptionv3 and inception-resnetv2 have been proposed by narin et al 63 further insufficient data and training problem can be overwhelmed by applying deep transfer learning technique using imagenet from the results it can be observed that highest classification performance with 98 accuracy can be attained by the resnet50 model over the other two models to interpret and predict the number of positive cases a covid-19 forecasting model build on convolutional neural network cnn was suggested by the huang et al 64 the main focus of the study was to consider the cities with large number of positive cases in china the overall competence of different algorithms was compared using mean absolute error mae and root mean square error rmse the outcomes indicate that cnn achieves greatest prediction efficacy when collated with other approaches of deep learning such as lstm gru and mlp furthermore the actual usage and feasibility of the proposed model in forecasting the total registered cases were also documented in their study to automatically recognize the ncov-2019 positive cases from chest x-ray images mukherjee et al 65 have proposed tailored shallow convolutional neural network architecture the architecture was designed with few parameters for validating 130 covid-19 positive x-ray images and 5-fold cross validation was used to avoid possible bias in the experimental tests moreover the proposed method achieved an accuracy sensitivity and auc of 9692 0942 and 09869 respectively which is dominative over other compared methods a multitask deep learning model has been proposed by amyar et al 66 to perform the automatic screening and segmentation covid-19 chest ct images for reconstruction and segmentation one encoder and two decoders along with multi-layer perceptron has been used in the architecture for the classification purpose then the model has been evaluated with a dataset of 1044 patients which includes 449 patients suffering with covid-19 100 normal cases 98 patients with lung cancer and 397 cases of different types of pathology moreover results indicate that the model obtains better performance over the other image segmentation and classification techniques the application of cnn in the classification and diagnosis of covid-19 has been depicted in table 5
long short-term memory is a type of the recurrent neural network that can store knowledge of previous states and can be trained for work that needs memory lstm is one of the efficient models for the prediction of time series sequential data 81 as past data is retained in the hidden states lstm approach can perform more accurate predictions of the output a novel multivariate spatiotemporal model has been proposed by jana et al 82 this model uses ensemble of convolutional lstm to make accurate forecast of the dynamics of covid-19 transmission in large geographic region for converting the available spatial features into set of 2d images a data preparation method is used further the proposed model is trained using usa and italy data from the findings it can be observed that the model achieves 557 and 03 mape for usa and italy respectively to predict the number of covid-19 cases in india a data-driven estimation approach based on lstm and curve fitting has been suggested by et al 83 this approach was also used to estimate the effective of social distancing measures on the spread of the pandemic further the findings show the accuracy of proposed approach in predicting the number of positive and recovered cases in india table 6
shows the applicability of lstm in resolving the issues of covid-19 pandemicin addition to cnn and lstm approaches several other deep learning approaches such as generative adversarial networks and autoencoder have also been used in the analysis and prediction of covid-19 pandemic generative adversarial networks gans are algorithmic architectures that consist of two neural networks called generator and discriminator to generate new synthetic instances of data from real ones that have been never observed before gans have been widely used in image generation video generation and voice generation an autoencoder is a sort of artificial neural network used to grasp efficient data coding in an unsupervised way the following table 7
represents the usage of other deep learning approaches in the prediction and diagnosis of novel coronavirus diseasefrom the past few pandemics mathematical and statistical models have been successfully used in the estimation of human loss and also in the prediction of total number of deaths until a specific period or end of the pandemic as the mathematical and statistical approaches shows better performance researchers have also used the same approaches in the estimation of spread rate and death count of the current pandemics to foresee the window period for testing positive negative results as well as false negative result a multivariate model has been developed by xu et al 99 the clinical characteristics that are responsible for false negative outcomes of sars-cov2 nucleic acid identification are determined using these models zhong et al 100 have used the simple mathematical models for the early prediction of novel coronavirus disease in china the prediction models estimated that the total number of positive cases may reach to 76000 to 230000 in late february to early march it is also estimated that from early may to late june the number of registered cases will rapidly decrease to predict the number of deaths in china boltzmanns function based analysis has been proposed by gao et al 101 the prediction model gives better prediction accuracy in the assessment of severity of situation the impact of primary health conditions such as cardiac disease diabetes and age of the patient in the prediction of death rate has been presented by banerjee et al 102 azad et al 103 have used holts and autoregressive integrated moving average arima model in the temporary forecasting of covid-19 infected patients in india from 30 january to 21 april 2020 the following table 8
shows some other analysis done in the prediction of covid-19 using mathematical and statistical approachesit has been evident from the system review that machine learning approaches also have been efficiently used in the prediction and diagnosis of covid-19 among the available machine learning approaches mostly support vector and random forest have been used in the recognition of novel covid-19 outbreak as support vector machine is one of the best classifier algorithms with minimum error rate and maximum accuracy it gives better prediction results a machine learning model suggested by barstugan et al 46 have been efficiently used in the classification of medical images using svm for classification and grey level co-occurrence matrix glcm for feature extraction the proposed model achieves 9968 classification accuracy as random forest uses multiple tress to identify the samples and robust to noise it has been extensively utilized in the classification of medical images moreover random forest approach is suitable for multiclass problem whereas svm is suitable for two-class problem a random forest model proposed by tang et al 38 have been successfully utilized in the severity assessment of coronavirus infected patients using 30 quantitative features the proposed model achieves 0933 true positive rate 074 true negative rate and 0875 accuracy table 9
represents the analysis of performance metrics of various machine learning algorithms in the diagnosis of covid-19 infection it has been evident from the systematic analysis that most of the machine learning approaches trained on small datasets moreover the limitations specified in the table provide scope for the researchers to develop more accurate prediction and forecasting models in the futuredue to the advantages of deep learning approaches over machine learning approaches such as excellent performance feature extraction without human intervention and handling complex and multimodal more number of researches has been carried in the diagnosis of covid-19 infection using deep learning approaches from the systematic review it is observed that cnn is one of the most commonly used deep learning approaches for the prediction of pandemic from the medical images over other approaches due to its ability to extract features automatically with a deep learning algorithm proposed by wang et al 113 have achieved an overall accuracy of 731 on external validation this is due to the limitations such as large number of variable objects and presence of only one radiologist in outlining the roi area it has been also observed that the implementation of exact architecture may not yield in better solutions a new modified cnn for categorizing x-ray images proposed by rahimzadeh et al 72 improves the overall performance by extracting multiple features using xception and resnet50v2 networks the model has been applied on 11302 images and conclusions show that the proposed method achieves an overall average accuracy of 9956 for covid-19 cases an iteratively pruned model proposed by rajaraman et al 68 improves the classification performance by combining distinct ensemble schemes the empirical results show that the proposed model outperforms by achieving 9901 accuracy and 09972 of area under curve value a resnet based framework proposed by farooq et al 114 have achieved an overall accuracy of 962 with augmentation hence the performance can be enhanced by considering some aspects such as presence of expert knowledge about the task to be solved additional augmentation and preprocessing steps optimization of hyperparameters and so on in the implementation the following table 10
depicts the performance analysis of some deep learning approaches that may enable the researchers to select an appropriate deep learning approach and architecture for resolving conflicts in covid-19 pandemic as well as further scope to improve the overall performance of different approachessince the start of outbreak of covid-19 in december 2019 several researchers and modeling groups around the world have developed abundant number of prediction models 125 126 127 128 using mathematical and intelligent computing approaches to predict the trends of covid-19 in different regions of the world the list of covid-19 forecasting attempts all over the world using various statistical models is publicly accessible1
 the modeling results have forecasted information about trends in covid-19 around the world such as infection cases future deaths recovered cases hospitality needs impact of social distancing travelling restrictions and so on these models have shown a vast range of variations in predictions due to uncertainty of data it has been found that the design issues have also been observed in the most cited forecasting technique from the imhe 129 130 though the issues are resolved in later revised model the prediction errors still persist high one of the reason for these variations is only small amount of information is available at the beginning of the outbreak and lack of reliable data due to frequent segregation of data over different geographical regions another reason is most of the prediction models have forecasted the future results by considering data of confirmed cases of those who got infected with symptoms and tested at the hospitals these predictions have not taken into consideration the data of asymptomatic patients furthermore the factors affecting the positive and death rate such as age gender hypertension chronic diseases etc have not considered in some prediction models the selection of suitable model for performing epidemic study also influences the predictions of the model a simple mode is not realistic as it does not include more epidemiological information while the complex model is biologically authentic though the complex model includes more biological information it requires more parameters when compared to simple model the complex model also leads to larger degree of uncertainty if the increased parameters are unknown therefore to make more accurate predictions in the future more research has to be carried on improving the tools and models of the prediction on large biological informationdespite having lower fatality rate sars-cov-2 caused thrice the total of deaths when compared to the combined statistics of deaths caused by both mers and sars-cov as the symptoms of covid-19 are similar to common influenza it becomes difficult to detect the infection in addition covid-19 is much more contagious than influenza due to asymptomatic condition further the shortage of medical supply rapid spread and the non-availability of a vaccine or drug for treating covid-19 are the major reasons that attracted most of the researchers to carry vast research on covid-19 when compared to other pandemics figure 5
represents the articles contributed for the analysis from jan 13 2020 to may 3 2020 in the initial stage of disease less than 1 of articles have been published in the month of january around 6 of articles issued in the month of february 16 of articles reported in the month of march and 77 of the articles are published in the month of april so it can be concluded that up to 3rd may 2020 majority of the articles have been published in the month of april as the number of infected covid-19 cases increased world wise it is worthy to note that with the increase of covid-19 cases throughout the world researchers have shown incredible interest to decipher the problem of various aspects on covid-19 through intelligent ml and other computing approachesit is evident from the figure 6
 that majority of work on covid-19 predictiondiagnosis has been conducted using deep learning approaches 39 next 37 of research has been experimented using the machine learning approaches only 24 of the work has been done using mathematical and statistical models in the prediction of covid-19 from the figure it can be concluded that more appropriate prediction and diagnosis of covid-19 diseases can be performed using deep learning approaches more work has been contributed on deep learning approaches when compared to other approaches because of the features such as excellent performance ability to handle complex and multi-modal data feature extraction without human intervention and absence of engineering advantage in training phasearticles from different sources such as lancet jama nejm elsevier oxford wiley nature bmj science and medrxiv have been considered for the systematic review it is evident from the figure 7
that majority of the articles have been published in bmj ie 176 next 171 articles have been published in lancet the articles from nature have contributed 153  the science has contributed 85 of the studies 76 of the studies have been contributed by journal of medical virology nejm jama clinical infectious diseases journal of infection travel medicine infectious diseases international journal of infectious diseases eurosurveillance emerging infectious diseases radiology viruses infection control hospital epidemiology emerging microbes infection journal of hospital infection have been contributed between 2 to 4 of the studies remaining journals like annals of internal medicine journal of the american academy of dermatology international journal of antimicrobial agents journal of clinical medicine journal of travel medicine journal of virology methods in molecular biology have contributed less than 1 of the studiesthe figure 8
displays the number of articles published country wise on the diagnosis and prognosis of covid-19 using statistical machine learning and deep learning approaches from the figure it can observed that majority of the articles ie 217 have been contributed by the researchers of china 181 articles have been contributed from the us researchers the researchers of uk have contributed 149 of the articles in the study 1316 of articles have been contributed by italy the countries india france republic of korea and japan have contributed 604 56 42 and 35 of the studies respectively 213 have been contributed by the researchers of the countries like egypt and australia the contributions from the researchers of turkey are 14 and nearly 106 of total research has been contributed by the researchers of canada germany and saudi arabia however the researchers of pakistan netherlands and brazil have contributed the 0711 of the studies next the researchers in the countries like iran spain iraq greece thailand and singapore have contributed 035 of the studiesthe forecasting of pandemics can be done with the information of registered number of covid-19 cases along with their geographical locations the most used dataset for the forecasting and prediction of covid-19 is collated by john hopkins university 131 this dataset contains information such as the daily positive cases total patients recovered per day and the death rates at a country as well as state level another data source kaggle also contains the daily number of covid-19 cases 132 this dataset is annotated with attributes such as patient demographics case reporting date and location when working with real datasets most of the researchers face class imbalance distribution issues another limitation is the variations in interventions population densities and demographics have a major impact on the prediction however many good researchers have suggested for the use of real clinical data under the supervision of doctors for further diagnosis of covid-19 other than online data the main problem with online data is the presence of large extent of missing values which may affect the proper analysis using any intelligent based methodsthe growth nature and spread of covid-19 can be predicted using the rich textual data available from various online sources the interpretation of the epidemic is quite complicated as most of the studies have taken into account only a few determinants assuming the affect of virus in terms of positive and death case everywhere in the globe could produce inaccurate predictions to make accurate predictions it is necessary for the researches to understand the spread at the local regional national as well as international levels to be accurate analysts would also need data from the medical authorities that distinguish between deaths caused by the coronavirus and deaths that would have happened due to anonymous disease in most of the studies this data is not known or not available the range to which people pursue the local governments quarantine policies or measures to prevent the spread of infection is also difficult to find these factors need to be considered to make accurate prediction of covid-19 using online data while experimenting with any ml based techniquesthe screening of medical images such as chest ct images or x-ray images is considered as an alternative solution to overcome the shortage of rt-pcr supply now-a-days most of the research for the classification and prediction of covid-19 has been carried on medical image data set as medical image analysis helps the physicians in the accurate prediction of imaging modalities in pneumonia from the literature review it has been observed there are still some limitations in the usage of medical image datasets the vast challenge in the medical diagnosis is the classification of medical images due to the limited accessibility of medical images the process of automated distinction is difficult in ct images as those share some common imagery characteristics among novel covid and other forms of pneumonia none of the studies reviewed by the authors accurately reported the high specificity of ct in distinguishing covid-19 from other pneumonia with identical ct findings thus restricting the usage of ct as a confirmatory diagnostic test the presence of mild or no ct findings in many early cases of infection highlights the difficulties of early detection moreover the ct scan tools are expensive and patients are exposed to more radiation even though chest x-ray images are cheaper and expose the patient to less radiation these images have higher false diagnosis ratefrom the figure 9
it has been observed that majority of work has been done on classification of covid-19 46 next 36 of work has been done on the prediction of covid-19 only 20 of the work has been done on the forecasting of covid-19from the figure it can be concluded that less work has been done on prediction and forecasting due to the lack of real world datasets and availability of less number of training medical imagesthe implementation of predictive tools using deep learning and machine learning requires huge volume of data even though few datasets for medical images and textual analysis are publicly available these datasets are small when compared to the needs of the deep learning approaches the main reason for the scarcity of measured data is the frequent segregation of data over different geographical regions therefore aligning of the data sources is one of the key issues that need to be solved another limitation arises in the development of quality datasets as real time datasets contain poorly quantified biases as results of this poor outcomes will be produced if models are trained on unrepresentative data although transfer learning allow models to be specific with regional characteristics it is difficult to perform model selection due to the fast moving nature of the data therefore designing an analytical approach to overcome these limitations is one of the key challenges that need to be addressed most of the researchers and technocrats are also facing the problem of lack of real data this issue can be accomplished by creating more real world datasets with updated covid-19 data another issue that needs to be observed is the less involvement of medical community in most of the studies either few or no physician has involved in the assessment of medical images such as x-rays and ct imagesthere exists a hidden risk in all scientific work as most of the methods in the study are based on statistical learning on quickly produced datasets the outcome of the research may have biases that may impact the policies taken by the government in controlling the spread of disease therefore the challenge is to find the uncertainty of conclusions produced in this research the correctness of the data can be ensured by providing reproducible conclusions this in turn creates the challenge of balancing the requirements against the urgencysome data science approaches such as ultrasound scans and magnetic resonance imaging mri have limited exposure in combating covid-19 even though ultrasound scans have shown good performance as that of chest ct scans no studies have explored the usage of ultrasound scans in the prediction of covid-19 though some studies 133 have shown the efficient usage of mri in predicting covid-19 infections still the approach remained unexplored due to the scarcity of adequate training data therefore the challenge is to develop well-annotated dataset to make potential usage of new approaches in the prediction of covid-19 infectionthe usage of predictive tools in diagnosis of covid-19 imposes a problem in developing countries that have limited access to healthcare facilities therefore a key challenge is the development of tools that should be capable of deployment in economically underprivileged regions for example the development of mobile app for contact tracing should consider factors such as low cost limited resources accessibility to illiterates or disability people and support of multiple languages so that it can be effectively deployed in economically deprived regionsmost of the studies have carried out only by considering the characteristics of covid-19 and other pneumonia the outcome of these studies may not produce accurate results as they not considered other the impact of other factors such as age gender diabetes hypertension chronic liver and kidney disease and so on therefore to perform accurate predictions more research has to be carried on symptom based identification of covid-19 moreover apart from prediction and forecasting based models future research requires more attention on the classification problems on covid-19 through various symptoms for easy and quick diagnosis also most of the research is dedicated to top affected countries with this pandemic disease and further research may be enhanced for remaining mostly affected countries around the globe further accurate prediction in the number of deaths and infections with advance machine learning approach is of utmost importance in the present scenario as most of the machine learning models are highly accurate with large amount of data so it may be worthy to note that with the increasing no of data and datasets of majorly covid affected countries many highly accurate models will be developed as a leading solution to this outbreakthe researchers are always active in addressing the emerging challenges that arises in different application domains in recent days covid-19 an infection caused by sars-cov2 is one of the most emerging research areas as it affected more than 3 million people in 213 countries within a short span of time therefore to empower the government and healthcare sector it is necessary to analyze various forecasting and prediction tools in this paper an overall comprehensive summary of ongoing work in the prediction of covid-19 infection using various intelligent approaches has been presented initially the origin dissemination and the affect of covid-19 on the public health has been discussed the major contribution of the study is the analysis of various prediction and forecasting models such as statistical machine learning and deep learning approaches and their applications in the control of the pandemic following this the analysis is broadened by making a critical investigation on the growth of studies carried on covid-19 in various journals by country and the performance analysis of the statistical machine learning and deep learning approaches finally at the end of the paper some of the challenges observed as a part of systematic review are highlighted that may further help the researchers and technocrats to develop more accurate prediction models in the prediction of covid-19the sars-cov-2 has infected about 348 million people and caused 248144 deaths across 213 countries of the world as on may 3 2020 according to the who as the total of covid-19 cases registered has crossed all the previous records of the viral disease since last moths it is considered to be the most dangerous disease till date the whole world political social economic and financial structures have been disturbed because of the outbreak of pandemic the economies of the worlds topmost countries such as the us china uk germany france italy japan and many others are at the edge of destruction as 162 countries have moved into the lockdown to prevent the transmission of pandemic the business across the world is operating in fear of an impending collapse of global financial markets the sectors such supply chains trade transport tourism and the hotel industry have been damaged extremely because of the pandemic other sectors like apparel  textile building and construction sectors have been affected adversely due to the lack of labour supply and availability of raw material the other sector that is badly affected is the aviation sector as both international and domestic flights cancelled due to the implementation of lockdown in many countries even though the effect of lock down is less on essential goods retailer other retailers such as shops and malls have been highly impacted by the pandemic due to the pandemic the educational institutions have also been seriously affected and led to the shutdown of institutions which caused an interruption in the students learning activity as well as in internal and external assessment necessary for the qualification of the student even though several sectors have been affected there are some sectors such as digital and internet economy food based retail chemicals and pharma sectors that have seen growth during the pandemic lockdown the deep learning and machine learning approaches are useful in forecasting the impact of covid-19 on different sectors which may help the government in implementing proper policies to overcome the economic crisis from the systematic analysis it is evident that computing intelligent approaches such as ml dl mathematical and statistical approaches have been profitably used in the prediction and screening of covid-19 pandemic it is observed that svm rfk-means and linear regression of ml approaches have been mostly used for solving issues of covid-19 while in case of dl cnn and its variants are mostly utilized for predicting the pandemic even though computing approaches have been successfully used in the prediction and forecasting of covid-19 pandemic still there exist certain limitations such as limited availability of annotated medical images not taking into account predictive end events such as mortality or admission into critical care unit while forecasting not considering some features of medical images such as ggo crazy-paving pattern and bilateral involvement which are prerequisite in the diagnosis covid-19 training on small datasets and not coping with data irregularities need urgent focus to develop more accurate models it is also observed that every researchers and modeling groups all over the world are presently facing the issue of scarcity of data therefore real-world datasets with more epidemiological data need to be created for the development of more accurate prediction models moreover the accuracy of prediction tools can be enhanced by the usage of advanced computing intelligent approaches such as ensemble method like bagging stacking etc application of optimization techniques usage of artificial neural networks and higher order neural networks in the screening and prediction of covid-19 which is considered as further scope of researchthe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paperthe authors declare that this manuscript has no conflict of interest with any other published source and has not been published previously partly or in full no data have been fabricated or manipulated to support our conclusionsmers-cov is the second coronavirus after severe acute respiratory syndrome sars-cov with the potential to cause a pandemic 3 characterized by its corona or crown shape it is a single-stranded rna virus with approximately 30000 nucleotides in its genomewhile current literature mostly concur that camels are important zoonotic reservoirs for mers-cov there has been some evidence that bats might be primary viral reservoirs and that mers-cov will jump to a different host such as dromedary camels and subsequently humans when opportunities arise similar transmission dynamic has been observed with sars-cov where palm civets acted as intermediary host between bats and humans 4 5 however coronaviruses isolated from bats are more genetically distant from human mers-cov than those isolated from camels which have shown very high similarities to humans 6virus transmission from camels is thought to be connected to consuming camel milk or urine working with camels andor handling camel products 7 secondary transmissions are largely associated with hospitals or close contacts of mers cases as shown with the family cluster in the united kingdom uk relatives or people living in close contact with an infected patient are susceptible to the pathogen even outside of hospital settings 8while the exact methods of mers-cov transmissions are unknown respiratory droplet and aerosol transmissions are cited as most probable but there is no conclusive evidence on how close a person has to be for exposure and what protection is most suitable 3 9 for example the korean ministry of health and welfare kmoh classified close contacts as those who were within 2 meters of mers-cov infected patient or in contact with respiratory droplets without personal protective equipment yet the extent to which of those close contacts were infected is unknown 10 it has been hypothesized that camels can transmit a higher dose of viruses to humans while the quantity is lower between humans and that mers-cov has not fully adapted for human-to-human transmission 11 12 food oral-fecal and fomite transmissions are also possible transmission routes since the virus has been detected in camel milk patient fecal sample and hospital surfaces 1316patients with mers have a wide range of symptoms from being completely asymptomatic to suffering from severe respiratory illnesses fever cough chills and myalgia are some of the most commonly reported symptoms in mild cases but respiratory distress kidney failure and septic shock have been reported in acute cases 17 18 there are neither vaccines nor specific medications against mers-cov so treatments are usually palliative in nature 17 19 more than a third of those infected with mers-cov die 1 for comparative perspective case fatality was one in ten for the sars pandemic of 2003 20research is yet to be done on the relationship between symptoms and transmissibility given that clinical procedures for acute patients can generate aerosolized viral particles patients with severe respiratory distress would be more likely to transmit the virus compared to asymptomatic patients but transmissibility of airborne mers-cov is unknown 12 in addition research in transmission is essential with regards to superspreaders who are sources for large number of cases for healthcare associated outbreaks 21the uncertainty of pathogen transmission lack of vaccine against mers-cov and deficit in mers specific treatments make public health interventions challenging to design 22 with ease of international travel the possibility of mers spread is present in all nations notably countries without mers endemic are unfamiliar with the infectious agent that may be imported by travelers and are therefore particularly vulnerablein this paper we reviewed epidemiological contact tracing information from public health agencies and peer-reviewed literature in order to see geographic and temporal distribution of mers cases around the globe concurrently we used genetic sequences to infer transmission dynamics and inter-host evolution of mers-cov the combined analysis was used to present a phylodynamic picture detailing international zoonotic and healthcare associated transmissions at genetic and population levels these analyses can be used to understand pathogen spread and to implement public health measures to curb a pandemic 23detailed review of current literature was conducted using the five-step model of khan et al 24 the literature searches on pubmed used following keywords middle east respiratory syndrome mers and mers cov the articles potential relevance to our topic was examined initially by article title then by abstract content included papers were case reports and articles on phylogenetics healthcare related outbreaks and epidemiology and we excluded papers on viral structure and model organism research relevant publications from national and international public health agencies were reviewed as well whos disease outbreak news and mers risk assessments spanning september 2012 to june 2016 were used as primary sources to create a map of global transmissions 1 the data were supplemented with the european centre for disease prevention and control ecdcs communicable disease threats reports and korean center for disease control and prevention kcdc and kmoh reports published online 25 26 number of cases in hospital settings and non-hospital settings were compared using mann-whitney u test in sas software v94 for windows 27 following the literature review forest plots of basic reproduction numbers were created using distillersr forest plot generator 28mers-cov sequences isolated from humans and camels were downloaded from the genbank repository and are listed in additional file 1 29 combined open reading frames 1a and 1b orf1ab region was chosen specifically for the high number of sequences available and low phylogenetic noise in order to create the most informative phylodynamic analyses duplicate sequences from single patients were excluded to explore inter-host dynamics without intra-host evolution and only sequences with known date and place city state or country of collection were included based on the metadata associated with the genbank accession we created three datasets first with all cov sequences isolated from both humans and camels second dataset with solely sequences from humans and third only with sequence from camelsthe sequences were aligned using clustal x and manually edited using bioedit 30 31 then the best fitting nucleotide substitution model was chosen via hierarchical likelihood ratio test with modeltest implemented in paup40 32 33three preliminary analyses were performed prior to bayesian analysis recombination phylogenetic signal and temporal signal tests first identification of recombinant strains was done using bootscanrecscan method in rdp4 with default window size and parameters 34 35second phylogenetic signals in the datasets were investigated with tree-puzzle 36 it reported maximum likelihood for each new tree generated as a single dot on a triangle the distribution of these dots among the seven zones of the triangle indicated their phylogenetic signals if a dot was located in the central triangle its tree had unresolved phylogeny with star-like structure if a dot was located in the sides of the triangle the phylogeny was network like and only partially resolved lastly if the dot was positioned in one of the three corners the tree topology was considered fully resolved 37third amount of evolutionary change over time or temporal signal from the sequences was examined using tempest 38 the three datasets were analyzed separately using default parametersin order to conduct bayesian phylogenetic analyses on mers-cov evolution three parameters for demographic growth model were tested 1 molecular clock 2 prior probability distribution and 3 marginal likelihood estimator first molecular clock was calibrated using dates of sample collection with the bayesian markov chain monte carlo mcmc method in beast v18 39 both strict and relaxed molecular clocks were tested but relaxed clock with underlying lognormal distribution was superior for the investigation of demographic growth of mers-cov orf1ab four independent mcmc runs were carried out each with one of the following coalescent prior probability distributions constant population size exponential growth bayesian gaussian markov random field gmrf skyride plot and bayesian skyline plot 4042 both parameters listed above were tested with path sampling and stepping stone marginal likelihood estimators 43 44best fitting model was chosen by comparing the bayes factors 45 if log bayes factor was 1 and 3 there was weak evidence against the model with lower marginal likelihood 43 higher log values indicated stronger evidence such that values greater than 3 and 5 were considered to give strong and very strong evidence respectivelyfor all three datasets the mcmc sampler was run for at least 50 million generations sampling every 5000 generations only parameter estimates with effective sample size ess greater than 250 were accepted to ensure proper mixing of the mcmcphylogeographic analyses were conducted also using bayesian-mcmc method in beast using 1 best fitting nucleotide substitution model chosen by modeltest 2 relaxed molecular clock with underlying lognormal rate distribution 3 gmrf skyride plot as demographic model and 4 evolutionary rate previously estimated with sample collection dates for all three datasets the mcmc chains were run for at least 100 million generations and sampled every 10000 steps using the standard continuous time markov chain over discrete sampling locations 31 cities and countries and bayesian stochastic search variable selection procedures to infer social network phylogeographic analyses were carried out for total and human datasets 46 for the camel subset continuous geographical trait analysis was used since spatial distribution of the mers-cov from camels was presumed not to be independent of their genetic phylogeny 47maximum clade credibility trees which had the largest product of posterior clade probabilities were selected after 10 burn-in using tree annotator part of the beast package 39 calculations of posterior probability were used to establish statistical support for monophyletic cladeswe retrieved 196 mers-cov sequences from genbank 88 from camels and 108 from humans to analyze molecular evolution of the coronavirus over time additional file 1 all available orf1ab sequences as of march 16 2016 were included and their dates ranged from april 2012 to the latest deposited sequences of june 2015 these sequences were from china egypt france germany oman qatar saudi arabia korea thailand uae uk and us 48 main dataset with all sequences subset with only sequences from humans and third subset with sequences from camels were createdsequences were aligned with clustal x and four were removed due to poor alignment genbank accession numbers kj361499 kj156916 kj156941 and kj156942due to possibilities of recombinant mers-cov strains aligned sequences were tested for recombination via rdp4 4951 sequences 441sa15 and 451sa15 had similarities to two different strains 470sa15 and 355sa13 and were removed from the dataset since recombinant strains could convolute the evolutionary analysis results shown in additional file 2 figure s1then the phylogenetic content of orf1ab region was investigated by likelihood mapping method to ensure that there were enough signals to compute phylogenies 36 the percentage of dots or noise level falling in the central triangle was 14 for all sequences 23 for human sequences only and 32 for camel sequences only additional file 2 figure s2a b and c respectively for all three datasets the three corners of the triangles summed to be greater than 95 and the central triangles had less than 30 noise so we expected fully resolved tree-like phylogenies 37temporal signal of the sequences was also investigated temporal signal refers to how much genetic change has taken place between sampling times which is especially important in this case since samples were collected over time 38 in order to make molecular clock inferences genetic distances on phylogenetic trees have to be translated into temporal distances root-to-tip divergence plots are shown in additional file 2 figure s3a b and c no major deviations from the regression line were observed indicating that the genetic divergence of the sequence more or less align with what is expected given the sequence sampling date the regression plots for the main dataset and the human subset had r2 values of 075 and 063 respectively indicating a strong association while the camel subset had r2 of 042 which was weaker but still positivefinally the datasets were analyzed for their evolutionary history over time and space using beast the tamura-nei 93 tn93 evolutionary model with gamma distribution g  005 was chosen by modeltest as best fit the gmrf skyride plot with stepping stone marginal likelihood estimator was selected as the best demographic model by beast phylogeographic trees of the main dataset is shown in fig 3 and the camel set is shown in fig 4 main dataset colored according to countries is available as additional file 2 figure s4 and human set trees are included as additional file 2 figures s5 and s6

over 1300 mers cases or almost 80 of global incidence have been reported from saudi arabia 1 korea has the second highest number of cases n  185 and united arab emirates uae with 83 cases is third 1 in the past three years since discovery of mers-cov eight major healthcare associated outbreaks have been reported worldwide the ninth wave recently occurring in multiple cities of saudi arabia those described here are based on cases with documented nosocomial transmission and are indicated by blue colored clusters in fig 5 cases of mers patients traveling internationally are indicated by arrows representing the direction of their travel and probable zoonotic transmission cases are marked by brown camels in the same figure
the first hospital related outbreak was in zarqa jordan where 2 cases were confirmed for mers-cov and 11 were declared probable cases retrospectively 52 at the time of this outbreak in april source of the respiratory illnesses was unknown but it was later determined to be identical to the novel coronavirus mers-cov identified in the following september 5254 in total nine cases were reported in 2012 and these early sequences 389jo12 can be seen at the top of the tree in fig 3in january of 2013 uk reported an intra-familial cluster of 3 where the index case had traveled to pakistan and saudi arabia 8 the three cases 245gb13 9gb13 and 10gb13 in fig 3 formed a distinct cluster in our tree as expected since the viruses isolated would have great genetic similarity consistent with proximity of the dates and location of infection secondary transmission occurred in france where the cov was transmitted to a patient sharing a hospital room with a mers confirmed case who had traveled to uae 55 56a major outbreak at several hospitals in the al-hasa region of saudi arabia occurred around april 2013 where epidemiological investigation linked 23 mers cases to dialysis and intensive care units 5759 these are indicated in orange near the middle of the phylogenetic tree fig 3 from june to august of the same year there was a community outbreak in hafr al-batin where 12 patients were infected 60 although there was a transmission to a healthcare worker the rest of the patients in this cluster were presumed to have gathered for the large regional camel market and therefore both zoonotic and human-to-human transmissions may have occurred simultaneously interestingly both the al-hasa and hafr-al-batin outbreaks cluster with sequences from riyadh which may indicate travel of persons and possibly mers-cov with them to and from this capital cityin the following year from march to june of 2014 the biggest outbreak to date was reported from multiple countries saudi arabia uae iran and jordan 6164 sequences from patients during this time distinctly separated into three clusters jeddah cluster in green abu dhabi cluster red and riyadh cluster pink and they can be seen forming independent clades on the tree and concurrently there were at least 13 cases of exported mers in uae jordan philippines malaysia algeria egypt greece netherlands qatar united states us turkey and austria via travelers who visited saudi arabia as shown in fig 5 1 26 6567in 2015 a traveler who visited the arabian peninsula was the index case in the largest outbreak of mers outside of the middle east affecting 185 patients and inciting national panic in south korea 2 19 68 nosocomial transmissions were reported from six hospitals especially prevalent in two major medical centers where 3 superspreaders have been linked to 166 cases 2 when total number of cases are compared nosocomial incidence is distinctly greater than incidence of community acquired or zoonotic infections size differences are statistically significant p  00001 and superspreading may be the culprit son of a korean mers patient traveled to china and tested positive there 313cn15 69 the cluster involving korean and chinese samples seem most closely related to saudi arabian strain 465sa15 which was isolated from hofufin the middle east there was an outbreak in king abulaziz medical center in riyadh with 130 cases from june to august as well as multi-facility outbreaks in riyadh and madinah from september to november of 2015 1 26 70 in 2016 an outbreak in buraidah of saudi arabia occurred in february and march 1 26 and recently an outbreak in a riyadh hospital with 24 cases due to superspreading occurred mid-2016 71a wide range of basic reproduction numbers r0 from 032 to 13 has been reported for mers and are summarized in fig 6 9 14 21 7279 most researchers agree that mers has a low potential to become a pandemic at this point in time but once the cov is introduced in a nosocomial setting the r0 can range from 2 to 67 and even from 7 to 193 75 78
after two farm workers tested positive for the cov qatar and who carried out an investigation of camel related mers cases in october 2013 80 all 14 of their camels tested positive for mers-cov antibodies and 11 were positive for the virus itself the partial sequences of the mers-cov sampled from camels were found genetically similar to the human samples parallel case was observed in saudi arabia where researchers were able to pinpoint the specific camel that carried a 100 genetically identical virus as the patient 81 these sequences 11sa13 and 12sa13 can be seen clustering together at the top of fig 4sequences from camels can be seen interspersed throughout the tree in fig 3 when the camel sequences are examined alone fig 4 it is easy to see that mers-cov from uae form distinct clusters on their own in red while those from saudi arabia seem to have multiple clades in our camel subset analysis the united arab emirates clade diverged from saudi arabian sequences early right after our estimated time to most recent common ancestor tmrca of all taxa march 2012 with 95 confidence intervals july 2011-november 2012 this clade also includes some al-hasa sequences al-hasa is the easternmost region of saudi arabia and therefore geographically closest to uae the intermixing of jeddah and riyadh sequences in the bottom half of the tree may be explained by the camel trades that occur between these two large citieswe analyzed the data separately for sequences isolated from humans and camels in order to ascertain when the introduction of mers-cov occurred in humans for the main dataset with sequences from humans and camels tmrca was estimated to be september 2008 95 confidence interval september 2005-june 2011 of riyadh saudi arabia origin for the human subset tmrca for all taxa was march 2011 ci june 2009-november 2011 and for the camel subset tmrca was march 2012 ci july 2011-november 2012 as mentioned abovethere were three aims for this paper 1 to examine case incidence trends over time and geographic area using epidemiological information 2 to trace evolutionary history of the virus in circulation using genetic data and 3 to explore ways in which these two analyses can be combined to design public health interventionswhile we aimed to have a thorough and complete representation of all contact tracing conducted the data may not be exhaustive we chose pubmed as the source for peer-reviewed literature since it contains relevant articles from life science and medical journals and we believe the flexibility in article search and use of mesh terms are its strong points in addition the database and genbank are overseen by the same organization national library of medicine which allowed us to link sequence meta-data with literature however pubmed does not include dissertations and conference proceedings that may be relevant and may be biased against articles written in languages other than englishnon-heterogeneous sequencing of mers-cov is a limitation of this study some patients have been sampled and had their mers-cov sequenced multiple times while others were not reached duplicate sequences from single patients were excluded based on available meta-data since sampling bias can create apparent sinks that are not present in reality 82 better sampling and meta-data annotation would greatly aid further analysis in this regardsaudi arabian sequences dominate the phylogeographic tree with greatest number of sequences and large number of probable ancestors figs 3 and 4 this was expected since overwhelming majority of mers cases have been reported there although saudi arabia had the largest amount of genetic sequences available which may skew the phylogenetic analysis it also had the most number of mers cases thus the number of sequences was relatively proportional to the number of cases for the country saudi arabia was the most frequent ancestor for many foreign exports and phylogenetic data indicated that the direction of probable transmission was always from mers endemic region of middle east to non-endemic regions such as europe and asiait has previously been posited that an area with great population such as central saudi arabia may be a hub of genetically diverse mers-covs introduced by passage of people and animals 83 for example the two cases exported to us were genetically dissimilar even though they were both healthcare workers returning from saudi arabia the 348us14 sequence clustered with the hospital outbreak of jeddah 2014 while the other us sequence 349us14 formed a distinct clade with riyadh 84 the jeddah sequences seem most genetically similar to mers-cov isolated from a camel in qatar 286qa14 even though jeddah is located in the west coast of saudi arabia and qatar borders the east the intermixing of geographic backgrounds and phylogenetic clustering seem consistent with the theory on presence of several circulating mers-covs in arabian peninsula due to movement of animals and people geographical distribution of camels and human mers-cov cases are found to be highly correlated 85 since majority of human cases have been concentrated in the middle east and camels in this region showed high seroprevalence of mers-cov antibodies there has been ongoing testing in other camel dwelling regions such as africa and asia 8689 seropositivity ranging from 143 to 100 have been found in countries with dromedaries and a nice summary covering these studies is provided by omrani et al 90the later tmrca for the camels march 2012 relative to tmrca for cov isolated from humans march 2011 was unexpected since antibodies against mers-cov have been detected in camels from samples archived as early as 1980s but this may be due to dearth of early sequences from camels 87 88 91 earliest cov isolates from camels were sequenced in 2013 and the short sampling timeframe from 2013 to 2015 makes the root of the tree less than reliable 92 93 while antibodies have been isolated from archived samples the virus itself has not been successfully recovered these historical samples may have been isolated in the latter part of the infection or much later after virus has cleared from the system other studies have shown that the virus most likely circulated in camels first becoming genetically divergent even within a single country before jumping to human hosts and because of the wide prevalence of seropositivity along with different lineages of cov in camels more mers-cov infections from camels to humans are bound to occur in the future 49 87 nevertheless this hypothesis cannot be validated without testing for mers-cov antibodies or even mers-cov in historical human samples 17seasonality of mers has been previously hypothesized from the high incidence of cases during spring and early summer months and it has been postulated that this may be correlated to the camel birthing pattern young newborn camels encountering mers-cov for the first time may get ill and transmit the virus to humans 13 94 95 however outbreaks in latter half of 2015 and early 2016 countered against the expected seasonality 96infectiousness of mers-cov isolated from camels has been demonstrated by raj et al and shepherds and slaughterhouse workers have been shown to have 15 to 23 times higher proportion of individuals with mers antibodies than the general population 97 98 and zoonotic transmission is an important factor to take into account since evolutionary rates of the virus may be different in humans and camels 99 as mers-cov in camels seem to be much more prevalent and as shown here genetically diverse contacts with camels should be engaged with proper personal protection equipment and public awareness about mers-cov infection related to camels should be raisedin surveys conducted regarding mers awareness of the saudi arabian public less than half 471 and 489 were aware that bats and camels could be primary sources of mers-cov 100 101 and there was an optimistic outlook on the fatality rate and treatment of the viral infection which may in turn be factors keeping the mild cases from seeking medical attention only half of the pilgrims surveyed by alqahtani et al were aware of mers and about quarter stated drinking camel milk or visiting a camel farm as possible activities to be pursued during hajj 102 in a 2013 study no mers-cov was detected amongst over 1000 pilgrims tested but 2 of those tested in 2014 were positive 103 104 the crowded living quarters during hajj can impair adequate infection control so health agencies have recommend visiting pilgrims to carefully wash hands consume hygienic foods and isolate themselves when ill 105 106awareness among health care providers should be raised as well superspreading is commonly observed in hospital settings because of the sustained contact in close quarters medical treatments generating aerosolized virus and susceptibility of hospitalized patients 21 even in the endemic nation of saudi arabia the ministry of health identified issues such as ambiguity on mers case definition inadequate infection control and overcrowding to be sources of hospital outbreaks 107 similar concerns have been raised in korea as well doctor shopping and suboptimal infection control due to crowded hospital rooms seem to have propagated the spread nationwide 19an interesting facet of this international analysis was the difference in outcomes for mers-cov infected patients depending on where they are located about 41 of patients in the middle eastern and african countries died 1 fatality in europe was 47 where about half of those infected died most likely due to severity of illness in cases transported there for treatment asian countries on the other hand have an atypical 203 case fatalitywe attempted to estimate the basic reproduction number via bayesian analysis but the mixing of human and camel sequences with multiple introductions of mers-cov from animals to humans was not possible to model however from the literature review many researchers seem to have reached consistent conclusion that the r0 is less than 1 even in endemic countries notable deviations arose only when mers-cov was introduced to a hospital setting then r0 increased by folds superspreading has been cited to be responsible for this trend since the exponential number of transmissions by a few can raise the r0 76although fundamental and gravely essential part of epidemiological investigation contact tracing is costly labor intensive and prone to human error along with many cases where possible sources of transmissions are unknown zoonotic transmissions were at times conjectural based on patients occupation or recall of food consumption nevertheless we were able to illustrate known and probable transmission events starting from first known cases of mers to recent cases of 2016 in addition we have conducted bayesian phylogeographic analysis of mers-cov strains in both humans and camels which is the most up-to-date and comprehensive to our knowledgepurely epidemiological data such as incidence reports and contact tracing can be prone to inaccuracies but can provide background information on individual cases and population level transmission genetic data circumvents human errors and presents quantitative information about an infectious agent but it is not fully informative without accompanying details on collection using phylodynamics to investigate evolutionary history of pathogen can add indispensable details to curb an outbreak such as identifying most closely related cases and predicting origin of the virus revealing additional details at molecular level when epidemiological tracing is inadequate as demonstrated with mers combining these two methods in a holistic approach is valuable for understanding pathogen history and transmission in order to implement effective public health measuresthrough combination of epidemiological data and genetic analysis we present evolutionary history of mers-cov affecting middle east and beyond with focus on hospital outbreaks and zoonotic transmissionssince december 2019 an increasing number of patients with pneumonia occurred in wuhan hubei province china which attracted much attention not only within china but across the world12 the novel pneumonia was named as corona virus disease 19 covid-19 by world health organization who httpswwwwhointdocsdefault-sourcecoronavirusesituation-reports20200211-sitrep-22-ncovpdfsfvrsnfb6d49b12 the common symptoms of covid-19 at illness onset were fever fatigue dry cough myalgia and dyspnea3 in addition some patients might suffer from headache dizziness abdominal pain diarrhea nausea and vomiting3 onset of disease may lead to progressive respiratory failure due to alveolar damage and even death4scientists then isolated a novel coronavirus from human airway epithelial cells which was named 2019-ncov5 lu et al6 found that 2019-ncov was closer to bat-sl-covzc45 and bat-sl-covzxc21 at the whole-genome level and the external subdomain of the 2019-ncov receptor-binding domain rbd was more similar to that of severe acute respiratory syndrome sars coronavirus sars-cov study of zhou et al4 indicated that the angiotensin-converting enzyme ii ace2 is likely the cell receptor of 2019-ncov which were also the receptor for sars-cov and hcov-nl6378 zhou et al4 also proved that 2019-ncov does not use other coronavirus receptors aminopeptidase n and dipeptidyl peptidase 4 the study of xu et al9 found that the rbd domain of the 2019-ncov s-protein supports strong interaction with human ace2 molecules these findings suggest that the ace2 plays an important role in cellular entry thus ace2-expressing cells may act as target cells and are susceptible to 2019-ncov infection10the expression and distribution of the ace2 in human body may indicate the potential infection routes of 2019-ncov through the developed single-cell rna sequencing scrna-seq technique and single-cell transcriptomes based on the public database researchers analyzed the ace2 rna expression profile at single-cell resolution high ace2 expression was identified in type ii alveolar cells at2 of lung1012 esophagus upper and stratified epithelial cells absorptive enterocytes from ileum and colon12 cholangiocytes13 myocardial cells kidney proximal tubule cells and bladder urothelial cells10 these findings indicated that those organs with high ace2-expressing cells should be considered as potential high risk for 2019-ncov infection10in order to investigated the potential routes of 2019-ncov infection on the mucosa of oral cavity we explored whether the ace2 is expressed and the ace2-expressing cell composition and proportion in oral cavity based on the public bulk rna-seq profiles from two public databases and single-cell transcriptomes from an independent data generated in-house the result showed that the ace2 could be expressed in the oral cavity and was highly enriched in epithelial cells moreover among different oral sites ace2 expression was higher in tongue than buccal and gingival tissues these findings indicate that the mucosa of oral cavity may be a potentially high risk route of 2019-ncov infectionna-seq profile data of 13 organs including 695 para-carcinoma normal tissues as control from public tcga were obtained for our analysis and fig 1a showed that ace2 could be expressed in various organs the mean expression of different organs could be found in table 1 according to the mean expression of ace2 the mucosa of oral cavity could express ace2 and the results were validated by the data of normal tissues from the fantom5 cage dataset fig 1bto investigate the ace2 expression on mucosa of oral cavity we looked into the ace2 expression in different oral sites according to the site information provided by the tcga among the 32 adjacent normal tissues 13 tissues located in the oral tongue 2 tissues located in the base of tongue 3 tissues located in the floor of mouse and 14 tissues did not definite the site and were just put into the category of oral cavity the mean expression distribution of different sites was shown in fig 1c when we combined the base of tongue floor of mouth and oral cavity as other sites and compared them with oral tongue we found the obvious tendency that the mean expression of ace2 was higher in oral tongue 13 tissues than others 19 tissues fig 1d while may due to the limitation of the sample size the p value was not significant p  0062single cell rna-seq was utilized for four oral tissues and the data was analyzed to confirm the above results and assess the cell type-specific expression of ace2 after the data preprocessing shown in section materials and methods 22 969 cells were acquired and 7 cell types were identified fig 2a including epithelial cells marker genes including sfn krt6a and krt10 fibroblasts marker genes including fap pdpn col1a2 dcn col3a1 col6a1 t cells marker genes including cd2 cd3d cd3e and cd3g macrophages marker genes including cd163 csf1r cd68 and fcgr2a mast cells marker genes including cma1 ms4a2 tpsab1 tpsb2 b cells marker genes including slamf7 fcrl5 and cd79a and endothelial cells marker genes including pecam1 vwf and eng the heatmap of main cell markers across the cell types can be found in fig 2baccording to fig 2c d we confirmed the ace2 was expressed in oral tissues 052 ace2-positive cells and higher in oral tongue than buccal and gingival tissues 9586 ace2-positive cells located in oral tongue figure 2e shows that the ace2-positive cells could be found in oral tissues including epithelial cells 119 ace2-positive cells t cells 05 b cells 05 and fibroblast 05 and the ace2 was highly enriched in epithelial cells of which 9338 ace2-positive cells belong to epithelial cells fig 2f the above results indicated that the ace2 could be expressed on the epithelial cells of the oral mucosa and highly enriched in tongue epithelial cellsin the last two decades coronavirus has caused two large-scale pandemics sars in 2002 and the middle east respiratory syndrome mers in 201214 in december 2019 a novel coronavirus 2019-ncov induced an outbreak of pneumonia in wuhan china restated the risk of coronaviruses posed to public health15 the infection routes and pathogenesis of 2019-ncov are not fully understood by far and the study of 2019-ncov host cell receptor ace2 could be valuable for the prevention and treatment of the covid-19in this study the analysis of public bulk-seq rna datasets showed that the mucosa of oral cavity could express the ace2 and was higher in tongue than other oral sites the results of this study were consistent with the study of zou et al10 in general many organs with higher expression of ace2 than lung such as intestine heart and kidney according to the study of zhao et al11 the ace2 expression in lung is concentrated in a small population of type ii alveolar cells at2 that may cause the relatively low ace2 expression of lung in bulk-seq rna datasets analysis even though the result of zou et al indicated that the respiratory tract should also be considered as a vulnerable target to 2019-ncov infection10the results of our single cell rna-seq profiles validated the ace2 expression in oral cavity and the level of ace2 expression in oral tissues was higher in tongue than buccal or gingival tissues furthermore we have also demonstrated that the ace2-positive cells were enriched in epithelial cells which was also reported by previous study101216 these findings indicated that oral cavity could be regarded as potentially high risk for 2019-ncov infectious susceptibilityinterestingly we found that the ace2 also expressed in lymphocytes within oral mucosa and similar results were found in various organs of the digestive system and in lungs1112 whether those facts have reminded the 2019-ncov attacks the lymphocytes and leads to the severe illness of patients needs more in vitro and in vivo evidence and validations though the proportion of ace2-positive lymphocytes is quite smallprevious studies have investigated the ace2 mrna and protein expression in various tissues by bulk samples1718 however the distribution of ace2 through bulk data could not indicate the cell type-specific expression of ace2 recently developed single-cell rna-sequencing technology enabled the generation of vast amounts of the transcriptomic data at cellular resolution19 the ace2 expression profile in various organs tissues and cell types provides the bioinformatics evidence for the potential infection routes of 2019-ncov which might also be associated with presented symptomsalthough studies have reported multiple symptoms of hospitalized patients with 2019-ncov infection320 some cases at home might be asymptomatic it is worth noting that a previous study showed that 99 of the patients had no clinical manifestation of oral human papillomavirus hpv but hpv dna was detected in 81 of oral mucosa samples and anti-hpv iga was detected in the saliva of 44 of the patients21 likewise although 2019-ncov infection hardly presented oral symptoms the ace2 expression in the oral cavity indicated that the oral infection route of 2019-ncov cannot be excluded moreover a latest pilot experiment showed that 4 out of 62 stool specimens tested positive to 2019-ncov and another four patients in a separate cohort who tested positive to rectal swabs had the 2019-ncov being detected in the gastrointestinal tract saliva or urine20 thus our results support that in addition to the respiratory droplets and direct contact fecaloral transmission might also be the route of transmission of 2019-ncovour results are mainly based on public datasets and single cell rna-sequencing data of in-house oral tissues with minimal diseased lesion which from our previous project found no significant expression difference among the common epithelial markers in our past study and other previous study2224 it is warrant that further histological methods are used to confirm our results and enhance the persuasion of the conclusionthe ace2-expressing cells in oral tissues especially in epithelial cells of tongue might provide possible routes of entry for the 2019-ncov which indicate oral cavity might be a potential risk route of 2019-ncov infection those preliminary findings have explained the basic mechanism that the oral cavity is a potentially high risk for 2019-ncov infectious susceptibility and provide a piece of evidence for the future prevention strategy in clinical practice as well as daily lifebulk rna-seq data of para-carcinoma normal tissues which were taken as control tissues in the studies were downloaded from the cancer genome atlas tcga httpswwwcancergovtcga and 695 para-carcinoma normal tissues distributed in different organs were obtained for this study which included intestine 51 tissues kidney 129 tissues stomach 35 tissues bile duct 9 tissues liver 50 tissues oral cavity 32 tissues lung 110 tissues thyroid 59 tissues esophagus 11 tissues bladder 19 tissues breast 113 tissues uterus 25 tissues and prostate 52 tissues the rna-seq data were batch effects normalized and log2-transformed for the subsequent analysis violin plot was used to show the distribution of ace2 expression among different organs t test was performed to compare the ace2 expression between two different groups shown in boxplotbesides bulk rna-seq data of normal tissues were downloaded from functional annotation of the mammalian genome cap analysis of gene expression fantom5 cage dataset25 as only two samples of this dataset which owns 60 samples in total located in the tongue we just downloaded 14 organ types to validate the ace2 expression in oral cavity with bar plot including colon ovary breast cerebellum epididymis esophagus gallbladder heart muscle kidney liver lung pancreas prostate and tongueall analyses were performed in r r version 360 and significant level was set as 005due to our previous project about oral potential malignant disorders four tissues of oral mucosa were obtained from patients after informed consent and ethical approval from west china hospital of stomatology sichuan university these oral tissues had been sent for single cell rna sequence the four were taken from three patients with an average age of 50 which were all diagnosed as hyperkeratosis without dysplasia by pathologists just showing an increase in cell number in the spinous layer andor in the basalparabasal cell layers without cellular atypia and its genetic profiles would be much more closed to normal tissue than malignant tissue2224 two tissues were from independent lesions of one patients dorsum linguae the other two tissues came from buccal and gingival sitesfresh biopsy tissues were washed twice by d-pbs hyclone and collected into prechilled macs tissue storage solution miltenyi single-cell suspensions were generated from biopsy tissues using whole skin dissociation kit human miltenyi manufacturer guidelines and filtered by 70 m macs smartstrainers miltenyi carryover red blood cells were lysed by red blood cell lysis buffer abcam and dead cells were removed by easysep dead cell removal annexin v kit stemcell finally cell pellets were re-suspended in d-pbsto generate single-cell gel beads-in-emulsion gems the 10 chromium platform was used to capture and barcode cells cells were partitioned into gems along with gel beads coated with oligonucleotides and cdnas with both barcodes were amplified and a library was constructed using the 10 genomics chromium single cell kit v3 chemistry for each sample the resulting libraries were sequenced on an illumina novaseq 6000 systemthe fastq files were analyzed with the cell ranger software suite version 31 10 genomics the seurat version 30 was applied to read the gene-barcode matrix of four tissues to control quality we removed cells with 200 genes and 500 umi counts and as well as the cells with mitochondrial content higher than 5 besides the genes detected in 3 cells were filtered out the sctransform wrapper in seurat was applied to normalize the data and remove confounding sources of variation the integratedata was used for integrated the seurat objects from four tissues the uniform manifold approximation and projection umap was used for dimensionality reduction and clustering the cells cell types were assigned based on their canonical markers umap plots heatmap and violin plots were generated with seurat in ras the outbreak of coronavirus disease 2019 covid-19 is rapidly expanding in china and beyond with the potential to become a worldwide pandemic1 real-time analyses of epidemiological data are needed to increase situational awareness and inform interventions2 previously real-time analyses have shed light on the transmissibility severity and natural history of an emerging pathogen in the first few weeks of an outbreak such as with severe acute respiratory syndrome sars the 2009 influenza pandemic and ebola3 4 5 6 analyses of detailed line lists of patients are particularly useful to infer key epidemiological parameters such as the incubation and infectious periods and delays between infection and detection isolation and reporting of cases3 4 however official individual patient data rarely become publicly available early on in an outbreak when the information is most neededbuilding on our previous experience collating news reports to monitor transmission of ebola virus7 here we present an effort to compile individual patient information and subnational epidemic curves on covid-19 from a variety of online resources data were made publicly available in real time and were used by the infectious disease modelling community to generate and compare epidemiological estimates relevant to interventions we describe the data generation process and provide an early analysis of age patterns of covid-19 case counts across china and internationally and delays between symptom onset admissions to hospital and reporting for cases reported until jan 31 2020
research in context
evidence before this study
an outbreak of coronavirus disease 2019 covid-19 was recognised in early january 2020 in wuhan city hubei province china the new virus is thought to have originated from an animal-to-human spillover event linked to seafood and live-animal markets the infection has spread locally in wuhan and elsewhere in china despite strict intervention measures implemented in the region where the infection originated on jan 23 2020 more than 500 patients infected with covid-19 outside of mainland china have been reported between jan 1 and feb 14 2020 although laboratory testing for covid-19 quickly ramped up in china and elsewhere information on individual patients remains scarce and official datasets have not been made publicly available patient-level information is important to estimate key time-to-delay events such as the incubation period and interval between symptom onset and visit to a hospital analyse the age profile of infected patients reconstruct epidemic curves by onset dates and infer transmission parameters we searched pubmed for publications between jan 1 1990 and feb 6 2020 using combinations of the following terms coronavirus or 2019-ncov and line list or case description or patient data and digital surveillance or social media or crowd-sourced data the search retrieved one relevant study on middle east respiratory syndrome coronavirus that mentioned flutrackers in their discussion a website that aggregates epidemiological information on emerging pathogens however flutrackers does not report individual-level data on covid-19
added value of this study
to our knowledge this is the first study that uses crowdsourced data from social media sources to monitor the covid-19 outbreak we searched dxycn a chinese health-care-oriented social network that broadcasts information from local and national health authorities to reconstruct patient-level information on covid-19 in china we also queried international media sources and national health agency websites to collate data on international exportations of covid-19 we describe the demographic characteristics delays between symptom onset seeking care at a hospital or clinic and reporting for 507 patients infected with covid-19 reported until jan 31 2020 the overall cumulative progression of the outbreak is consistent between our line list and an official report published by the chinese national health authorities on jan 28 2020 the estimated incubation period in our data aligns with that of previous work our dataset was made available in the public domain on jan 21 2020
implications of all the available evidence
crowdsourced line-list data can be reconstructed from social media data especially when a central resource is available to curate relevant information public access to line lists is important so that several teams with different expertise can provide their own insights and interpretations of the data especially in the early phase of an outbreak when little information is available publicly available line lists can also increase transparency the main issue with the quality of patient-level data obtained during health emergencies is the potential lack of information from locations overwhelmed by the outbreak in this case hubei province and other provinces with weaker health infrastructures future studies based on larger samples of patients with covid-19 could explore in more detail the transmission dynamics of the outbreak in different locations the effectiveness of interventions and the demographic factors driving transmission
in this population-level observational study we used crowdsourced reports from dxycn a social network for chinese physicians health-care professionals pharmacies and health-care facilities established in 2000 this online platform is providing real-time coverage of the covid-19 outbreak in china obtained by collating and curating reports from news media government television and national and provincial health agencies the information reported includes time-stamped cumulative counts of covid-19 infections outbreak maps and real-time streaming of health authority announcements in chinese directly or through state media8 every report is linked to an online source which can be accessed for more detailed information on individual casesthese are publicly available de-identified patient data reported directly by public health authorities or by state media no patient consent was needed and no ethics approval was requiredwe closely monitored updates on dxycn between jan 20 2020 and jan 31 2020 to extract key information on individual patients in near real-time and reports of daily case counts for individual-level patient data we used descriptions from the original source in chinese to retrieve age sex province of identification travel history reporting date dates of symptom onset and seeking care at a hospital or clinic and discharge status when available individual-level patient data were formatted into a line-list database for further quantitative analysis individual-level patient data were entered from dxycn by a native chinese speaker ks who also generated an english summary for each patient entries were checked by a second person jc since dxycn primarily provides information on patients reported in china we also compiled additional information on internationally exported cases of covid-19 we obtained data for 21 countries outside of mainland china australia cambodia canada france germany hong kong india italy japan malaysia nepal russia singapore south korea sri lanka taiwan thailand united arab emirates the uk the usa and vietnam we gathered and cross-checked data for infected patients outside of china using several sources including global news media kyodo news straits times and cnn official press releases from each countrys ministry of health and disease control agenciesin addition to detailed information on individual patients we reconstructed the daily progression of reported patients in each province of china from jan 13 until jan 31 2020 we used the daily outbreak situation reports communicated by provincial health authorities covered by state television and media and posted on dxycn all patients in our databases had a laboratory confirmed sars coronavirus 2 sars-cov-2 infectionour covid-19 database was made publicly available as a google sheet disseminated via twitter on jan 21 2020 and posted on the website of northeastern university boston ma usa on jan 24 2020 where it is updated in real time data used in this analysis frozen at jan 31 2020 are available online as a spreadsheetwe assessed the age distribution of all patients with covid-19 by discharge status we adjusted the age profile of chinese patients by the population of china we used 2016 population estimates from the institute for health metrics and evaluation9 to calculate the relative risk rr of infection with covid-19 by age group to calculate the rr we followed the method used by lemaitre and colleagues10 to explore the age profile of influenza where rr for age group i is defined as
rriciiciniini
where c
i is the number of cases in age group i and n
i is the population size of age group ito estimate trends in the strength of case detection and interventions we analysed delays between symptom onset and visit to a health-care provider at a hospital or clinic and from seeking care at a hospital or clinic to reporting by time period and location we considered the period before and after jan 18 2020 when media attention and awareness of the outbreak became more pronounced11 we used non-parametric tests to assess differences in delays between seeking care at a hospital or clinic and reporting between locations wilcoxon test to compare two locations and kruskallwallis test to compare three or more locationswe estimated the duration of the incubation period on the basis of our line list data we analysed a subset of patients returning from wuhan who had spent less than a week in wuhan to ensure a narrowly defined exposure window the incubation period was estimated as the midpoint between the time spent in wuhan and the date of symptom onsetwe did all analyses in r version 353 we considered p values of less than 005 to be significantthe funder had no role in study design data compilation data analysis data interpretation or writing of the report all authors had access to the data and had final responsibility for the decision to submit for publicationour line list comprised 507 patients reported from jan 13 to jan 31 2020 including 364 72 from mainland china and 143 28 from outside of china table
 our sample captured 52 of 9826 covid-19 cases reported by who on jan 31 2020 the sex ratio was skewed towards males in mainland china five of 30 provinces were represented with 133 26 patients reported by beijing 87 17 by shaanxi 41 8 by hubei capital city is wuhan 19 4 by tianjin and 22 4 by yunnan of 435 patients with known relation to wuhan city most reported a travel history to the city 135 30 or were residents of the city 152 30 while 80 16 had no direct relation to the city 122 24 patients all reported in beijing had no information about their recent history with wuhanthe age distribution of covid-19 cases was skewed towards older age groups with a median age of 45 years iqr 3356 for patients who were alive or who had an unknown outcome at the time of reporting figure 1
 the median age of patients who had died at the time of reporting was 70 years iqr 6581 few patients 13 3 were younger than 15 years adjustment for the age demographics of china confirmed a deficit of infections among children with a rr below 05 in patients younger than 15 years figure 1 the rr measure indicated a sharp increase in the likelihood of reported covid-19 among people aged 30 years and oldera timeline of cases in our crowdsourced patient line list is shown by date of onset in figure 2
 indicating an acceleration of reported cases by jan 13 2020 the outbreak progression based on the crowdsourced patient line list was consistent with the timeline published by china center for disease control and prevention cdc on jan 28 202012 which is based on a more comprehensive database of more than 6000 patients with covid-19 since jan 23 2020 the cumulative number of cases has slowed down in the crowdsourced and china cdc curves figure 2 which probably reflects the delay between disease onset and reporting the median reporting delay was 5 days iqr 38 in our dataprovince-level epidemic curves are shown by reporting date in figure 3
 as of jan 31 2020 16 52 of 30 provinces in mainland china had reported more than 100 confirmed cases the apparent rapid growth of newly reported cases between jan 18 and jan 31 2020 in several provinces outside of hubei province is consistent with sustained local transmissionacross the study period the median delay between symptom onset and seeking care at a hospital or clinic was 2 days iqr 05 days in mainland china figure 4
 this delay decreased from 5 days before jan 18 2020 to 2 days thereafter wilcoxon test p00009 some provinces such as tianjin and yunnan had shorter delays data by province not shown while the early cases from hubei province were characterised by longer delays in seeking care median 0 days iqr 01the median delay between seeking care at a hospital or clinic and reporting was 2 days iqr 25 days in mainland china and decreased from 9 days before jan 18 2020 to 2 days thereafter wilcoxon test p00001 figure 4 similarly to delays in seeking care at a hospital or clinic reporting was quickest in tianjin and yunnan median 1 day iqr 01 and slowest in hubei province median 12 days iqr 716the median delay between symptom onset and seeking care at a hospital or clinic was 1 day iqr 03 for international travellers and shorter than for patients in hubei province or the rest of mainland china kruskalwallis test p00001 figure 4 even in the period after jan 18 2020 when awareness of the outbreak increased a shorter delay between symptom onset and seeking care at a hospital or clinic was seen for international patients than for those in mainland china wilcoxon test p00001 for international cases the delay between seeking care at a hospital or clinic and reporting was 2 days iqr 14 also shorter than for mainland china wilcoxon test p00001 figure 4on the basis of 33 patients with a travel history to wuhan we estimated the median incubation period for covid-19 to be 45 days iqr 3055 appendix p 2information from patient line lists is crucial but difficult to obtain at the beginning of an outbreak here we have shown that careful compilation of crowdsourced reports curated by a long-standing chinese medical social network provides a valuable picture of the outbreak of covid-19 in real time the outbreak timeline is consistent with aggregated case counts provided by health authorities for comparison china cdc published the first epidemic curve by symptom onset on jan 28 202012 line lists provide unique information on the delays between symptom onset and detection by the health-care system reporting delays and travel histories this information cannot be extracted from aggregated case counts published by official sources line list data can help assess the effectiveness of interventions and the potential for widespread transmission beyond the initial foci of infection in particular shorter delays between symptom onset and admission to hospital or seeking care in a hospital or clinic accelerate detection and isolation of cases effectively shortening the infectious perioda useful feature of our crowdsourced database was the availability of travel histories for patients returning from wuhan which along with dates of symptom onset allowed for estimation of the incubation period here and in related work13 14 a narrow window of exposure could be defined for a subset of patients who had a short stay in wuhan at a time when the epidemic was still localised to wuhan several teams have used our dataset and datasets from others to estimate a mean incubation period for covid-19 to be 56 days 95 ci 21113 14 15 16 our own estimate median 45 days iqr 3055 is consistent with previous work that used other modelling approaches13 14 15 16 the incubation period is a useful parameter to guide isolation and contact tracing based on existing data the disease status of a contact should be known with near certainty after a period of observation of 14 days13 availability of a public dataset enables independent estimation of important epidemiological parameters by several teams allowing for confirmation and cross-checking at a time when information can be conflicting and noisyan interesting finding in our data relates to the age distribution of patients we found a heavy skew of infection towards older age groups with substantially fewer children infected this pattern could indicate age-related differences in susceptibility to infection severe outcomes or behaviour however a substantial portion of the patients in our database are travellers a population that is usually predominantly adults although does not exclude children furthermore because patient data in our dataset were captured by the health system they are biased towards the more severe spectrum of the disease especially for patients from mainland china clinical reports have shown that severity of covid-19 is associated with the presence of chronic conditions16 17 which are more frequent in older age groups nevertheless we would also expect children younger than 5 years to be at risk of severe outcomes and to be reported to the health-care system as is seen for other respiratory infections18
biological differences could have a role in shaping these age profiles a detailed analysis of one of the early covid-19 clusters by chan and colleagues19 revealed symptomatic infections in five adult members of the same household while a child in the same household aged 10 years was infected but remained asymptomatic potentially indicating biological differences in the risk of clinical disease driven by age previous immunity from infection with a related coronavirus has been speculated to potentially protect children from sars20 21 and so might also have a role in covid-19 in any case if the age distribution of cases reported here was to be confirmed and the epidemic were to progress globally we would expect an increase in respiratory mortality concentrated among people aged 30 years and older this mortality pattern would be substantially different from the profile of the 2009 influenza pandemic for which excess mortality was concentrated in those younger than 65 years21
in our dataset we saw a rapid increase in the number of people infected with covid-19 in several provinces of china consistent with local transmission outside of hubei province as of jan 31 2020 province-level epidemic curves are only available by date of reporting rather than date of symptom onset which usually inflates recent case counts if detection has increased furthermore province-level data include both returning travellers from hubei province ie importations and locally acquired cases which also usually inflate the apparent risk of local transmission notably other lines of evidence suggest that local transmission is now well established outside of hubei province because travel increased just before the chinese new year on jan 25 2020 and before implementation of the travel ban in wuhan22 accordingly our own data include evidence of transmission clusters in non-travellers with for instance a second-generation transmission event reported in shaanxi on jan 21 2020our study had several limitations one of which was the data we used although all provinces in mainland china provide aggregated information on infections and deaths individual-level patient descriptions are only available for a subset of provinces geographical coverage is heterogeneous in our line list and we have a notable deficit of cases from hubei province the foci of the covid-19 outbreak we expect that little patient-level information is shared on social media by province-level and city-level health authorities in wuhan and hubei province because health systems are overwhelmed for similar reasons provinces with a large total case count at the end of january 2020 or with a weaker health infrastructure were under-represented in our line list with the exception of beijing other limitations in our data include severity only patients who had severe enough symptoms to seek care were captured and changes in case definition a series of epidemiological criteria were required for covid-19 testing including travel history to wuhan within the past 2 weeks residence in wuhan within the past 2 weeks contact with individuals from wuhan with fever and respiratory symptoms within the past 2 weeks and being part of an established disease cluster some of these criteria eg relation to wuhan were relaxed over time appendix as a result we have an over-representation of travel-related cases in our databasethe reproduction number is an important quantity for outbreak control we refrained from estimating this parameter because reporting changes could bias estimates relying on epidemic growth rates furthermore our dataset captured cases all over china and does not reflect transmission patterns in any particular location a mean reproduction number of 2527 has previously been estimated on the basis of the volume of importations of international cases in the pre-intervention period in wuhan11
we recognise that although our data source is useful and timely it should not replace official statistics manual compilation of detailed line lists from media sources is highly time consuming and is not sustainable when case counts reach several thousands here we provide detailed data on 507 patients when the official case count was over 9000 by jan 31 2020 representing a sample of approximately 5 of reported cases and a much smaller proportion of the full spectrum of covid-19 cases which include mild infections a crowdsourced system would not be expected to catch all cases especially if many cases are too mild to be captured by the health-care system digital surveillance or social media notably dxycn does not generate data outside of traditional surveillance systems but rather provides a channel of rapid communication between the public and health authorities in turn our approach has helped extract and repackage information from health authorities into an analytical format which was not available elsewhereat the time of writing efforts are underway to coordinate compilation of covid-19 data from online sources across several academic teams ultimately we expect that a line list of patients will be shared by government sources with the global community however data cleaning and access issues might take a prohibitively long time to resolve for the west african ebola outbreak a similarly coordinated effort to publish a line list took 2 years23 given the progression of the covid-19 outbreak such a long delay would be counterproductiveoverall the novelty of our approach was to rely on a unique source for social media and news reports in china which aggregated and curated relevant information this approach facilitated entry of robust and standard data on clinical and demographic information reassuringly dxycn maintains a special section dedicated to debunking fake news myths and rumours about the covid-19 outbreak looking to the future collection of patient data in the context of emergencies could include information on whether patients are identified through contact tracing or because they seek care on their own furthermore data interpretability could be improved by gathering more quantitative information on how case definitions are used in practicein conclusion crowdsourced epidemiological data can be useful to monitor emerging outbreaks such as covid-19 and as previously ebola virus7 these efforts can help generate and disseminate detailed information in the early stages of an outbreak when little other data are available enabling independent estimation of key parameters that affect interventions based on our small sample of patients with covid-19 we note an intriguing age distribution reminiscent of that of sars which warrants further epidemiological and serological studies we also report early signs that the response is strengthening in china on the basis of a decrease in case detection time and rapid management of travel-related infections that are identified internationally this is an early report of a rapidly evolving situation and the parameters discussed here could change quickly in the coming weeks we will continue to monitor the epidemiology of this outbreak using data from news reports and official sources
for an example of an online source see httpsncovdxycnncovh5viewpneumonia
for the who situation report as of jan 31 2020 see httpswwwwhointdocsdefault-sourcecoronavirusesituation-reports20200131-sitrep-11-ncovpdfsfvrsnde7c0f74
for the laboratory for the modeling of biological  socio-technical systems website at northeastern university see httpswwwmobs-laborg2019ncovhtml
for the spreadsheet of patient-level data until jan 31 2020 see httpsdocsgooglecomspreadsheetsd1gb5cyg0fjutsqh3hll-c5a23zioxmwh5vebklfshzgedituspsharing
for dxy website see dxycn

all data used in this report have been made publicly available on the laboratory for the modeling of biological  socio-technical systems website of northeastern university the available data include daily case counts of covid-19 by reporting date and chinese province and a de-identified line list of patients with covid-19 the line list includes geographical location country and province reporting date dates of symptom onset and seeking care at a hospital or clinic relation to wuhan discharge status when known an english summary of the case description from media sources and a link to the original source of datawhile the recent swine flu pandemic was luckily less severe than initially thought there remains a constant threat of mutated or reassorted influenza strains that give rise to new outbreaks that could range from small local clusters 1 to seasonal epidemics 2 or even global pandemics 3 4 similarly history has also shown us that previously unknown pathogens such as the sars coronavirus could emerge and cause serious outbreaks 5 just in 2012 and 2013 there were 2 new outbreaks of different viruses with pandemic potential mers-cov 6 and h7n9 7 triggering increased surveillance alerts respiratory diseases often manifest themselves through similar flu-like symptoms and early detection of new outbreaks is of central importance in order to delay or prevent their escalation and wider spread however classical surveillance systems are mostly relying on time-delayed and costly virological tests requiring hospital or physician visits 810one potential alternative is to detect typical flu-like symptom in human behaviors by automatically analyzing video footage from public areas such as airports bus stations which exploits the existing vision-based surveillance infrastructure in public venues this will provide a unique valuable source of information that is complementary to the existing public health monitoring network under this context we make a first attempt on the recognition of typical flu-like symptoms sneeze and cough actions and propose a novel discriminative approach which is further evaluated on a new sneeze-cough action datasetmajor contributions our first contribution is a new video action dataset1 dedicated towards the problem of flu-like symptoms detection that is of central importance in early surveillance of respiratory disease outbreaks a series of experiments are conducted with performance analysis that reveals some of the characteristics of this dataset our second contribution is two novel types of action matching kernels amks that are shown to perform competitively comparing to the state-of-the-art methods in particular we show that pyramid match kernel 11 and spatial pyramid matching 12 are both special cases of the proposed kernels the kernels are also closely connected to the recent developments in hough transform 13 14related work current respiratory disease surveillance systems are known to lag significantly behind the onset of outbreaks 15 16 mostly due to their heavy reliance on virological and clinical data including physician visits very recently a web-based surveillance tool has been developed by google 17 which is made possible through search engines by taking advantage of the social health-seeking behavior of patients there are nonetheless concerns that there sometimes exists non-negligible bias in the detection results driven by disease publicity rather than the disease itself the work presented in this paper to our best knowledge is the first to examine this problem with the help of vision-based surveillance and analysisresearch on video action recognition and retrieval 18 has recently witnessed a dramatic increase mainly due to the vast demand to analyze and understand human actions from video footage of everyday life and from web hosts such as youtube myspace videos flickr and sciencestage established methods for modeling and analyzing human actions are often generative statistical approaches especially the markov models eg
19 20 recently the discriminative learning scheme has also been extended to allow structured predictions eg conditional random fields 21 they nevertheless often rely on learning with sophisticated parametric modelssimilar to a number of recent works 2225 we also assume a human action can be sufficiently described by a set of local features in space-time a local feature typically comes with two aspects a descriptor vector and its space-time location as the number and locations of the local features are usually not fixed often a bag-of-words bow method is utilized to map the feature descriptors to a histogram vector in the space spanned by codewords as in 11 24 26 or hierarchical codewords as described in the pyramid match kernel 11 the bow representation has demonstrated impressive performance on image and action analysis tasks nevertheless it does not retain information regarding space-time layout of the local featureson the other hand the spatial or space-time layout of local features has long been regarded as an important cue to infer the existence of a global object from local features the elegant hough transform 27 is originally devised to detect lines and circles an important generalization is developed by ballard 28 to detect objects of arbitrary shapes leibe et al in their seminal work 13 consider a probabilistic variant of the hough transform where the bow model is integrated into the voting space by means of conditional and posteriori probabilities this is further followed by 14 where a dedicated max-margin learning method is developed throughout these methods a crucial step is the construction of a voting space where all local features are made to vote for the existence and if so the location of the global object they belong to an interesting observation is that this voting space is employed by 14 in an implicit manner as clearly revealed from equations 12 and 13 of 14 the model or the parameter vector w is implicitly related to the voting space w is interpreted as weights for the activations of codewords where influence from the voting space is implicitly carried out via the activations a latent variant has also been used for object detection 29recently there have been attempts to integrate the two sources of information bow and the space-time layout the spatial pyramid matching 12 a probabilistic variant of hough transform also called implicit shape model 13 and utilizing the skeleton structure of human body 30 are such examples in the next section we show that our amk explicitly incorporates the space-time layout and the bow model we will also show that the pyramid match kernel and the spatial pyramid matching are special cases of our proposed amks with proper feature extensions section sneeze-cough a public health surveillance dataset will describe our new sneeze-cough dataset in details and followed the experimental results in section results and discussionpresented with such an action below we describe a set of kernel design recipes that are able to integrate both the bow representation and the space-time locations of local featuresunary extensions a unary extension partitions the volume into disjoint parts one such scheme is to partition into concentric layers as displayed in figure 1a by pooling the codeword assignments of these features in their bow representation one partition is characterized by a histogram of length k when k codewords are used a length ks vector is thus produced as a unary extension by concatenating over s partitionsother partition schemes are also possible for example partitioning the volume into half in each dimension results in 222 blocks and is denoted as s8 we can further partition each block into smaller ones where each block has its own histogram interestingly this is the same three-layer spatial pyramid as depicted in figure 1 of spatial pyramid matching 12 the only difference is that here we consider a 3d space-time volume instead of a 2d image space by summing all the histograms over layers with proper weights and by using histogram intersection similarity measure we get back exactly the spatial pyramid matching 12in fact the degenerate case of unary extensions by setting s to 1 returns the original bow model meanwhile by fixing s to 1 considering a bow model with hierarchical codewords and by using histogram intersection similarity measure the pyramid match kernel 11 is recoveredbinary extension different from the unary extensions a binary extension considers the interactions between a pair of features in space-time figure 1b provides such an example where similar to the concept of co-occurrence matrix a 3-dimensional array or 3-tensor is used to accumulate the counts of feature pairs using both volume and bow representations indexed by codewords codewords distance naively this leads to a vector of length kks by accumulating the quantized distance of each feature pair with s possible outcomes in practice it is further summarized into a more compact vector representation for a fixed distance a a k-dim vector is extracted from the diagonal elements b a k-dim vector is obtained by summing over all the off-diagonal elements row-wise for both cases the output vectors are normalized to sum to 1 as each case ends up giving a ks vector a concatenation of both finally leads to a vector representation of length 2ksfrom feature extensions to kernels it is straightforward to carry on and build a kernel from the extended vectors mentioned above in fact a kernel can be built by considering different feature extension by examining on a variety of similarity measures eg linear 2 histogram intersection radial basis function and by choosing from hierarchical vs standard codeword representations a family of kernels can thus be devised using the above recipes where the examples we illustrate in the paper comprise only a small fractionoriginal pyramid match kernels in the original pyramid match kernel paper 11 a video action is represented as a set of local features descriptors excluding their space-time location information therefore an action of interest is represented as  this is followed by building hierarchical codewords using eg hierarchical k-means in each scale l0l-1 a histogram hl of codewords can be computed note the length of corresponding histogram decreases as we navigate to the upper layers of the hierarchy by concatenating these histograms the action p is then characterized as a feature vector p  h0phl-1p as in 11 the kernel function between two actions p and q is thus defined by
1here wl is used to limit the contribution from a particular scale of histogram as inversely proportional to its scale wl  2-l nl is the partial increment from level l-1 to level l
2 denotes the histogram intersection
3which can be equivalently written as
4where id stores the codeword index of a local feature  is the indicator function and k is an index of the set of codewordsamk type ii as illustrated in figure 2 instead of using histogram intersection of eq 3 we consider a matching function by modifying eq 4 to incorporate space-time locations of local features
5where mlpq is a geometric measure of the feature pair and is computed as their affinity in the space-time volume
6as shown in figure 2    refers to its quantized 3d location in the volume while dx dy and dt denote the number of quantization levels on each of the dimensions respectively it is easy to check that for the trivial case dx  dy  dt  1 eq 3 is recovered from eq 5 in other words the pyramid match kernel 11 can be regarded as a special case of amk type ii when no spatial and temporal constraints are enforcedaction matching kernels are mercer kernels it is easy to check that amks type i are mercer kernels ie the kernel matrix is positive semi-definite psd 31 32 as long as proper similarity measures such as 2 and histogram intersection are utilized an important property of amk type ii as defined by eqs 1 2 5 and 6 is that it is a mercer kernel this is clear from the fact that eq 6 is a psd as well as the fact that mercer kernels are closed under positive scaling and summation operations 31 and the weights wl are always positive endowed with a mercer kernel the induced convex optimization problem is guaranteed to produce a unique optimal solution using the support vector machine svm classifiers 31 in practice we use the binarymulticlass algorithms of libsvm 33 with customized kernelsthe action volume an action is naturally bounded in 3d space-time as eg illustrated in figure 1a bottom left in fact this is a property inherit in the problems regarding action recognition and retrieval in a typical recognition dataset such as kth 22 where there is only one person performing an action in a video the action is bounded by the size of the frames one possible scheme is to consider a local coordinate with its origin fixed to the center of these features and to explicitly examine all possible scales in a manner similarly to that of the hough voting space a simple scheme is instead considered in this paper where the action volume is determined by aligning the bounding boxes detected using a human detector 34 as a result its scale is also implicitly decidedwe describe here the new sneeze-cough video dataset that tailors to the specific challenges and characteristics of recognizing flu-like behavior symptoms in public areas note written consent on publication and use of the video data was obtained from each volunteer and the study was cleared by the bioinformatics institute ethics committee represented by the executive director this dataset contains 960 color video clips of imitated surveillance video settings collected from 20 human subjects 8 females and 12 males of 20 to 50 years old using a canon vixia hf20 camcorder a gallery of sample frames are displayed in figure 3 the data acquisition process is carried out in an indoor environment with semi-controlled lighting condition sun lights through windows are present in some of the videos and the camera is mounted on a tripod mimicking the relative height of a typical surveillance camera each clip contains one specific action performed by one subject in a particular view and pose video shots are normalized at 480  290 resolution with stream rate of 5 frame per second each lasts for around 15 seconds in addition to the two flu-like behaviors namely sneeze and cough six common background action types are also included drinking phone calling scratching head stretching arms wiping glasses and waving hands note we deliberately cover a spectrum of possible background action types that are relatively close to our actions of interest in addition each human subject performs each action six times under 2 different poses standing and walking and 3 different views roughly frontalleftright we also perform horizontal flip on each video to produce an additional video set of reflective views which results in a final set of 1920 videosthroughout the experiments the following parameters are used for amk type i and ii the number of codewords is fixed to k  1024 by default 2 similarity measure is used for amk type i meanwhile amk type ii employs histogram intersection together with a hierarchical codewords of 4 levels these two different similarity measures are utilized here to showcase the flexibility of incorporating various similarity measures into the proposed amks libsvm 33 is used with the trade-off parameter c  10 to verify that the proposed amks are able to accommodate different local features two publicly available local feature detectors  descriptors are considered namely hoghof also called space time interest point 22 and cuboid 23accuracy measures for kth we use the standard accuracy measure by averaging the diagonal values from the row-normalized confusion matrix for binary classification this becomes 2 which however is problematic for datasets with imbalanced class distributions such as sneeze-cough as 34 of the sneeze-cough examples belongs to background actions category and using the standard accuracy measure a rate of 75 is reached when a classifier is biased towards blindly assigning every example to background actions this leads to the utilization of precision and recall which are computed by  and  respectively we thus adopt a different accuracy measure of  for this binary classification task which can be regarded as a lower-bounding summary of the precision recall pairkth the kth dataset 22 contains 2391 video shots from 25 actors repeatedly performing 6 different action types under 4 different background contexts the actions include boxing handclapping handwaving jogging running and walking to facilitate direct comparison the same split scheme of 22 is adopted in our experiments where videos from 16 persons are used for training and the other 9 persons are retained for testing table 1 compares results of our proposed amks with reported works our implementation of the two baseline methods 882 for cuboid and 885 for hoghof is consistent with what has been reported in the literature 891
35 for cuboid and 918
35 for hoghof and the results of the proposed amk methods with best rate of 934 with cuboid and 942 with hoghof are competitive when comparing to the state-of-the-art approachessneeze-cough for the sneeze-cough dataset we use 15 persons for training and retain the rest 5 persons for testing we would like to emphasize that this dataset is significantly different and is more challenging comparing to the kth dataset first the actions in this dataset except for hand-waving are usually of short time-span in contrast to actions such as walk or boxing that usually consist of a good number of repetitive action cycles second there exist large variations within the sneeze and cough actions over eg different genders ages and views this is further complicated by the fact that the background actions commonly seen in public areas such as phone calling scratching head are often very similar in appearance to flu-like symptoms meanwhile these 6 background actions by themselves are highly complex and exhibit large variations as well as indicated in the sample frames of figure 3by experimenting with 8-class recognition tasks confusion matrices are obtained to facilitate our investigation into the inter- and cross- actions pattern of this new dataset figure 4 presents the confusion matrices obtained using baseline method bow 2 and the proposed amk type ii kernel when comparing the confusion matrices to the counterparts from kth dataset figure 4a vs figure 5a and figure 4b vs figure 5b it can be seen that the two baseline methods perform much worse on the sneeze-cough dataset than on the kth dataset this loss in accuracy suggests that the sneeze-cough dataset is much more challenging than the kth datasetmeanwhile the actions of sneeze and cough seems to be more correlated with the subset of actions call drink scratch  rather than the rest ones of stretch wave wipe  this might due to the fact that for the action subset sneeze cough call drink scratch  hands are usually placed near the face while for stretch wave wipe  hands are often placed further away from the face the gain in accuracy by adopting the amk ii kernel is also evident when we compare the matrices c and a or d and b in figure 5 for the kth dataset as well as by comparing the same two pair of matrices in figure 4 for the sneeze-cough dataset for kth an improvement of around five points has been observed for the averaged diagonal elements as for sneeze-cough this improvement is around ten points these observations hold valid for both featuresour major interest in this dataset is to recognize flu-like symptoms sneeze and cough from the background actions therefore binary classification experiments are conducted to examine the performance of the proposed amk kernels and the results are listed in table 2 for each amk kernel type in addition to the precision recall pair the accuracy measure provides an easy-to-compare summary of its performance on average we can see that this dataset is rather challenging the best method merely reach an accuracy of around 444 which can be partially explained by the large variations within coughsneeze over various gendersagesviews as well as their similar space-time appearances to those of the background actions for both cuboid and hoghof local features we see significant improvement in accuracy by using specific amks compared to baseline methods take cuboid feature for example we observe that using the amk type i kernel with ub and s27 leads to an increase of accuracy by 125 points interestingly although the best results ie 434 vs 444 are similar for both local features they are in fact obtained from different type of amk kernelsin this paper we develop a new family of kernels in the proposed approach that explicitly integrates the two important aspects of action local features space-time layout and bow representations meanwhile a new public health action dataset is introduced in this paper to facilitate the study of detecting typical flu-like symptoms in public areas this dataset is shown to be significantly different from and is more challenging than established datasets such as the kth dataset we demonstrate that our approach while achieving competitive performance on the well-studied kth dataset produces reasonable results for this unique and challenging sneeze-cough datasetfor ongoing work we would extend the current approach to retrieve flu-like behavior symptoms from video archives which often contain multiple persons simultaneously performing a series of actions often in crowded environments in particular we plan to work with real surveillance datasets and test correlation of daily or weekly average sneezecough incidence with public health records of respiratory disease trends over time to show utility of the approach and if it is following or preceding reported peaks from hospital or doctor visit-based reporting systems we envision that this approach can also be useful for detection of a variety of emergency situations triggering respiratory symptoms such as fires gas leaks or chemical spills from accidents or even terrorist attacks1 the dataset is made available at httpwebbiia-staredusgchengliflurecognitionhtm2 tp tn fp and fn refer to true positive true negative false positive and false negative respectivelythe outbreak of coronavirus disease 19 covid-19 first recognized in wuhan china rapidly became a pandemic of major impact not only on global public health but also on economy and social well-being 1 sars-cov-2 infection results in clinical outcomes ranging from asymptomatic status to severe disease and ultimately death 2 understanding of the molecular mechanisms underlying the pathology of covid-19 is required to design effective therapies and safe vaccines in this context current investigations have been devoted to biochemical characterization and cellular phenotyping in patients to development of animal models of covid-19 3transcriptomics of peripheral blood cells has been a powerful tool to characterize human immune responses to diverse pathogens including respiratory viruses 46 gene expression profiling by different analytical platforms and sample types revealed that covid-19 patients exhibit i activation of humoral immunity hypercytokinemia apoptosis 7 and dynamic toll like receptor tlr signaling 8 in peripheral leukocytes ii induction of interferon stimulated genes isgs chemokines and inflammation in the lower respiratory tract 7 9 10 of importance the results and interpretation of these data were based on single-gene-level analyses in which significance of quantitative changes of each gene are calculated separately and they are latter submitted to pathway enrichment analysis however the statistical power and sensitivity to identify pathways or gene modules computational gene networks associated with disease phenotypes can be enhanced by the use of non-parametric rank-based tests such as the robust positional framework gene set enrichment analysis gsea 11 moreover interpretation of transcriptional changes during covid-19 has been primarily evaluated using canonical pathways that do not often reflect human responses therefore we propose alternative strategies to analyze and interpret transcriptomics data which provide novel insights into immune and metabolic responses during covid-19datasets used in this study included public transcriptomes available at the genome sequence archive gsa or human gsa in national genomics data center beijing institute of genomics big chinese academy of sciences for rna-seq data related to sars-cov-2 infection cra002390 and hra000143 gene expression omnibus geo for rna-seq data related to sars-cov-2 infection gse147507 and microarray data related to sars-cov-1 infection gse1739 or influenza a virus iav infection gse34205 gse6269 gse29366 gse38900 gse20346 gse52428 gse40012 gse68310 gse61754 gse90732 and arrayexpress for nanostring ncounter data related to sars-cov-2 infection e-mtab-8871 deseq2-normalized counts were used for the rna-seq dataset cra002390 7 while raw read counts for the rna-seq datasets gse147507 9 or hra000143 10 were treated and normalized to log2 counts per million with edger package for r 12 normalized data was acquired for nanostring ncounter e-mtab-8871 8 normalized microarray datasets were acquired with omicc platform 13 detailed information about the datasets used in this study are described in table 1data were analyzed with the positional framework gene set enrichment analysis gsea 11 using pre-ranked mode 1000 permutations and weighted enrichment statistics the blood transcriptional modules btms 24 and metabolic pathways annotated in the kyoto encyclopedia of genes and genomes kegg database 25 were used as gene setsto construct the network of btms from peripheral blood mononuclear cell pbmc transcriptomes genes were pre-ranked by the wald test statistics score calculated with deseq2 package comparing each gene in covid-19 patients and healthy controls as described 7 btms detected with a false discovery rate fdr adjusted p  0001 were then linked by the number of genes shared between two gene modulesto perform the btm-driven meta-analysis between respiratory viruses gene lists from each dataset were pre-ranked by log2 fold change of experimental samples over healthy controls gene modules significantly associated with at least 50 of the datasets were selected by a nominal p  0001 for pbmcs and whole blood the datasets were not merged at the single-gene-level each dataset was composed by a different number of genes and samples and different types of samples table 1 the output of the gsea provides a normalized enrichment score nes for each btm associated with each dataset the nes was then compared between datasets selected at the determined cut-off p  0001 to enforce confidence in the enrichments we also retained only the btms that were associated with at least 50 of the datasets independently of infection sample type and regulation metabolic pathways from kegg database were selected by a fdr adjusted p  005 for pbmcs from covid-19 patientsfor balf datasets cra002390 and hra000143 genes were also pre-ranked by log2 fold change of experimental samples over healthy controls and used as input in pre-ranked gsea btms and kegg metabolic pathways were selected by relaxed significance nominal p  005 and consistent up- or downregulation in both datasets for lung biopsies gse147507 one sample from covid-19 patients shows a distinct read count profile and was considered an outlier as described 26 the remaining sample was used to perform single sample gsea in which genes were pre-ranked by log2 fold change of the experimental sample over healthy controlsnetworks were visualized and generated with cytoscape v372 27 heat maps were generated with the package gplots for r and hierarchical clustering with the package amap for r using euclidian distance metric and ward linkage the bubble plots were generated with the package ggplot2 for r graphpad prisma v 8 was used to perform t-tests on nanostring ncounter data and generate bar plotsto evaluate the robustness of our approach validate previous findings and obtain novel perspectives into immune responses to sars-cov-2 infection we constructed a modular transcriptional network of pbmcs from covid-19 patients genes were pre-ranked by the wald test statistics score calculated with deseq2 package 7 and used as input in pre-ranked gsea we interpreted the dynamics in gene expression of covid-19 patients using the alternative tool to conventional pathways the btms which were particularly devised to evaluate human immune responses 24 to ensure maximal confidence we applied a conservative statistical cutoff fdr adjusted p  0001 to select significant btms figure 1a the transcriptional network captured several cellular characteristics of sars-cov-2 infection in peripheral blood including t and nk cell figure 1d cytopenia 28 and upregulation of cell cycle or genes associated with plasma cells and immunoglobulins 7 in addition our approach also detected increased signals of monocytes figure 1b dendritic cells figure 1c and of the mitochondrial respiratory electron transport chain in sars-cov-2 infection figure 1a suggesting a critical role of metabolic pathways for the immune response of covid-19 patientsto gather further insights on host responses to sars-cov-2 infection the modular transcriptional signature of covid-19 patients was compared to that of individuals infected with sars-cov-1 or iav for this we analyzed 11 additional public transcriptome datasets spanning over 600 samples from human pbmcs or whole blood gene lists from each dataset were pre-ranked by the log2 fold changes relative to healthy controls and used as input in pre-ranked gsea the statistical cutoff was established at nominal p  0001 whereas only bmts present in at least 50 of datasets are shown figure 2a independently of the cohort technology to quantify gene expression rna-seq or microarray and type of sample pbmcs or whole blood we observed a core transcriptional response that is comparable between infections caused by sars-cov-2 sars-cov-1 and iav this core response includes modules of cell cycle and proliferation monocytes and dendritic cells indeed the module m67 dendritic cells was upregulated in almost all datasets of interest sars-cov-1 and iav infections also induced significant reduction of peripheral t lymphocytes and nk cells datasets from iav infection induced activation of type i interferonantiviral responses or rig-1 like receptor signaling while only sars-cov-1 induced significant association to one module antiviral ifn signature data from a different cohort of patients and analytical platform also demonstrated that several genes involved in type i interferonantiviral responses were not significantly altered in whole blood of covid-19 patients figure 2b we also evaluated btms that were uniquely associated to the transcriptomes from covid-19 patients which showed enrichment in immune-related modules and heme biosynthesis figure 2c data indicates an upregulation of heme biosynthesis in pbmcs from covid-19 patients figure 2d because immune responses are tightly connected to metabolic programs 4 2931 we explored metabolic pathway enrichment with the kegg database in addition to porphyrin metabolism which shares significant proportion of genes with btm m222 heme biosynthesis ii our analysis confirmed the upregulation of glycolysis and gluconeogenesis 7 and detected other pathways such as tricarboxylic acid tca cycle oxidative phosphorylation tryptophan metabolism glycan degradation nucleotide metabolism and galactose metabolism figure 2ebecause the lung is the primary site of infection and failure of this organ is a severe complication of sars-cov-2 infection we also evaluated immune and metabolic signatures in the lower respiratory tract of covid-19 patients for that we performed a btm-driven meta-analysis of transcriptomes from samples of bronchioalveolar lavage fluid balf 7 using a relaxed statistical cutoff nominal p  005 there were nine significant btms and three kegg metabolic pathways that were consistently up or downregulated among both datasets figure 3a btms reflect upregulated networks of chemokines and neutrophils as well as reduced expression of genes related to dendritic cells monocytes and t cell activation we also found consistent upregulation of the modules related to chemokines figure 3b and neutrophils figure 3c in lung tissue data from one covid-19 patient few metabolic pathways were consistently regulated between the balf datasets including the upregulation of oxidative phosphorylation and downregulation of fructose and mannose metabolism and other glycan degradation figure 3a none of these metabolic pathways were significantly enriched on the sample of lung tissuehere we used a robust modular transcriptomics approach that captured significant changes of cellular patterns in peripheral blood of covid-19 patients including t lymphopenia and reduced numbers of nk cells 28 several hypothesis have been formulated to explain the lymphopenia during covid-19 including t cell infection by sars-cov-2 32 or t cell exhaustion 33 in addition we identified upregulated expression of chemokines and neutrophils in the lung tissue and balf of covid-19 patients that support an immunopathological role for these granulocytes 34 these data are in line with findings by zhou et al 10 which also suggest higher proportion of neutrophils activated dendritic cells and activated mast cells via cell deconvolution of balf transcriptomes interestingly our data suggest increased proportion of monocytes and dendritic cells in the circulation but not in the balf using single-cell rna-seq some studies demonstrated that dendritic cells are indeed reduced in the balf 35 and there are significant phenotypical alterations of monocytes from covid-19 patients compared to healthy controls 36we demonstrated that compared to sars-cov-1 or iav sars-cov-2 infection fails to induce significant type i interferon responses in pbmcs figure 2a or whole blood figure 2b which corroborates the low concentrations of type i interferon in the circulation of covid-19 patients 9 37 38 these findings contrast with induction of isg expression in both lung tissue 9 and balf 10 of covid-19 patients while recent studies indicate that type i and iii interferons negatively affect the lung epithelium during viral infections 39 40 the transcriptional response of peripheral leukocytes reflects the systemic adaptations to the inflammatory environment imposed by sars-cov-2 infection whereas type i interferon signaling in peripheral leukocytes might affect immunity in other organs such as the kidneys 41 importantly recent data suggest an improvement of patients with uncomplicated covid-19 treated with interferon-alpha2b 42we expect that several factors will contribute to differences in transcriptional profiles of larger cohorts of covid-19 patients especially those bearing comorbidities associated with severe disease higher expression of angiotensin-converting enzyme 2 ace2 has been suggested as a potential mechanism of susceptibility of individuals with comorbidities associated with covid-19 43 however severe disease and death also occur after infection of otherwise healthy individuals indicating that a series of mechanisms account for the severity of covid-19 upregulated expression of genes that coordinate heme biosynthesis has been described in sepsis secondary to pneumonia and suggest a protective mechanism against oxidative stress 44 hypoxia also modulates the expression of genes coding for proteins that coordinate heme biosynthesis 45 we hypothesize that excessive heme accumulation could amplify pro-inflammatory cytokine production 46 47 or cause intravascular coagulation 48 and promote pathology during covid-19strikingly we observed the modulation of several metabolic pathways in pbmcs and balf while oxidative phosphorylation was the only significant metabolic pathway overlapping in both compartments this suggests a critical role for mitochondrial activity during covid-19 many metabolites composing the pathways identified in the current study have been quantified via metabolomics of plasma or serum from covid-19 patients 49 50 mass spectrometry measurements revealed the modulation of pathways such as tca cycle and fructose and mannose metabolism 50 tryptophan metabolism glycolysis and gluconeogenesis and others 49 metabolomics analysis of human pbmcs infected with iav showed activation of tryptophan metabolism and glycolysis whereas glucose consumption via hexosamine biosynthesis underlies the cytokine storm promoted by iav infection 51 and could also affect covid-19 taken together this study demonstrates unappreciated inflammatory networks and metabolic pathways that are associated with covid-19publicly available datasets were analyzed in this study this data can be found here genome sequence archive gsa or human gsa in national genomics data center beijing institute of genomics big chinese academy of sciences for rna-seq data related to sars-cov-2 infection cra002390 and hra000143 gene expression omnibus geo for rna-seq data related to sars-cov-2 infection gse147507 and microarray data related to sars-cov-1 infection gse1739 or influenza a virus iav infection gse34205 gse6269 gse29366 gse38900 gse20346 gse52428 gse40012 gse68310 gse61754 gse90732 and arrayexpress for nanostring ncounter data related to sars-cov-2 infection e-mtab-8871blg selected the data performed data analysis interpreted the results and wrote the manuscript cs hs-c and sf interpreted the results and critically reviewed the manuscript all authors contributed to the article and approved the submitted versionthe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interestthe world health organization declared that new coronavirus disease 2019 covid-19 was a public health emergency of international concern on january 30th 2020 1 2 by then there were a total number of 7818 confirmed cases of covid-19 globally with more than 1370 severe cases and 170 deaths the bulk of which was found in china 3 over the course of a few weeks the disease has propagated across the boundaries of china infecting nearly every country at the time of writing this paper may 01 2020 there is a total of 2397216 confirmed cases globally with 162956 deaths 4 symptoms of the disease include dry cough sore throat and fever although the majority of the cases are mild some cases could lead to acute respiratory distress syndrome ards severe pneumonia pulmonary oedema and organ failure 5 after the emergency declaration of who several works have been done in the terms of modeling and prediction to try and provide ways to either understand the disease propagation evaluate preventive measure put in place by authorities provide early and accurate detection of the disease just to name a few mathematical modeling has been used for several years in epidemiological studies 6 mathematical modeling of disease transmission and propagation helps in the prediction of the course of epidemics the design of mass vaccination programs and also it can provide guidance on what type of data are relevant in the study of the epidemics 7 some of the studies carried out in regards to the current covid-19 include modeling of the dynamic of covid-19 exploring the effect of prevention method like travel restriction of covid-19 and studying the effect of climate on the covid-19 propagation 8 on the other hand artificial intelligence ai is a tool used for prediction ai is the study and development of algorithms machines that mimic human intelligence ai has been successfully used in a several fields such as computer vision online advertising spam filtering robotics fraud detection and so on 9 10 in healthcare ai has also gained attention in terms of disease detection treatment selection patient monitoring drug discovery gene function annotation automated experiments automated data collection etc 11 12 as to what concerns the covid-19 ai has been used in medical image acquisition image segmentation and diagnosis 13 in this paper a review of the mathematical modeling and artificial intelligence used in the study estimation and prediction of covid-19 is presented the paper is divided into three parts the first presents the mathematical models used in the study of the pandemic the second presents the various ai applications in disease diagnosis and estimation and in the third part a list of available datasets for covid-19 is presentedthe review is divided into three parts each dealing with a specific aspect like mathematical modeling ai applications and available datasets for each of the three parts the items reviewed were grouped into topics and then a summary of each group is done in all a total number of 61 journal articles reports fact sheets and websites were reviewed the items reviewed were all published between december 2019 to april 2020 table 1 shows the structure of the review including the number of items reviewed and the main focus of the reviewed items
choujun et al 23 used daily intercity migration data together with a seir model to generate a new model that describes the dynamics of covid-19 in china they collected the daily intercity migration data form 367 cities using a mobile application that tracks human migration they concluded that the number of infections in most cities in china would be highest between the middle of february to early march 2020 anca and kieran adapted a traditional seir model to study the specific dynamic compartments and epidemic parameters of covid-19 24 they analyzed the current management strategy of the pandemic including social distancing travel bans and service interruptions and closures for the generation of predictions and assessment of the efficiency of these control measures in 25 the combination of seir and regression models was used with john hopkins university dataset on covid-19 for the prediction of the change in the spreading of covid-19 the study presented in 26 used an age-structured susceptible-exposed-infected-removed seir model for physical distancing measurement and evaluation the authors showed that physical distancing measures were most effective if the gradual return to work started in april the study of the transmission of the covid-19 and its association with temperature and humidity using the seir model was initiated by xiao-jing et al 27 the outcomes of the study presented that raising the temperature and humidity values contributed to the control of transmission of the disease in 28 the seir model was adapted to investigate the potential community-wide impact of public use of face masks on the transmission dynamics and control of the covid-19 pandemic it was suggested that face masks should be used nation-wide and implemented immediately table 3
a time-dependent susceptible-infected-recovered sir model to track the transmission rate and the recovering rate at a particular time was proposed in 29 they obtained a prediction error of 3 or less for confirmed cases and predicted that the day the recovering rate over took the transmission rate was on february 17 2020 in the hubei province of china wang et al 30 modified the sir model by adding different types of time-varying quarantine strategies such as government imposed mass isolation policies and micro-inspection measures at the community level to establish a method of calibrating cases of under-reported infections the sir model was also used to fit the cumulative data of covid-19 to an empirical form in china 31 it was reported that for given parameter values the sir model on the euclidean network obtained high accuracy on data form china and predict when the pandemic would be expected to be over in 32 a simple age-sensitive sir model which integrated known age-interaction contact patterns for the examination of potential effects of age-heterogeneous mitigations on an epidemic in a covid-19-like parameter regime was studied authors found that strict age-targeted mitigation strategies had the potential to reduce mortalities the age-structured sir model with social contact matrices and bayesian imputation was studied to evaluate the progress of the pandemic in india 33 the authors evaluated the influence of social distancing measures like workplace non-attendance and school closure on the transmission of the novel corona virus it was found that a three-week lockdown would be insufficient to prevent the spread of the disease a simple sir model modified to include certain variables of containment measures taken worldwide was used to study these measures 34 by comparing various scenarios it was shown that the infection progress strongly affected by the measures takena susceptible-infectious-quarantined-recovered siqr model for the analysis of data in brazil was used 35 it was found that the number of quarantined individuals grew exponentially and stabilized the seiqr susceptible-exposed-infectious-quarantined-recovered model with time delays for latency and an asymptomatic phase was investigated 36 it was reported that time-varying social distancing using the seiqr model could reduce the number of infections by about 50recently a novel model known as bats-hosts-reservoir-people transmission network model was used to simulate the potential transmission from bats infection source to human 37 another method was developed where the age-specific susceptible-exposed-symptomatic-asymptomatic-recovered-seafood market seiarw model based on two suspected transmission routes was used to quantify age-specific transmission 38 the two routes were from market to person and from person to person the authors concluded that covid-19 transmissibility is higher in elderly persons as compared to young persons in 39 the influence of interventions and self-protection measures travel restriction quarantine of entry contact tracing isolation and wearing masks on covid-19 transmission dynamic in mainland china excluding hubei province was modeled using the markov chain monte carlo mcmc the results showed that the containment strategies were effective and magnificently suppressed the pandemic transmission it was also found that softening personal protection too early might lead to the spread of disease the spss modeler was also used to investigate the correlation between average daily temperatures and the growth rate of covid-19 in infected countries 40 it was shown that the pandemic rates were higher in case studies where the average temperature is lower finally in 41 a coupled ordinary differential equation metapopulation model for different courses on the disease in different age groups were developed it was shown that the economic lockdown could be safely reversed at any time without a substantial effect on the course of the disease in addition it was concluded that strict quarantines could not be necessary to keep the number of infected people lowx-ray radiology consists of beaming x-ray photons onto a part of body to be imaged and collecting the photons that pass through that part of the body depending on the bodys tissue type it will attenuate block some of the incident photons this will create a shadowy image of the body on a detector located behind the body x-ray radiology is used to examine bone structure and detect infections in the lungs computed tomography ct takes the ides of x-ray radiography further by taking x-rays images of the body from multiple angles to produce cross-sectional images without dissecting the body these cross-sectional images also called slices are tomographic images and these contain more detail medical information than the conventional x-rays radiography ct images are used to detect abnormalities in the body like tumors and hemorrhage it can also be used to detect pulmonary embolisms excess fluid and pneumonia in the lungs 42 43 this makes it suitable for diagnosis of covid-19 which is a disease that attacks the lungs and the respiratory systemin their study pan feng et al seek to verify the change obtained in the chest images of patients with covid-19 pneumonia the study was carried out on 4-day intervals from the first day of diagnosis to the day of total recovery excluded from this study are patients with complicated pneumonia with severe respiratory distress for non-severe cases the results of the chest scanner show a progress of lesions severity during the first 10 days then stabilizes thereafter according to this study almost all the patients presented a spike of the disease around the 10th day and the signs of improvement around the 14th day of the symptoms 44 in a series of experiments carried out in 3 days on 51 patients yicheng fang et al studied the performance of 2 methods of medical examinations on patients with covid-19 the results indicate that the sensitivity of chest ct to covid-19 is higher than the rt-pcr technique 98 for ct versus 71 for pcr when rt-pcr tests are negative chest ct can therefore be used on patients with clinical and epidemiological characteristics of covid-19 to confirm or refute the previous results 45 li yan et al also conducted the study to determine the rate of false diagnoses and the performance of ct scans on covid-19 their study was carried out on the first 51 patients confirmed by nucleic acid tests the study confirmed the high performance of the chest ct which produced a low rate of false diagnosis on covid-19 46the principle of neural network nn is based on the collection of nodes called artificial neurons which freely model neurons in the brain based on examples without any prior knowledge without being programmed this system automatically generates identification characteristics when the algorithm uses multiple layers of neurons it is known as deep learning a convolutional neural network cnn is a deep learning algorithm which takes an image as input assign learnable weights to various features objects in the image so as to be able to differentiate one image from the other 9 10wang et al in 49 used cnn with a dataset comprising of 13800 chest x-ray radiography images from 13725 patients so as to try and provide clinicians with a deeper insight into the critical factors affecting with covid-19 cases the reported an accuracy sensitivity and positive prediction value ppv of 926 871 and 964 respectively in 50 three models resnet50 inceptionv3 and inceptionresnetv2 based on cnn were proposed for detecting covid-19 in pneumonia infected patients from chest x-ray radiography images they used roc analyses and confusion matrices to evaluate the performances of the three models and found that the resnet50 model provided the best classification performance with an accuracy of 98 in a retrospective and multi-center study carried out by li et al 51 cnn was employed for the detection of covid-19 they extracted visual features from volumetric chest ct images of covid patients and classified them they reported that the method was not only able to detect covid-19 case but also to distinguish it from other community acquired pneumonia and non-pneumonic lung diseases in 52 a concept known as transfer learning where available data from one scenario is used to enhance accuracy of detection in a second scenario where there is lack of data was used on x-ray images from patients with ordinary bacterial pneumonia confirmed covid-19 cases and other normal infections the goal of the work was to evaluate the performance of some state-of-the-art cnn architectures for medical image classification they obtained an accuracy sensitivity and specificity of 9678 9866 and 9646 respectively and concluded that cnn with x-ray imaging might extract significant biomarkers related to covid-19 hemdan et al 53 on their part implemented seven different cnn architectures with the aim of assisting radiologists in the automatic diagnoses of covid-19 in x-ray images they validated the architectures on 50 chest x-ray images with half confirmed covid-19 cases they reported that the vgg19 and dense convolutional network densenet models had the best performance both with an accuracy of of 90support vector machines svm are supervised learning methods used for regression classification and also outlier detection the aim of svm is to find a hyperplane in an n-dimensional space where n is the number of features that markedly classifies the input data in other words svm will work to find a plane that has the maximum distance between data points of separate classes support vectors are those data points that are closest to the hyperplane these data points affects the position and orientation of the hyperplane 67barstugan et al 54 presented an early detection of covid-19 based on svm the algorithm was applied on abdominal computed tomography ct images four different image datasets of variable size 16x16 32x32 48x48 64x64 were created from 150 ct images features were extracted through grey level co-occurrence matrix glcm local directional pattern ldp grey level run length matrix glrlm grey-level size zone matrix glszm and discrete wavelet transform dwt algorithms svm was then used to classify the extracted features a maximum sensitivity and accuracy of 9756 and 9871 respectively were obtained with 10-fold cross-validation and glszm feature extraction method in 55 a combination of deep feature extractor and svm was used to detect covid-19 infection in x-ray images the proposed model combination of resnet50 and svm obtained an accuracy of 9538 in 57 svm was used on features extracted from chest x-ray radiography images for early detection of covid-19 cases the features were extracted through a multi-level thresholding of the images they obtained a classification accuracy of 9882 on a total of 40 contrast-enhanced chest x-ray imagesnon-image data was also used with svm and data from emergency care admission exams to detect covid-19 cases de moraes et al 56 used svm and data from emergency care admission exams to detect covid-19 cases they collected data from 235 patients of which 43 were confirmed covid-19 cases they trained five machine learning algorithms namely logistic regression random forests gradient boosting trees neural networks and support vector machines on 70 of the patients and evaluated their performance on the remaining 30 they found out that the svm had the best performance with an accuracy of 85 and concluded that the method could be used to target which patient needs a laboratory covid-19 tests done on themin statistics logistic regression is used to model the probability each sample is assigned a probability between 0 and 1 it can be extended to model several classes of events in order to determine for example different objects in an image 68 although simpler than the cnn logistic regression also could be applied in the in depth study of the manifestation of covid-19 for instance in 58 logistic regression was applied to values provided by roc analysis in the aim of investigating clinical and ct features that indicates severity covid-19 through logistic regression analyses it was found that the clinical factors associated with severecritical covid-19 pneumonia were patient older than 50 years chest pain dyspnea comorbidities and cough among others in 59 deep features from covid-19 patient chest x-ray images were extracted using resnet152 and then smote was used to balance the data points of covid-19 and normal patients then finally machine learning algorithms like random forest and xgboost were used to classify according to the features they obtained an accuracy of 973 for random forest and 977 for xgboostnaive bayes classifiers are among the simplest bayesian network models from the family of probabilistic classifiers coupled with the kernel density estimation they can reach high levels of precision in digital images classification 69 in the study of covid-19 it has also been used for classification in 60 the authors combined conventional statistical and machine learning in order to extract features from ct images the extracted features were then classified by hybrid classifier system based on naive bayes experimental evaluation of this method produced and accuracy of 9607linear discriminant analysis lda is used to find a linear combination of features that characterizes or separates classes of objects or events in pattern recognition and machine learning this resulting combination can be used as a linear classifier for dimensionality reduction before the final classification 70lda was used in 61 with the aim of investigating the characteristics and rules of hematology changes in patients suffering from covid-19 clinical and laboratory test results of the patients were analyzed and different hematological parameters were fitted using lda the nlrrdw  sd combined parameter was found to be the best indicator of the severity of covid-19 in patients with an accuracy of 938decision trees is a technique that helps analyzing decisions by identifying the most likely strategy leading to the goal random forest on its part is essentially a collection of decision trees whose results are accumulated into a final result they have the ability to limit variance without increasing error due to bias in medical practice it is used to classify patient images 71 in 62 the chest ct images of 176 patients with covid-19 were used for severity assessment a random forest modeled and trained to evaluate the severity of covid-19 in patients based on quantitative features the rf model showed encouraging results with an accuracy of 875 shi et al proposed an infection size aware random forest method isarf their method had two steps the first one consisted of categorizing different groups while the second classified the images 63 they used an infection size feature defined as the ratio of the volume of infected regions to the total volume of whole segmented lung this infection size was then used in a 3 level random forest classifier that classified it into 4 groups they used a 5-fold cross-validation to evaluate the performance of the proposed algorithm and also compared it to other classifiers like logistic regression support vector machine and neural network nn they obtained a sensitivity specificity and accuracy of 907833879 respectivelyu-net was first proposed by ronneberger et al for segmentation of biomedical images 72 the u-net architecture has two paths namely a contraction path or the encoder and an expanding path or the decoder in the encoder successive convolutional and max pool down-sampling layers are used to extract the context of an image while in the decoder the discriminative features learnt in the encoder are projected onto the pixel space image so as to obtain a semantically segmented image the decoder is made up of a series of upsampling concatenation and then convolution operationu-net based algorithms were also used in the segmentation of medical images for the purpose of covid-19 detection chen et al proposed a new method called modified u-net structure to segment the regions of infected lungs with covid-19 they used aggregated residual network resnext for learning and complex features from the original images they also applied a soft attention mechanism that enhanced the model s ability to differentiate various symptoms of covid-19 64 in 65 attention u-net was used with an adversarial critic model to improve its performance they obtained an average dice score of 978 on 1047 chest x-ray images from three sources in 66 two methods are proposed namely the infnet and the semi-inf-net the inf-net uses implicit reverse attention and explicit edge attention to ameliorate the detection of infected regions in ct lung images the semi-infnet is a semi-supervised solution that helps to overcome the lack of high quality and labeled images they carried out extensive experiments on covid-19 datasets and showed that the proposed methods perform better than other segmentation methodsunsupervised learning have also been used in the study of covid-19 unsupervised learning unlike supervised learning searches for previously undetected prototypes in a data stream without pre-existing labels and minimimum human intervention it makes it possible to model the densities of probability on the entries this algorithm makes it possible to detect abnormal parts of data which do not correspond to any group its application is in the field of density estimation in statistics 10 among the unsupervised learning used in covid-19 is k-means clustering which is a vector quantization algorithm it partitions n observations into k clusters in which each annotation belongs to the cluster with the neighboring mean serving as the princeps of the cluster 73in both mathematical modeling and ai data is the raw material so the first step in the development of covid-19 applications is data collection over the course of few months there are multiple datasets that have been put online in regards to the covid-19 most if not all of these datasets are open source meaning that they are free for anyone to download and use also they are constantly being updated with new data from the field table 4 presents a collection of the open source datasets explored the following presents a comprehensive description of these datasetsdong et al 74 currently provides one of the most complete database of the covid-19 situation the database known as the 2019 novel coronavirus visual dashboard operated is maintained by the johns hopkins university center for systems science and engineering jhu csse they obtained data from about 18 sources such as the who cdc and other governments agencies compiled and shared them in the form of an interactive map of the covid-19 situation map the database includes number of daily contamination active recovery and death it also contains the location stateprovince country longitude latitude number of people tested incident rate and hospitalization rate xu et al 75 are currently collecting and sharing health information on persons with covid-19 from local to national level together with other information from online reports the data are localized geographically and also indicate aspects like the symptoms and the dates of confirmation and admission and also travel recordcohen et al 76 created a covid-19 image database by collecting x-ray images from various websites as well as publications the database is made up of 345 x-ray images zhao et al 77 created a computed tomography ct image database currently may 01 2020 containing 349 images of confirmed covid-19 cases along with 398 images of non-covid-19 cases the ct images are gathered from several covid19-related papers ma et al provided a dataset containing 20 labeled covid-19 ct images of the left lung the right lung and the infection type the labeling was done by two radiologists 78 the aim of their work was to establish a benchmark for ct image segmentation of lungs in regards to covid-19 two radiologists in based in oslo norway have shared two ct datasets the covid-19 ct segmentation dataset with 100 axial ct slices and the segmentation dataset nr 2 with 829 ct slices from more than 60 patients 79 the databases were manually segmented by radiology expertschen et al shared a covid-19 twitter dataset 80 this dataset contains an ongoing collection of tweets ids associated with covid-19 and which started from january 28 2020 such tweet ids include covid-19 coronavirus pandemic and so on they also tracked certain accounts like that of the who cdcgov and hhsgov as of may 01 2020 they collected more than 10 million tweets in many languages rabindra 81 is also collecting tweets using the lstm model deployed on a website the model continuously monitors real-time twitter feed for covid-19 related tweets it uses filters such as language en and tweeter keywords like covid19 coronavirus covid and so on as of may 01 2020 more than 30million tweets were collectedhavard dataverse also provides the global news dataset which contains covid-19 related global english news from gdelt 82 and the climate dataset which contains time series temperature humidity air quality and other monitored data in china from january 1 2020 83 the coronacases initiative which is a pro bono initiative of raioss desenvolvimento ltda and livon sade ltda also provides information on covid-19 cases on their website 84in covid-19 and other pandemic studies other datasets such as population density mobility security incidents economic situation humanitarian condition data and healthcare workforce are important data that will ensure the accuracy of the studies several sources provide those datasets one of such sources is the worldpop which shares spatial demographic datasets from africa asia and central and south america 85 some of the datasets provided by worldpop are population data births internal migration age and sex data administrative areas and global flight data the humanitarian data exchange hdx coordinated by the un office for the coordination of humanitarian affairs ocha shares more than 17000 humanitarian datasets form 253 locations around the globe 86 the who on its part shares the global health workforce statistics 87 the dataset includes data on the number of health workers as well as hospital bed capacity in each country the tech-giants apple and google both released mobility reports on covid-19 apple called their dataset mobility trends reports 88 while google called it google covid-19 community mobility reports 89 both presents aggregated data that registers the daily use of various modes of transportation walking driving transit since the start of february 2020 as well as places visited or stayed in by users of their services the data was collected from customer requests for directions or location in apple and in google maps they also offer a useful visualization tool of the data our world in data on its part provides covid-19 testing dataset where they collect data that are based on tests carried out to establish if a person is currently infected 90 acaps 91 provides a dataset of government measures dataset also provides government measures implemented by governments all around the world in response to covid-19 while the armed conflict location  event data project acled 92 provides security incidents related to covid19 dataset the international monetary fund imf 93 and bfa global 94 both provide datasets on the key economic responses of governments and the effect of covid19 management measures on economylastly the software providerc3ai compiled cleaned structured and standardized covid-19 data from most of the sources presented in this paper 95 the initiative known as c3ai covid-19 data lake contains analysis-ready covid-19 data in one place the service is free and the datasets are updated continuously it contains everything from time-series data to case reports also a github repository was created to collect covid-19 images regarding ai research papers and datasets it contain 19 datsets 11 review papers 18 clinical papers on covid19 images 54 ai-related papers 54 atrticles on cxr methods and 1 paper on line artefact quantification in lung ultrasound images 96the use of mathematical modeling and ai with covid-19 data will increase our knowledge on the disease propagation evaluating prevention measures as well as early and accurate detection of the disease in patients however to arrive at this end a lot of data is needed to explore various models and ai algorithms the data available up till now are mostly of medical images for diagnosis and text based data for social impact analysis while the later may be generated by and readily available to a large number people the former on the other hand can only be generated in a specialized institution by a specialized professional this means that data in low resource setting are not available as these places do not have the sophisticated imaging equipment needed to generate such images 97 also it is well known in data science that datasets from different geographical locations may not hold the same information and this is especially true in terms of healthcare data more data types are therefore needed that can be easily generated easily anywhere on the globe so as to enhance and render the application of the mathematical models and ai algorithm possible for many these data types could be physiological measurements such as ecg spo2 body temperature that could be obtained using wearable devices 98 data concerning the type of preventive measures implemented by authorities are also not well documented in this work only a few of the dataset found provided that information however this information could help in the examination and optimization of the set measures thereby improving the situationin mathematical modeling most of the articles found in the writing of this paper are of covid-19 dynamics however modeling can be done with appropriate datasets to explore the effect of the variables like climate and preventive measure on the spread of covid-19 as explained earlier there is also not many studies on the correlation of environmental and climatic conditions to the covid-19 propagation in the work only two articles were found that addresses this issue and they both provide in different and interesting way of looking at the propagation of this diseases 27 28 simulation of second and third waves of covid-19 outbreaks will also help to enhance surveillance as countries start easing social restriction measures a study is needed to estimate possible hopspots for new outbreaksai deep learning is powerful tool for early and accurate diagnosis of covid-19 and many articles have addressed it most of them apply convolutional neural networks cnn in their work for medical image classification few other studies apply the random forest and support vector machines there are also some that applied u-net and its variations for the segmentation of ct and x-ray images the authors of the ai algorithms reviewed here all claimed that their algorithm performs very well on test data however it is well known that good performance of an algorithm on test data does not mean that it will perform similarly when deployed on the field this is due to fact that in real life the data is more prone to noise and other artefact that are not usually present in the training and test data the lack of diverse annotated images is also not helping the situation in this review only 2 out of 18 studies were found to used annotated data from radiologists collaboration is needed between clinicians and ai experts in other to build a huge amount of annotated images of covid-19 also human in the loop or human augmentation can be another solution to overcome the problem caused by the disparity of an algorithms performance when applied to test data and when applied in the real world most of the studies reviewed used existing models while a few used well known models with some modifications those used with some modifications performed slightly better than the others stressing the need of developing hybrid models to build better and robust architectures much work is also needs to be done in terms of drug andor vaccine discovery treatment selection and contamination risk assessment for medical personnel 99 finally since most of the ai research objective on covid-19 is to find the optimal solution for diagnosis other algorithms like genetic programming and boosting adaboost should be explored so as to clear any doubt regarding their performancesin conclusion covid-19 has spread rapidly all over the world creating an emergency situation mathematical modeling and ai have both shown to be reliable tools in the fight against this pandemic most of the modeling done were based on the susceptible-exposed-infected-removed seir model and the susceptible-infected-recovered sir model while most of the ai implementations were convolutional neural network cnn on x-ray and ct images several datasets concerning the covid-19 have been collected and shared open source however much work is needed to be done in terms of providing the public with a wide variety of data types and from many regions as possible also other ai and modeling applications in healthcare should be explored in regards to this covid-19